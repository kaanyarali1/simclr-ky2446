{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example-InstanceLevelClassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7lapJXPcfwJ"
      },
      "outputs": [],
      "source": [
        "from simclr import SimClr\n",
        "from ntxent import nt_xent_loss\n",
        "from ntxentgit import SimCLR_Loss\n",
        "from augment import TransformsSimCLR\n",
        "from utils import *\n",
        "from LARS import LARS\n",
        "from downstream import DownStream\n",
        "from dataloader import *\n",
        "from ResNetCifar import ResNetCifar\n",
        "from utilsInstance import *\n",
        "from NCECriterion import *\n",
        "from alias_multinomial import *\n",
        "from Cifar10Instance import *\n",
        "from dloadertest import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import pickle"
      ],
      "metadata": {
        "id": "21SGrER9ckeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Cifar10Instance()\n",
        "train_loader = DataLoader(dataset,\n",
        "                    batch_size=128,\n",
        "                    shuffle=True,\n",
        "                    drop_last=True,\n",
        "                    num_workers=2)"
      ],
      "metadata": {
        "id": "eDSlOjbacn9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_dtrain = 50000 # number of training samples in the Dataset. This is for memory bank\n",
        "output_dim = 2048  #Projected output dimensionality\n",
        "noise_count = 512 # number of noise/ negative samples for per image in the mini-batch\n",
        "temp = 0.07 #temperature\n",
        "momentum = 0.9\n",
        "criterion = NCECriterion(len_dtrain)"
      ],
      "metadata": {
        "id": "KaRGASKQcqyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchSize = 128\n",
        "resnet = ResNetCifar(\"resnet50\",batchSize,momentum,temp,noise_count).cuda() #init the encoder network\n",
        "lr = 0.03\n",
        "momentum = 0.9\n",
        "weight_decay = 1e-4\n",
        "epochs = 100\n",
        "optimizer = torch.optim.SGD(resnet.parameters(),lr,momentum= momentum,weight_decay= weight_decay)"
      ],
      "metadata": {
        "id": "8wlS3VaBc-GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet, avg_loss_epoch, mem = trainInstance(resnet,epochs,train_loader,criterion,optimizer,True,\"/content/model-k512\",\"/content/memory-k512\")\n",
        "# If you want to save the model and the memory bank, set the boolean as True and pass path for both memory bank and model."
      ],
      "metadata": {
        "id": "q1pyJ_uTdDdj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}