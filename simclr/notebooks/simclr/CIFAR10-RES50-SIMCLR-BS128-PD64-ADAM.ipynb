{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0772ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# setting path\n",
    "sys.path.append(\"/home/ky2446/simclr\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/layers\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/models\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/loss\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/optim\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/dataloader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0eda83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simclrpy import SimClr\n",
    "from ntxent import nt_xent_loss\n",
    "from ntxentgit import SimCLR_Loss\n",
    "from augment import TransformsSimCLR\n",
    "from utils import *\n",
    "from LARS import LARS\n",
    "from downstream import DownStream\n",
    "from dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83738303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7134ec1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader_simclr = train_loader_simclr(\"CIFAR10\",128)\n",
    "test_loader = test_loader(\"CIFAR10\",128)\n",
    "test_images, test_labels = get_testimgs_list(\"CIFAR10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74bcdd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, step: 50/390, loss: 5.541714191436768\n",
      "Epoch: 0, step: 100/390, loss: 5.528379917144775\n",
      "Epoch: 0, step: 150/390, loss: 5.335732936859131\n",
      "Epoch: 0, step: 200/390, loss: 5.296202659606934\n",
      "Epoch: 0, step: 250/390, loss: 5.207955360412598\n",
      "Epoch: 0, step: 300/390, loss: 5.247541904449463\n",
      "Epoch: 0, step: 350/390, loss: 5.136037826538086\n",
      "Epoch: 0 completed, average loss: 5.347435405926826, time taken: 0.9784109234809876 mins\n",
      "Epoch: 1, step: 50/390, loss: 5.063374996185303\n",
      "Epoch: 1, step: 100/390, loss: 4.898366928100586\n",
      "Epoch: 1, step: 150/390, loss: 5.160389423370361\n",
      "Epoch: 1, step: 200/390, loss: 4.921266078948975\n",
      "Epoch: 1, step: 250/390, loss: 5.008535385131836\n",
      "Epoch: 1, step: 300/390, loss: 4.8974175453186035\n",
      "Epoch: 1, step: 350/390, loss: 4.801013946533203\n",
      "Epoch: 1 completed, average loss: 4.982297826424623, time taken: 0.9477085630098979 mins\n",
      "Epoch: 2, step: 50/390, loss: 4.929309844970703\n",
      "Epoch: 2, step: 100/390, loss: 4.848935604095459\n",
      "Epoch: 2, step: 150/390, loss: 4.85053014755249\n",
      "Epoch: 2, step: 200/390, loss: 4.672571182250977\n",
      "Epoch: 2, step: 250/390, loss: 4.850564956665039\n",
      "Epoch: 2, step: 300/390, loss: 4.763327598571777\n",
      "Epoch: 2, step: 350/390, loss: 4.647538661956787\n",
      "Epoch: 2 completed, average loss: 4.786371603990212, time taken: 0.9387314160664876 mins\n",
      "Epoch: 3, step: 50/390, loss: 4.8369526863098145\n",
      "Epoch: 3, step: 100/390, loss: 4.7482099533081055\n",
      "Epoch: 3, step: 150/390, loss: 4.737977504730225\n",
      "Epoch: 3, step: 200/390, loss: 4.6432013511657715\n",
      "Epoch: 3, step: 250/390, loss: 4.590506076812744\n",
      "Epoch: 3, step: 300/390, loss: 4.6379313468933105\n",
      "Epoch: 3, step: 350/390, loss: 4.5775251388549805\n",
      "Epoch: 3 completed, average loss: 4.64326457732763, time taken: 0.94546404282252 mins\n",
      "Epoch: 4, step: 50/390, loss: 4.536259651184082\n",
      "Epoch: 4, step: 100/390, loss: 4.588239669799805\n",
      "Epoch: 4, step: 150/390, loss: 4.6294450759887695\n",
      "Epoch: 4, step: 200/390, loss: 4.524842739105225\n",
      "Epoch: 4, step: 250/390, loss: 4.481236934661865\n",
      "Epoch: 4, step: 300/390, loss: 4.469873905181885\n",
      "Epoch: 4, step: 350/390, loss: 4.437667369842529\n",
      "Epoch: 4 completed, average loss: 4.557570495360937, time taken: 0.9350707491238912 mins\n",
      "Epoch: 5, step: 50/390, loss: 4.492485523223877\n",
      "Epoch: 5, step: 100/390, loss: 4.5580878257751465\n",
      "Epoch: 5, step: 150/390, loss: 4.40872859954834\n",
      "Epoch: 5, step: 200/390, loss: 4.590398788452148\n",
      "Epoch: 5, step: 250/390, loss: 4.444084167480469\n",
      "Epoch: 5, step: 300/390, loss: 4.430774211883545\n",
      "Epoch: 5, step: 350/390, loss: 4.428689002990723\n",
      "Epoch: 5 completed, average loss: 4.497609362235436, time taken: 0.9428166747093201 mins\n",
      "Epoch: 6, step: 50/390, loss: 4.4344892501831055\n",
      "Epoch: 6, step: 100/390, loss: 4.488438129425049\n",
      "Epoch: 6, step: 150/390, loss: 4.437809944152832\n",
      "Epoch: 6, step: 200/390, loss: 4.401312351226807\n",
      "Epoch: 6, step: 250/390, loss: 4.4497599601745605\n",
      "Epoch: 6, step: 300/390, loss: 4.370737552642822\n",
      "Epoch: 6, step: 350/390, loss: 4.414305686950684\n",
      "Epoch: 6 completed, average loss: 4.455836225167299, time taken: 0.9711988727251689 mins\n",
      "Epoch: 7, step: 50/390, loss: 4.500282287597656\n",
      "Epoch: 7, step: 100/390, loss: 4.518693447113037\n",
      "Epoch: 7, step: 150/390, loss: 4.4684062004089355\n",
      "Epoch: 7, step: 200/390, loss: 4.430723667144775\n",
      "Epoch: 7, step: 250/390, loss: 4.3490777015686035\n",
      "Epoch: 7, step: 300/390, loss: 4.54888916015625\n",
      "Epoch: 7, step: 350/390, loss: 4.4500412940979\n",
      "Epoch: 7 completed, average loss: 4.427070429386236, time taken: 0.9736543814341228 mins\n",
      "Epoch: 8, step: 50/390, loss: 4.426259994506836\n",
      "Epoch: 8, step: 100/390, loss: 4.404346466064453\n",
      "Epoch: 8, step: 150/390, loss: 4.350352764129639\n",
      "Epoch: 8, step: 200/390, loss: 4.374340534210205\n",
      "Epoch: 8, step: 250/390, loss: 4.354401588439941\n",
      "Epoch: 8, step: 300/390, loss: 4.419317245483398\n",
      "Epoch: 8, step: 350/390, loss: 4.4450788497924805\n",
      "Epoch: 8 completed, average loss: 4.4001362482706705, time taken: 0.9865593791007996 mins\n",
      "Epoch: 9, step: 50/390, loss: 4.466289520263672\n",
      "Epoch: 9, step: 100/390, loss: 4.375060081481934\n",
      "Epoch: 9, step: 150/390, loss: 4.368937969207764\n",
      "Epoch: 9, step: 200/390, loss: 4.4531707763671875\n",
      "Epoch: 9, step: 250/390, loss: 4.359654426574707\n",
      "Epoch: 9, step: 300/390, loss: 4.409478187561035\n",
      "Epoch: 9, step: 350/390, loss: 4.3792548179626465\n",
      "Epoch: 9 completed, average loss: 4.370326113089537, time taken: 0.9443791111310323 mins\n",
      "Epoch: 10, step: 50/390, loss: 4.349129676818848\n",
      "Epoch: 10, step: 100/390, loss: 4.4137139320373535\n",
      "Epoch: 10, step: 150/390, loss: 4.333193302154541\n",
      "Epoch: 10, step: 200/390, loss: 4.289517879486084\n",
      "Epoch: 10, step: 250/390, loss: 4.298732280731201\n",
      "Epoch: 10, step: 300/390, loss: 4.35047721862793\n",
      "Epoch: 10, step: 350/390, loss: 4.344041347503662\n",
      "Epoch: 10 completed, average loss: 4.356814366120559, time taken: 0.9268979748090108 mins\n",
      "Epoch: 11, step: 50/390, loss: 4.294750690460205\n",
      "Epoch: 11, step: 100/390, loss: 4.364404201507568\n",
      "Epoch: 11, step: 150/390, loss: 4.334274768829346\n",
      "Epoch: 11, step: 200/390, loss: 4.40728235244751\n",
      "Epoch: 11, step: 250/390, loss: 4.2990851402282715\n",
      "Epoch: 11, step: 300/390, loss: 4.339838027954102\n",
      "Epoch: 11, step: 350/390, loss: 4.280150890350342\n",
      "Epoch: 11 completed, average loss: 4.336126898496579, time taken: 0.9336193243662516 mins\n",
      "Epoch: 12, step: 50/390, loss: 4.317704677581787\n",
      "Epoch: 12, step: 100/390, loss: 4.343926429748535\n",
      "Epoch: 12, step: 150/390, loss: 4.321616172790527\n",
      "Epoch: 12, step: 200/390, loss: 4.242996692657471\n",
      "Epoch: 12, step: 250/390, loss: 4.315590858459473\n",
      "Epoch: 12, step: 300/390, loss: 4.314248561859131\n",
      "Epoch: 12, step: 350/390, loss: 4.292849540710449\n",
      "Epoch: 12 completed, average loss: 4.327048008258526, time taken: 0.9416433811187744 mins\n",
      "Epoch: 13, step: 50/390, loss: 4.412632942199707\n",
      "Epoch: 13, step: 100/390, loss: 4.392372131347656\n",
      "Epoch: 13, step: 150/390, loss: 4.238100528717041\n",
      "Epoch: 13, step: 200/390, loss: 4.343621730804443\n",
      "Epoch: 13, step: 250/390, loss: 4.33111572265625\n",
      "Epoch: 13, step: 300/390, loss: 4.268511772155762\n",
      "Epoch: 13, step: 350/390, loss: 4.285445690155029\n",
      "Epoch: 13 completed, average loss: 4.310708147440201, time taken: 0.9650072654088339 mins\n",
      "Epoch: 14, step: 50/390, loss: 4.356506824493408\n",
      "Epoch: 14, step: 100/390, loss: 4.31702995300293\n",
      "Epoch: 14, step: 150/390, loss: 4.290916919708252\n",
      "Epoch: 14, step: 200/390, loss: 4.369134902954102\n",
      "Epoch: 14, step: 250/390, loss: 4.286740303039551\n",
      "Epoch: 14, step: 300/390, loss: 4.320658206939697\n",
      "Epoch: 14, step: 350/390, loss: 4.214317798614502\n",
      "Epoch: 14 completed, average loss: 4.295578489548121, time taken: 0.9586727301279704 mins\n",
      "Epoch: 15, step: 50/390, loss: 4.267122745513916\n",
      "Epoch: 15, step: 100/390, loss: 4.240420341491699\n",
      "Epoch: 15, step: 150/390, loss: 4.281644821166992\n",
      "Epoch: 15, step: 200/390, loss: 4.269912242889404\n",
      "Epoch: 15, step: 250/390, loss: 4.297794342041016\n",
      "Epoch: 15, step: 300/390, loss: 4.245543956756592\n",
      "Epoch: 15, step: 350/390, loss: 4.296088695526123\n",
      "Epoch: 15 completed, average loss: 4.28304429543324, time taken: 0.9400431315104166 mins\n",
      "Epoch: 16, step: 50/390, loss: 4.206287860870361\n",
      "Epoch: 16, step: 100/390, loss: 4.283337593078613\n",
      "Epoch: 16, step: 150/390, loss: 4.284599781036377\n",
      "Epoch: 16, step: 200/390, loss: 4.211372375488281\n",
      "Epoch: 16, step: 250/390, loss: 4.221654415130615\n",
      "Epoch: 16, step: 300/390, loss: 4.268126010894775\n",
      "Epoch: 16, step: 350/390, loss: 4.287904739379883\n",
      "Epoch: 16 completed, average loss: 4.276748671898475, time taken: 0.9506195465723674 mins\n",
      "Epoch: 17, step: 50/390, loss: 4.254437446594238\n",
      "Epoch: 17, step: 100/390, loss: 4.281835079193115\n",
      "Epoch: 17, step: 150/390, loss: 4.305281162261963\n",
      "Epoch: 17, step: 200/390, loss: 4.301969051361084\n",
      "Epoch: 17, step: 250/390, loss: 4.207286357879639\n",
      "Epoch: 17, step: 300/390, loss: 4.3067216873168945\n",
      "Epoch: 17, step: 350/390, loss: 4.236321926116943\n",
      "Epoch: 17 completed, average loss: 4.266194094144381, time taken: 0.9520569403966268 mins\n",
      "Epoch: 18, step: 50/390, loss: 4.2427825927734375\n",
      "Epoch: 18, step: 100/390, loss: 4.249476432800293\n",
      "Epoch: 18, step: 150/390, loss: 4.262818336486816\n",
      "Epoch: 18, step: 200/390, loss: 4.237972259521484\n",
      "Epoch: 18, step: 250/390, loss: 4.286065101623535\n",
      "Epoch: 18, step: 300/390, loss: 4.232915878295898\n",
      "Epoch: 18, step: 350/390, loss: 4.227686405181885\n",
      "Epoch: 18 completed, average loss: 4.257943833179963, time taken: 0.9766757408777873 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, step: 50/390, loss: 4.214625358581543\n",
      "Epoch: 19, step: 100/390, loss: 4.259737491607666\n",
      "Epoch: 19, step: 150/390, loss: 4.209160327911377\n",
      "Epoch: 19, step: 200/390, loss: 4.207788944244385\n",
      "Epoch: 19, step: 250/390, loss: 4.315921306610107\n",
      "Epoch: 19, step: 300/390, loss: 4.263549327850342\n",
      "Epoch: 19, step: 350/390, loss: 4.233273029327393\n",
      "Epoch: 19 completed, average loss: 4.248796258828579, time taken: 0.966874607404073 mins\n",
      "Epoch: 20, step: 50/390, loss: 4.281632423400879\n",
      "Epoch: 20, step: 100/390, loss: 4.243159294128418\n",
      "Epoch: 20, step: 150/390, loss: 4.210104942321777\n",
      "Epoch: 20, step: 200/390, loss: 4.221617221832275\n",
      "Epoch: 20, step: 250/390, loss: 4.214272975921631\n",
      "Epoch: 20, step: 300/390, loss: 4.217483043670654\n",
      "Epoch: 20, step: 350/390, loss: 4.320334434509277\n",
      "Epoch: 20 completed, average loss: 4.244018705074604, time taken: 0.9549369970957439 mins\n",
      "Epoch: 21, step: 50/390, loss: 4.202402114868164\n",
      "Epoch: 21, step: 100/390, loss: 4.245851516723633\n",
      "Epoch: 21, step: 150/390, loss: 4.307963848114014\n",
      "Epoch: 21, step: 200/390, loss: 4.191415309906006\n",
      "Epoch: 21, step: 250/390, loss: 4.253959655761719\n",
      "Epoch: 21, step: 300/390, loss: 4.256492614746094\n",
      "Epoch: 21, step: 350/390, loss: 4.290197372436523\n",
      "Epoch: 21 completed, average loss: 4.238772878891383, time taken: 0.9802549203236898 mins\n",
      "Epoch: 22, step: 50/390, loss: 4.1876630783081055\n",
      "Epoch: 22, step: 100/390, loss: 4.2304463386535645\n",
      "Epoch: 22, step: 150/390, loss: 4.182378768920898\n",
      "Epoch: 22, step: 200/390, loss: 4.243283748626709\n",
      "Epoch: 22, step: 250/390, loss: 4.147038459777832\n",
      "Epoch: 22, step: 300/390, loss: 4.2601141929626465\n",
      "Epoch: 22, step: 350/390, loss: 4.223641395568848\n",
      "Epoch: 22 completed, average loss: 4.2345607134012075, time taken: 0.9614505012830098 mins\n",
      "Epoch: 23, step: 50/390, loss: 4.1559367179870605\n",
      "Epoch: 23, step: 100/390, loss: 4.309356212615967\n",
      "Epoch: 23, step: 150/390, loss: 4.215961933135986\n",
      "Epoch: 23, step: 200/390, loss: 4.262608051300049\n",
      "Epoch: 23, step: 250/390, loss: 4.193925857543945\n",
      "Epoch: 23, step: 300/390, loss: 4.313655376434326\n",
      "Epoch: 23, step: 350/390, loss: 4.202970504760742\n",
      "Epoch: 23 completed, average loss: 4.226303369571001, time taken: 0.9737513621648153 mins\n",
      "Epoch: 24, step: 50/390, loss: 4.1635050773620605\n",
      "Epoch: 24, step: 100/390, loss: 4.284054279327393\n",
      "Epoch: 24, step: 150/390, loss: 4.203794479370117\n",
      "Epoch: 24, step: 200/390, loss: 4.180503845214844\n",
      "Epoch: 24, step: 250/390, loss: 4.220180988311768\n",
      "Epoch: 24, step: 300/390, loss: 4.314133644104004\n",
      "Epoch: 24, step: 350/390, loss: 4.223047733306885\n",
      "Epoch: 24 completed, average loss: 4.224950428498097, time taken: 0.9374972144762675 mins\n",
      "Epoch: 25, step: 50/390, loss: 4.265545845031738\n",
      "Epoch: 25, step: 100/390, loss: 4.2616496086120605\n",
      "Epoch: 25, step: 150/390, loss: 4.22151517868042\n",
      "Epoch: 25, step: 200/390, loss: 4.2435150146484375\n",
      "Epoch: 25, step: 250/390, loss: 4.29600715637207\n",
      "Epoch: 25, step: 300/390, loss: 4.234799861907959\n",
      "Epoch: 25, step: 350/390, loss: 4.170660495758057\n",
      "Epoch: 25 completed, average loss: 4.221405830138769, time taken: 0.9683425505956014 mins\n",
      "Epoch: 26, step: 50/390, loss: 4.237854957580566\n",
      "Epoch: 26, step: 100/390, loss: 4.16448450088501\n",
      "Epoch: 26, step: 150/390, loss: 4.2192792892456055\n",
      "Epoch: 26, step: 200/390, loss: 4.190314769744873\n",
      "Epoch: 26, step: 250/390, loss: 4.1771626472473145\n",
      "Epoch: 26, step: 300/390, loss: 4.23472261428833\n",
      "Epoch: 26, step: 350/390, loss: 4.13461971282959\n",
      "Epoch: 26 completed, average loss: 4.217335745004507, time taken: 0.9477426648139954 mins\n",
      "Epoch: 27, step: 50/390, loss: 4.183471202850342\n",
      "Epoch: 27, step: 100/390, loss: 4.167021751403809\n",
      "Epoch: 27, step: 150/390, loss: 4.1790947914123535\n",
      "Epoch: 27, step: 200/390, loss: 4.181854724884033\n",
      "Epoch: 27, step: 250/390, loss: 4.232866287231445\n",
      "Epoch: 27, step: 300/390, loss: 4.1852707862854\n",
      "Epoch: 27, step: 350/390, loss: 4.193345069885254\n",
      "Epoch: 27 completed, average loss: 4.20863506366045, time taken: 0.9684810439745585 mins\n",
      "Epoch: 28, step: 50/390, loss: 4.1652727127075195\n",
      "Epoch: 28, step: 100/390, loss: 4.274392127990723\n",
      "Epoch: 28, step: 150/390, loss: 4.275448799133301\n",
      "Epoch: 28, step: 200/390, loss: 4.249645709991455\n",
      "Epoch: 28, step: 250/390, loss: 4.315520286560059\n",
      "Epoch: 28, step: 300/390, loss: 4.19388484954834\n",
      "Epoch: 28, step: 350/390, loss: 4.241697788238525\n",
      "Epoch: 28 completed, average loss: 4.2036374446673275, time taken: 0.9478597402572632 mins\n",
      "Epoch: 29, step: 50/390, loss: 4.151231288909912\n",
      "Epoch: 29, step: 100/390, loss: 4.191884994506836\n",
      "Epoch: 29, step: 150/390, loss: 4.157553195953369\n",
      "Epoch: 29, step: 200/390, loss: 4.209352016448975\n",
      "Epoch: 29, step: 250/390, loss: 4.257244110107422\n",
      "Epoch: 29, step: 300/390, loss: 4.214258193969727\n",
      "Epoch: 29, step: 350/390, loss: 4.196256637573242\n",
      "Epoch: 29 completed, average loss: 4.200794993914091, time taken: 0.9093792319297791 mins\n",
      "Epoch: 30, step: 50/390, loss: 4.200167179107666\n",
      "Epoch: 30, step: 100/390, loss: 4.199896812438965\n",
      "Epoch: 30, step: 150/390, loss: 4.183305263519287\n",
      "Epoch: 30, step: 200/390, loss: 4.238759994506836\n",
      "Epoch: 30, step: 250/390, loss: 4.17449426651001\n",
      "Epoch: 30, step: 300/390, loss: 4.266035556793213\n",
      "Epoch: 30, step: 350/390, loss: 4.218634128570557\n",
      "Epoch: 30 completed, average loss: 4.1966263502072065, time taken: 0.9627995371818543 mins\n",
      "Epoch: 31, step: 50/390, loss: 4.143304824829102\n",
      "Epoch: 31, step: 100/390, loss: 4.218987941741943\n",
      "Epoch: 31, step: 150/390, loss: 4.155655860900879\n",
      "Epoch: 31, step: 200/390, loss: 4.2146148681640625\n",
      "Epoch: 31, step: 250/390, loss: 4.261425018310547\n",
      "Epoch: 31, step: 300/390, loss: 4.168467044830322\n",
      "Epoch: 31, step: 350/390, loss: 4.168991565704346\n",
      "Epoch: 31 completed, average loss: 4.194376852573493, time taken: 0.945942775408427 mins\n",
      "Epoch: 32, step: 50/390, loss: 4.211325645446777\n",
      "Epoch: 32, step: 100/390, loss: 4.173586845397949\n",
      "Epoch: 32, step: 150/390, loss: 4.2017059326171875\n",
      "Epoch: 32, step: 200/390, loss: 4.142016410827637\n",
      "Epoch: 32, step: 250/390, loss: 4.1459527015686035\n",
      "Epoch: 32, step: 300/390, loss: 4.207603931427002\n",
      "Epoch: 32, step: 350/390, loss: 4.142887592315674\n",
      "Epoch: 32 completed, average loss: 4.188992423277635, time taken: 0.9597190817197164 mins\n",
      "Epoch: 33, step: 50/390, loss: 4.159769058227539\n",
      "Epoch: 33, step: 100/390, loss: 4.244994640350342\n",
      "Epoch: 33, step: 150/390, loss: 4.228404998779297\n",
      "Epoch: 33, step: 200/390, loss: 4.2826433181762695\n",
      "Epoch: 33, step: 250/390, loss: 4.142024517059326\n",
      "Epoch: 33, step: 300/390, loss: 4.282876014709473\n",
      "Epoch: 33, step: 350/390, loss: 4.157334804534912\n",
      "Epoch: 33 completed, average loss: 4.183024852703779, time taken: 0.9345403909683228 mins\n",
      "Epoch: 34, step: 50/390, loss: 4.216522216796875\n",
      "Epoch: 34, step: 100/390, loss: 4.234052658081055\n",
      "Epoch: 34, step: 150/390, loss: 4.236330986022949\n",
      "Epoch: 34, step: 200/390, loss: 4.178305625915527\n",
      "Epoch: 34, step: 250/390, loss: 4.1436614990234375\n",
      "Epoch: 34, step: 300/390, loss: 4.141323089599609\n",
      "Epoch: 34, step: 350/390, loss: 4.13170051574707\n",
      "Epoch: 34 completed, average loss: 4.181176455815633, time taken: 0.9658419887224833 mins\n",
      "Epoch: 35, step: 50/390, loss: 4.2492356300354\n",
      "Epoch: 35, step: 100/390, loss: 4.280431747436523\n",
      "Epoch: 35, step: 150/390, loss: 4.121581077575684\n",
      "Epoch: 35, step: 200/390, loss: 4.169360160827637\n",
      "Epoch: 35, step: 250/390, loss: 4.221673965454102\n",
      "Epoch: 35, step: 300/390, loss: 4.258687973022461\n",
      "Epoch: 35, step: 350/390, loss: 4.190128326416016\n",
      "Epoch: 35 completed, average loss: 4.178276416582939, time taken: 0.964134669303894 mins\n",
      "Epoch: 36, step: 50/390, loss: 4.099490165710449\n",
      "Epoch: 36, step: 100/390, loss: 4.182640552520752\n",
      "Epoch: 36, step: 150/390, loss: 4.132282733917236\n",
      "Epoch: 36, step: 200/390, loss: 4.1131591796875\n",
      "Epoch: 36, step: 250/390, loss: 4.193282604217529\n",
      "Epoch: 36, step: 300/390, loss: 4.178101062774658\n",
      "Epoch: 36, step: 350/390, loss: 4.188538551330566\n",
      "Epoch: 36 completed, average loss: 4.172923659055661, time taken: 0.9336653232574463 mins\n",
      "Epoch: 37, step: 50/390, loss: 4.132955074310303\n",
      "Epoch: 37, step: 100/390, loss: 4.238286972045898\n",
      "Epoch: 37, step: 150/390, loss: 4.20031213760376\n",
      "Epoch: 37, step: 200/390, loss: 4.147890090942383\n",
      "Epoch: 37, step: 250/390, loss: 4.247354984283447\n",
      "Epoch: 37, step: 300/390, loss: 4.167603015899658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, step: 350/390, loss: 4.245105266571045\n",
      "Epoch: 37 completed, average loss: 4.17536877363156, time taken: 0.9434629559516907 mins\n",
      "Epoch: 38, step: 50/390, loss: 4.211002349853516\n",
      "Epoch: 38, step: 100/390, loss: 4.135268211364746\n",
      "Epoch: 38, step: 150/390, loss: 4.1551666259765625\n",
      "Epoch: 38, step: 200/390, loss: 4.192165374755859\n",
      "Epoch: 38, step: 250/390, loss: 4.196189880371094\n",
      "Epoch: 38, step: 300/390, loss: 4.165858745574951\n",
      "Epoch: 38, step: 350/390, loss: 4.116433143615723\n",
      "Epoch: 38 completed, average loss: 4.168588182253715, time taken: 0.925615652402242 mins\n",
      "Epoch: 39, step: 50/390, loss: 4.213598251342773\n",
      "Epoch: 39, step: 100/390, loss: 4.105805397033691\n",
      "Epoch: 39, step: 150/390, loss: 4.188473224639893\n",
      "Epoch: 39, step: 200/390, loss: 4.160001277923584\n",
      "Epoch: 39, step: 250/390, loss: 4.225940704345703\n",
      "Epoch: 39, step: 300/390, loss: 4.153600692749023\n",
      "Epoch: 39, step: 350/390, loss: 4.223080635070801\n",
      "Epoch: 39 completed, average loss: 4.162405520219069, time taken: 0.9663941025733948 mins\n",
      "Epoch: 40, step: 50/390, loss: 4.154987335205078\n",
      "Epoch: 40, step: 100/390, loss: 4.140016078948975\n",
      "Epoch: 40, step: 150/390, loss: 4.164453506469727\n",
      "Epoch: 40, step: 200/390, loss: 4.20911979675293\n",
      "Epoch: 40, step: 250/390, loss: 4.115508556365967\n",
      "Epoch: 40, step: 300/390, loss: 4.251328945159912\n",
      "Epoch: 40, step: 350/390, loss: 4.2045087814331055\n",
      "Epoch: 40 completed, average loss: 4.165245831318391, time taken: 0.9481821258862814 mins\n",
      "Epoch: 41, step: 50/390, loss: 4.147736072540283\n",
      "Epoch: 41, step: 100/390, loss: 4.168214797973633\n",
      "Epoch: 41, step: 150/390, loss: 4.2511796951293945\n",
      "Epoch: 41, step: 200/390, loss: 4.084810733795166\n",
      "Epoch: 41, step: 250/390, loss: 4.200034141540527\n",
      "Epoch: 41, step: 300/390, loss: 4.134942054748535\n",
      "Epoch: 41, step: 350/390, loss: 4.1167216300964355\n",
      "Epoch: 41 completed, average loss: 4.161170448401036, time taken: 0.9292463858922323 mins\n",
      "Epoch: 42, step: 50/390, loss: 4.131949424743652\n",
      "Epoch: 42, step: 100/390, loss: 4.128453254699707\n",
      "Epoch: 42, step: 150/390, loss: 4.1624226570129395\n",
      "Epoch: 42, step: 200/390, loss: 4.1064629554748535\n",
      "Epoch: 42, step: 250/390, loss: 4.229975700378418\n",
      "Epoch: 42, step: 300/390, loss: 4.117201805114746\n",
      "Epoch: 42, step: 350/390, loss: 4.104126930236816\n",
      "Epoch: 42 completed, average loss: 4.155386719336876, time taken: 0.915572214126587 mins\n",
      "Epoch: 43, step: 50/390, loss: 4.1682610511779785\n",
      "Epoch: 43, step: 100/390, loss: 4.15610933303833\n",
      "Epoch: 43, step: 150/390, loss: 4.170576095581055\n",
      "Epoch: 43, step: 200/390, loss: 4.13249397277832\n",
      "Epoch: 43, step: 250/390, loss: 4.219341278076172\n",
      "Epoch: 43, step: 300/390, loss: 4.132259845733643\n",
      "Epoch: 43, step: 350/390, loss: 4.084980010986328\n",
      "Epoch: 43 completed, average loss: 4.154636329259628, time taken: 0.9469195326169332 mins\n",
      "Epoch: 44, step: 50/390, loss: 4.11004114151001\n",
      "Epoch: 44, step: 100/390, loss: 4.259900093078613\n",
      "Epoch: 44, step: 150/390, loss: 4.151636123657227\n",
      "Epoch: 44, step: 200/390, loss: 4.088336944580078\n",
      "Epoch: 44, step: 250/390, loss: 4.093395233154297\n",
      "Epoch: 44, step: 300/390, loss: 4.108529567718506\n",
      "Epoch: 44, step: 350/390, loss: 4.131599426269531\n",
      "Epoch: 44 completed, average loss: 4.152787184103941, time taken: 0.9648584643999736 mins\n",
      "Epoch: 45, step: 50/390, loss: 4.153254985809326\n",
      "Epoch: 45, step: 100/390, loss: 4.154911994934082\n",
      "Epoch: 45, step: 150/390, loss: 4.136289596557617\n",
      "Epoch: 45, step: 200/390, loss: 4.1452555656433105\n",
      "Epoch: 45, step: 250/390, loss: 4.201986312866211\n",
      "Epoch: 45, step: 300/390, loss: 4.170107364654541\n",
      "Epoch: 45, step: 350/390, loss: 4.123190879821777\n",
      "Epoch: 45 completed, average loss: 4.151155295738807, time taken: 0.9293426553408305 mins\n",
      "Epoch: 46, step: 50/390, loss: 4.151529788970947\n",
      "Epoch: 46, step: 100/390, loss: 4.109405517578125\n",
      "Epoch: 46, step: 150/390, loss: 4.220150470733643\n",
      "Epoch: 46, step: 200/390, loss: 4.168970108032227\n",
      "Epoch: 46, step: 250/390, loss: 4.322388648986816\n",
      "Epoch: 46, step: 300/390, loss: 4.16675329208374\n",
      "Epoch: 46, step: 350/390, loss: 4.190485000610352\n",
      "Epoch: 46 completed, average loss: 4.148752781061026, time taken: 0.9479078491528828 mins\n",
      "Epoch: 47, step: 50/390, loss: 4.136213302612305\n",
      "Epoch: 47, step: 100/390, loss: 4.139736175537109\n",
      "Epoch: 47, step: 150/390, loss: 4.13750696182251\n",
      "Epoch: 47, step: 200/390, loss: 4.151494026184082\n",
      "Epoch: 47, step: 250/390, loss: 4.172238349914551\n",
      "Epoch: 47, step: 300/390, loss: 4.124610424041748\n",
      "Epoch: 47, step: 350/390, loss: 4.167059421539307\n",
      "Epoch: 47 completed, average loss: 4.148175272574791, time taken: 0.9548778136571249 mins\n",
      "Epoch: 48, step: 50/390, loss: 4.167606353759766\n",
      "Epoch: 48, step: 100/390, loss: 4.222342014312744\n",
      "Epoch: 48, step: 150/390, loss: 4.100222587585449\n",
      "Epoch: 48, step: 200/390, loss: 4.113980293273926\n",
      "Epoch: 48, step: 250/390, loss: 4.0966410636901855\n",
      "Epoch: 48, step: 300/390, loss: 4.185760021209717\n",
      "Epoch: 48, step: 350/390, loss: 4.1135406494140625\n",
      "Epoch: 48 completed, average loss: 4.141892359806941, time taken: 0.9405703822771708 mins\n",
      "Epoch: 49, step: 50/390, loss: 4.168798446655273\n",
      "Epoch: 49, step: 100/390, loss: 4.136999607086182\n",
      "Epoch: 49, step: 150/390, loss: 4.089686870574951\n",
      "Epoch: 49, step: 200/390, loss: 4.182496070861816\n",
      "Epoch: 49, step: 250/390, loss: 4.137138366699219\n",
      "Epoch: 49, step: 300/390, loss: 4.144626140594482\n",
      "Epoch: 49, step: 350/390, loss: 4.194197177886963\n",
      "Epoch: 49 completed, average loss: 4.13956168614901, time taken: 0.9397590120633443 mins\n",
      "Epoch: 50, step: 50/390, loss: 4.213621139526367\n",
      "Epoch: 50, step: 100/390, loss: 4.096763610839844\n",
      "Epoch: 50, step: 150/390, loss: 4.080382347106934\n",
      "Epoch: 50, step: 200/390, loss: 4.115313529968262\n",
      "Epoch: 50, step: 250/390, loss: 4.124371528625488\n",
      "Epoch: 50, step: 300/390, loss: 4.173847675323486\n",
      "Epoch: 50, step: 350/390, loss: 4.118633270263672\n",
      "Epoch: 50 completed, average loss: 4.142536591260861, time taken: 0.9216217001279196 mins\n",
      "Epoch: 51, step: 50/390, loss: 4.110177993774414\n",
      "Epoch: 51, step: 100/390, loss: 4.073051452636719\n",
      "Epoch: 51, step: 150/390, loss: 4.105001926422119\n",
      "Epoch: 51, step: 200/390, loss: 4.042884349822998\n",
      "Epoch: 51, step: 250/390, loss: 4.04006814956665\n",
      "Epoch: 51, step: 300/390, loss: 4.076969146728516\n",
      "Epoch: 51, step: 350/390, loss: 4.165668487548828\n",
      "Epoch: 51 completed, average loss: 4.136479583153358, time taken: 0.9279417753219604 mins\n",
      "Epoch: 52, step: 50/390, loss: 4.174789905548096\n",
      "Epoch: 52, step: 100/390, loss: 4.186152458190918\n",
      "Epoch: 52, step: 150/390, loss: 4.129521369934082\n",
      "Epoch: 52, step: 200/390, loss: 4.122421741485596\n",
      "Epoch: 52, step: 250/390, loss: 4.160606861114502\n",
      "Epoch: 52, step: 300/390, loss: 4.105762004852295\n",
      "Epoch: 52, step: 350/390, loss: 4.112383842468262\n",
      "Epoch: 52 completed, average loss: 4.13675377307794, time taken: 0.942314883073171 mins\n",
      "Epoch: 53, step: 50/390, loss: 4.112271785736084\n",
      "Epoch: 53, step: 100/390, loss: 4.167330265045166\n",
      "Epoch: 53, step: 150/390, loss: 4.18088960647583\n",
      "Epoch: 53, step: 200/390, loss: 4.146734237670898\n",
      "Epoch: 53, step: 250/390, loss: 4.2252044677734375\n",
      "Epoch: 53, step: 300/390, loss: 4.045162677764893\n",
      "Epoch: 53, step: 350/390, loss: 4.075883388519287\n",
      "Epoch: 53 completed, average loss: 4.134040334897164, time taken: 0.9307741641998291 mins\n",
      "Epoch: 54, step: 50/390, loss: 4.07451057434082\n",
      "Epoch: 54, step: 100/390, loss: 4.148792743682861\n",
      "Epoch: 54, step: 150/390, loss: 4.11699914932251\n",
      "Epoch: 54, step: 200/390, loss: 4.161515235900879\n",
      "Epoch: 54, step: 250/390, loss: 4.14152717590332\n",
      "Epoch: 54, step: 300/390, loss: 4.14447021484375\n",
      "Epoch: 54, step: 350/390, loss: 4.1161298751831055\n",
      "Epoch: 54 completed, average loss: 4.133828258514404, time taken: 0.9594163815180461 mins\n",
      "Epoch: 55, step: 50/390, loss: 4.0758056640625\n",
      "Epoch: 55, step: 100/390, loss: 4.127813816070557\n",
      "Epoch: 55, step: 150/390, loss: 4.139261722564697\n",
      "Epoch: 55, step: 200/390, loss: 4.143048286437988\n",
      "Epoch: 55, step: 250/390, loss: 4.127335548400879\n",
      "Epoch: 55, step: 300/390, loss: 4.158909797668457\n",
      "Epoch: 55, step: 350/390, loss: 4.1534295082092285\n",
      "Epoch: 55 completed, average loss: 4.1307409873375525, time taken: 0.9396072149276733 mins\n",
      "Epoch: 56, step: 50/390, loss: 4.100500583648682\n",
      "Epoch: 56, step: 100/390, loss: 4.096033096313477\n",
      "Epoch: 56, step: 150/390, loss: 4.148210048675537\n",
      "Epoch: 56, step: 200/390, loss: 4.140366554260254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56, step: 250/390, loss: 4.110506057739258\n",
      "Epoch: 56, step: 300/390, loss: 4.128668308258057\n",
      "Epoch: 56, step: 350/390, loss: 4.122603416442871\n",
      "Epoch: 56 completed, average loss: 4.131174733699896, time taken: 0.9481040557225545 mins\n",
      "Epoch: 57, step: 50/390, loss: 4.148905277252197\n",
      "Epoch: 57, step: 100/390, loss: 4.16014289855957\n",
      "Epoch: 57, step: 150/390, loss: 4.08035945892334\n",
      "Epoch: 57, step: 200/390, loss: 4.104180335998535\n",
      "Epoch: 57, step: 250/390, loss: 4.112277030944824\n",
      "Epoch: 57, step: 300/390, loss: 4.152058124542236\n",
      "Epoch: 57, step: 350/390, loss: 4.120716571807861\n",
      "Epoch: 57 completed, average loss: 4.1267281043223845, time taken: 0.9736664930979411 mins\n",
      "Epoch: 58, step: 50/390, loss: 4.1793084144592285\n",
      "Epoch: 58, step: 100/390, loss: 4.168908596038818\n",
      "Epoch: 58, step: 150/390, loss: 4.104461193084717\n",
      "Epoch: 58, step: 200/390, loss: 4.205812454223633\n",
      "Epoch: 58, step: 250/390, loss: 4.082683086395264\n",
      "Epoch: 58, step: 300/390, loss: 4.139416217803955\n",
      "Epoch: 58, step: 350/390, loss: 4.12622594833374\n",
      "Epoch: 58 completed, average loss: 4.126202731254773, time taken: 0.9276367545127868 mins\n",
      "Epoch: 59, step: 50/390, loss: 4.135818004608154\n",
      "Epoch: 59, step: 100/390, loss: 4.109707832336426\n",
      "Epoch: 59, step: 150/390, loss: 4.134215831756592\n",
      "Epoch: 59, step: 200/390, loss: 4.150934219360352\n",
      "Epoch: 59, step: 250/390, loss: 4.082009315490723\n",
      "Epoch: 59, step: 300/390, loss: 4.150310516357422\n",
      "Epoch: 59, step: 350/390, loss: 4.191514492034912\n",
      "Epoch: 59 completed, average loss: 4.123013669405228, time taken: 0.9781818072001139 mins\n",
      "Epoch: 60, step: 50/390, loss: 4.139358997344971\n",
      "Epoch: 60, step: 100/390, loss: 4.090030670166016\n",
      "Epoch: 60, step: 150/390, loss: 4.063905239105225\n",
      "Epoch: 60, step: 200/390, loss: 4.240191459655762\n",
      "Epoch: 60, step: 250/390, loss: 4.048194885253906\n",
      "Epoch: 60, step: 300/390, loss: 4.034054756164551\n",
      "Epoch: 60, step: 350/390, loss: 4.067843437194824\n",
      "Epoch: 60 completed, average loss: 4.1208020112453365, time taken: 0.9516109387079875 mins\n",
      "Epoch: 61, step: 50/390, loss: 4.178344249725342\n",
      "Epoch: 61, step: 100/390, loss: 4.098581314086914\n",
      "Epoch: 61, step: 150/390, loss: 4.084423065185547\n",
      "Epoch: 61, step: 200/390, loss: 4.064830780029297\n",
      "Epoch: 61, step: 250/390, loss: 4.087402820587158\n",
      "Epoch: 61, step: 300/390, loss: 4.079363822937012\n",
      "Epoch: 61, step: 350/390, loss: 4.080112934112549\n",
      "Epoch: 61 completed, average loss: 4.121260596544315, time taken: 0.9693842132886251 mins\n",
      "Epoch: 62, step: 50/390, loss: 4.0981316566467285\n",
      "Epoch: 62, step: 100/390, loss: 4.202935695648193\n",
      "Epoch: 62, step: 150/390, loss: 4.127013683319092\n",
      "Epoch: 62, step: 200/390, loss: 4.086853981018066\n",
      "Epoch: 62, step: 250/390, loss: 4.085507869720459\n",
      "Epoch: 62, step: 300/390, loss: 4.091782569885254\n",
      "Epoch: 62, step: 350/390, loss: 4.133487224578857\n",
      "Epoch: 62 completed, average loss: 4.118322662206796, time taken: 0.9546306848526 mins\n",
      "Epoch: 63, step: 50/390, loss: 4.075695991516113\n",
      "Epoch: 63, step: 100/390, loss: 4.1693806648254395\n",
      "Epoch: 63, step: 150/390, loss: 4.113035202026367\n",
      "Epoch: 63, step: 200/390, loss: 4.070024013519287\n",
      "Epoch: 63, step: 250/390, loss: 4.036393165588379\n",
      "Epoch: 63, step: 300/390, loss: 4.095622539520264\n",
      "Epoch: 63, step: 350/390, loss: 4.116399765014648\n",
      "Epoch: 63 completed, average loss: 4.11498277982076, time taken: 0.9715116381645202 mins\n",
      "Epoch: 64, step: 50/390, loss: 4.086887359619141\n",
      "Epoch: 64, step: 100/390, loss: 4.134451389312744\n",
      "Epoch: 64, step: 150/390, loss: 4.087597846984863\n",
      "Epoch: 64, step: 200/390, loss: 4.038917541503906\n",
      "Epoch: 64, step: 250/390, loss: 4.096874713897705\n",
      "Epoch: 64, step: 300/390, loss: 4.067706108093262\n",
      "Epoch: 64, step: 350/390, loss: 4.078327655792236\n",
      "Epoch: 64 completed, average loss: 4.11821904426966, time taken: 0.9259239832560221 mins\n",
      "Epoch: 65, step: 50/390, loss: 4.1031107902526855\n",
      "Epoch: 65, step: 100/390, loss: 4.135753631591797\n",
      "Epoch: 65, step: 150/390, loss: 4.106479644775391\n",
      "Epoch: 65, step: 200/390, loss: 4.120009899139404\n",
      "Epoch: 65, step: 250/390, loss: 4.079352855682373\n",
      "Epoch: 65, step: 300/390, loss: 4.04408597946167\n",
      "Epoch: 65, step: 350/390, loss: 4.0856242179870605\n",
      "Epoch: 65 completed, average loss: 4.112791053454081, time taken: 0.9538821657498677 mins\n",
      "Epoch: 66, step: 50/390, loss: 4.202390670776367\n",
      "Epoch: 66, step: 100/390, loss: 4.108887195587158\n",
      "Epoch: 66, step: 150/390, loss: 4.1179022789001465\n",
      "Epoch: 66, step: 200/390, loss: 4.144749164581299\n",
      "Epoch: 66, step: 250/390, loss: 4.14208459854126\n",
      "Epoch: 66, step: 300/390, loss: 4.210509300231934\n",
      "Epoch: 66, step: 350/390, loss: 4.198808670043945\n",
      "Epoch: 66 completed, average loss: 4.113885455865127, time taken: 0.9442874431610108 mins\n",
      "Epoch: 67, step: 50/390, loss: 4.136404037475586\n",
      "Epoch: 67, step: 100/390, loss: 4.107646942138672\n",
      "Epoch: 67, step: 150/390, loss: 3.9784038066864014\n",
      "Epoch: 67, step: 200/390, loss: 4.13095760345459\n",
      "Epoch: 67, step: 250/390, loss: 4.10441255569458\n",
      "Epoch: 67, step: 300/390, loss: 4.157890796661377\n",
      "Epoch: 67, step: 350/390, loss: 4.084558010101318\n",
      "Epoch: 67 completed, average loss: 4.112244078440544, time taken: 0.9410672465960185 mins\n",
      "Epoch: 68, step: 50/390, loss: 4.083353042602539\n",
      "Epoch: 68, step: 100/390, loss: 4.135092735290527\n",
      "Epoch: 68, step: 150/390, loss: 4.061066150665283\n",
      "Epoch: 68, step: 200/390, loss: 4.084255218505859\n",
      "Epoch: 68, step: 250/390, loss: 4.072476387023926\n",
      "Epoch: 68, step: 300/390, loss: 4.162859916687012\n",
      "Epoch: 68, step: 350/390, loss: 4.114443778991699\n",
      "Epoch: 68 completed, average loss: 4.109575204360179, time taken: 0.9359140237172444 mins\n",
      "Epoch: 69, step: 50/390, loss: 4.064020156860352\n",
      "Epoch: 69, step: 100/390, loss: 4.079619407653809\n",
      "Epoch: 69, step: 150/390, loss: 4.169703483581543\n",
      "Epoch: 69, step: 200/390, loss: 4.137821197509766\n",
      "Epoch: 69, step: 250/390, loss: 4.1337761878967285\n",
      "Epoch: 69, step: 300/390, loss: 4.069851875305176\n",
      "Epoch: 69, step: 350/390, loss: 4.134583473205566\n",
      "Epoch: 69 completed, average loss: 4.110865226158729, time taken: 0.9379133065541585 mins\n",
      "Epoch: 70, step: 50/390, loss: 4.158259391784668\n",
      "Epoch: 70, step: 100/390, loss: 4.16908597946167\n",
      "Epoch: 70, step: 150/390, loss: 4.1578898429870605\n",
      "Epoch: 70, step: 200/390, loss: 4.1135640144348145\n",
      "Epoch: 70, step: 250/390, loss: 4.106649875640869\n",
      "Epoch: 70, step: 300/390, loss: 4.065030574798584\n",
      "Epoch: 70, step: 350/390, loss: 4.12058162689209\n",
      "Epoch: 70 completed, average loss: 4.104790021211673, time taken: 0.9517793973286947 mins\n",
      "Epoch: 71, step: 50/390, loss: 4.076100826263428\n",
      "Epoch: 71, step: 100/390, loss: 4.100386619567871\n",
      "Epoch: 71, step: 150/390, loss: 4.11072301864624\n",
      "Epoch: 71, step: 200/390, loss: 4.115230560302734\n",
      "Epoch: 71, step: 250/390, loss: 4.09622049331665\n",
      "Epoch: 71, step: 300/390, loss: 4.164205074310303\n",
      "Epoch: 71, step: 350/390, loss: 4.107607841491699\n",
      "Epoch: 71 completed, average loss: 4.103607517633683, time taken: 0.9375178456306458 mins\n",
      "Epoch: 72, step: 50/390, loss: 4.105681419372559\n",
      "Epoch: 72, step: 100/390, loss: 4.094722747802734\n",
      "Epoch: 72, step: 150/390, loss: 4.11539888381958\n",
      "Epoch: 72, step: 200/390, loss: 4.156014442443848\n",
      "Epoch: 72, step: 250/390, loss: 4.090153694152832\n",
      "Epoch: 72, step: 300/390, loss: 4.144083499908447\n",
      "Epoch: 72, step: 350/390, loss: 4.057190895080566\n",
      "Epoch: 72 completed, average loss: 4.1047259440788855, time taken: 0.9688843528429667 mins\n",
      "Epoch: 73, step: 50/390, loss: 4.167089462280273\n",
      "Epoch: 73, step: 100/390, loss: 4.099403381347656\n",
      "Epoch: 73, step: 150/390, loss: 4.165525913238525\n",
      "Epoch: 73, step: 200/390, loss: 4.048805236816406\n",
      "Epoch: 73, step: 250/390, loss: 4.172482013702393\n",
      "Epoch: 73, step: 300/390, loss: 4.121214866638184\n",
      "Epoch: 73, step: 350/390, loss: 4.144997596740723\n",
      "Epoch: 73 completed, average loss: 4.1048250149457886, time taken: 0.9615777929623922 mins\n",
      "Epoch: 74, step: 50/390, loss: 4.109196186065674\n",
      "Epoch: 74, step: 100/390, loss: 4.09207820892334\n",
      "Epoch: 74, step: 150/390, loss: 4.151622772216797\n",
      "Epoch: 74, step: 200/390, loss: 4.106025695800781\n",
      "Epoch: 74, step: 250/390, loss: 4.110166549682617\n",
      "Epoch: 74, step: 300/390, loss: 4.164572715759277\n",
      "Epoch: 74, step: 350/390, loss: 4.0556135177612305\n",
      "Epoch: 74 completed, average loss: 4.099374183019003, time taken: 0.9225960969924927 mins\n",
      "Epoch: 75, step: 50/390, loss: 4.119184970855713\n",
      "Epoch: 75, step: 100/390, loss: 4.078314781188965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75, step: 150/390, loss: 4.026205062866211\n",
      "Epoch: 75, step: 200/390, loss: 4.151582717895508\n",
      "Epoch: 75, step: 250/390, loss: 4.130720138549805\n",
      "Epoch: 75, step: 300/390, loss: 4.182042598724365\n",
      "Epoch: 75, step: 350/390, loss: 4.0890326499938965\n",
      "Epoch: 75 completed, average loss: 4.099539260986524, time taken: 0.9153995434443156 mins\n",
      "Epoch: 76, step: 50/390, loss: 4.092307090759277\n",
      "Epoch: 76, step: 100/390, loss: 4.095676422119141\n",
      "Epoch: 76, step: 150/390, loss: 4.077334403991699\n",
      "Epoch: 76, step: 200/390, loss: 4.072711944580078\n",
      "Epoch: 76, step: 250/390, loss: 4.112860679626465\n",
      "Epoch: 76, step: 300/390, loss: 4.087353229522705\n",
      "Epoch: 76, step: 350/390, loss: 4.145196437835693\n",
      "Epoch: 76 completed, average loss: 4.092668635417254, time taken: 0.9559266328811645 mins\n",
      "Epoch: 77, step: 50/390, loss: 4.1251606941223145\n",
      "Epoch: 77, step: 100/390, loss: 4.06082010269165\n",
      "Epoch: 77, step: 150/390, loss: 4.075681686401367\n",
      "Epoch: 77, step: 200/390, loss: 4.113114356994629\n",
      "Epoch: 77, step: 250/390, loss: 4.071940898895264\n",
      "Epoch: 77, step: 300/390, loss: 4.0967793464660645\n",
      "Epoch: 77, step: 350/390, loss: 4.091695785522461\n",
      "Epoch: 77 completed, average loss: 4.098446562351325, time taken: 0.9616742293039958 mins\n",
      "Epoch: 78, step: 50/390, loss: 4.050939559936523\n",
      "Epoch: 78, step: 100/390, loss: 4.1089372634887695\n",
      "Epoch: 78, step: 150/390, loss: 4.144599914550781\n",
      "Epoch: 78, step: 200/390, loss: 4.031761169433594\n",
      "Epoch: 78, step: 250/390, loss: 4.132325649261475\n",
      "Epoch: 78, step: 300/390, loss: 4.08601713180542\n",
      "Epoch: 78, step: 350/390, loss: 4.068431854248047\n",
      "Epoch: 78 completed, average loss: 4.092657344157879, time taken: 0.9420791943868001 mins\n",
      "Epoch: 79, step: 50/390, loss: 4.076626300811768\n",
      "Epoch: 79, step: 100/390, loss: 4.121907711029053\n",
      "Epoch: 79, step: 150/390, loss: 4.049324989318848\n",
      "Epoch: 79, step: 200/390, loss: 4.085867404937744\n",
      "Epoch: 79, step: 250/390, loss: 4.0644073486328125\n",
      "Epoch: 79, step: 300/390, loss: 4.140158653259277\n",
      "Epoch: 79, step: 350/390, loss: 4.066407203674316\n",
      "Epoch: 79 completed, average loss: 4.0936743626227745, time taken: 0.9313031077384949 mins\n",
      "Epoch: 80, step: 50/390, loss: 4.125338554382324\n",
      "Epoch: 80, step: 100/390, loss: 4.107427597045898\n",
      "Epoch: 80, step: 150/390, loss: 4.1152849197387695\n",
      "Epoch: 80, step: 200/390, loss: 4.113417148590088\n",
      "Epoch: 80, step: 250/390, loss: 4.108422756195068\n",
      "Epoch: 80, step: 300/390, loss: 4.060317516326904\n",
      "Epoch: 80, step: 350/390, loss: 4.091137886047363\n",
      "Epoch: 80 completed, average loss: 4.090029353973193, time taken: 0.9576317032178243 mins\n",
      "Epoch: 81, step: 50/390, loss: 4.150439739227295\n",
      "Epoch: 81, step: 100/390, loss: 4.1030802726745605\n",
      "Epoch: 81, step: 150/390, loss: 4.116535663604736\n",
      "Epoch: 81, step: 200/390, loss: 4.062624454498291\n",
      "Epoch: 81, step: 250/390, loss: 4.07319974899292\n",
      "Epoch: 81, step: 300/390, loss: 4.055315971374512\n",
      "Epoch: 81, step: 350/390, loss: 4.054609775543213\n",
      "Epoch: 81 completed, average loss: 4.0941466893905245, time taken: 0.9418886423110961 mins\n",
      "Epoch: 82, step: 50/390, loss: 4.097917079925537\n",
      "Epoch: 82, step: 100/390, loss: 4.11167049407959\n",
      "Epoch: 82, step: 150/390, loss: 4.11564826965332\n",
      "Epoch: 82, step: 200/390, loss: 4.087019443511963\n",
      "Epoch: 82, step: 250/390, loss: 4.092667102813721\n",
      "Epoch: 82, step: 300/390, loss: 4.152737617492676\n",
      "Epoch: 82, step: 350/390, loss: 4.063520908355713\n",
      "Epoch: 82 completed, average loss: 4.091845997785911, time taken: 0.9563457369804382 mins\n",
      "Epoch: 83, step: 50/390, loss: 4.103894233703613\n",
      "Epoch: 83, step: 100/390, loss: 4.090541362762451\n",
      "Epoch: 83, step: 150/390, loss: 4.053922176361084\n",
      "Epoch: 83, step: 200/390, loss: 4.062664031982422\n",
      "Epoch: 83, step: 250/390, loss: 4.127143859863281\n",
      "Epoch: 83, step: 300/390, loss: 4.089329242706299\n",
      "Epoch: 83, step: 350/390, loss: 4.135922431945801\n",
      "Epoch: 83 completed, average loss: 4.087964725494385, time taken: 0.9363391598065695 mins\n",
      "Epoch: 84, step: 50/390, loss: 4.056303024291992\n",
      "Epoch: 84, step: 100/390, loss: 4.079404830932617\n",
      "Epoch: 84, step: 150/390, loss: 4.033576965332031\n",
      "Epoch: 84, step: 200/390, loss: 3.9812302589416504\n",
      "Epoch: 84, step: 250/390, loss: 4.023623466491699\n",
      "Epoch: 84, step: 300/390, loss: 4.039764881134033\n",
      "Epoch: 84, step: 350/390, loss: 4.029660224914551\n",
      "Epoch: 84 completed, average loss: 4.0886297788375465, time taken: 0.9402652462323506 mins\n",
      "Epoch: 85, step: 50/390, loss: 4.1071271896362305\n",
      "Epoch: 85, step: 100/390, loss: 4.147895812988281\n",
      "Epoch: 85, step: 150/390, loss: 4.109097003936768\n",
      "Epoch: 85, step: 200/390, loss: 4.063596248626709\n",
      "Epoch: 85, step: 250/390, loss: 3.993182897567749\n",
      "Epoch: 85, step: 300/390, loss: 4.051746368408203\n",
      "Epoch: 85, step: 350/390, loss: 4.13108491897583\n",
      "Epoch: 85 completed, average loss: 4.091961488968287, time taken: 0.9404977003733317 mins\n",
      "Epoch: 86, step: 50/390, loss: 4.089913845062256\n",
      "Epoch: 86, step: 100/390, loss: 4.034168243408203\n",
      "Epoch: 86, step: 150/390, loss: 4.053260803222656\n",
      "Epoch: 86, step: 200/390, loss: 4.004741191864014\n",
      "Epoch: 86, step: 250/390, loss: 4.0323028564453125\n",
      "Epoch: 86, step: 300/390, loss: 4.066145420074463\n",
      "Epoch: 86, step: 350/390, loss: 4.13941764831543\n",
      "Epoch: 86 completed, average loss: 4.0879180816503675, time taken: 0.9583770116170247 mins\n",
      "Epoch: 87, step: 50/390, loss: 4.061339378356934\n",
      "Epoch: 87, step: 100/390, loss: 4.0815019607543945\n",
      "Epoch: 87, step: 150/390, loss: 4.157570838928223\n",
      "Epoch: 87, step: 200/390, loss: 4.06593132019043\n",
      "Epoch: 87, step: 250/390, loss: 4.119529724121094\n",
      "Epoch: 87, step: 300/390, loss: 4.085824966430664\n",
      "Epoch: 87, step: 350/390, loss: 4.085967540740967\n",
      "Epoch: 87 completed, average loss: 4.084918303367419, time taken: 0.9645610690116883 mins\n",
      "Epoch: 88, step: 50/390, loss: 4.021154403686523\n",
      "Epoch: 88, step: 100/390, loss: 4.141300678253174\n",
      "Epoch: 88, step: 150/390, loss: 4.048448085784912\n",
      "Epoch: 88, step: 200/390, loss: 4.083360195159912\n",
      "Epoch: 88, step: 250/390, loss: 3.993508815765381\n",
      "Epoch: 88, step: 300/390, loss: 4.051289081573486\n",
      "Epoch: 88, step: 350/390, loss: 4.0356974601745605\n",
      "Epoch: 88 completed, average loss: 4.083545761841994, time taken: 0.9353332638740539 mins\n",
      "Epoch: 89, step: 50/390, loss: 4.102222919464111\n",
      "Epoch: 89, step: 100/390, loss: 4.019409656524658\n",
      "Epoch: 89, step: 150/390, loss: 4.076827049255371\n",
      "Epoch: 89, step: 200/390, loss: 4.075109481811523\n",
      "Epoch: 89, step: 250/390, loss: 4.073188781738281\n",
      "Epoch: 89, step: 300/390, loss: 4.0954508781433105\n",
      "Epoch: 89, step: 350/390, loss: 4.09326171875\n",
      "Epoch: 89 completed, average loss: 4.084640303024879, time taken: 0.987885570526123 mins\n",
      "Epoch: 90, step: 50/390, loss: 4.0786051750183105\n",
      "Epoch: 90, step: 100/390, loss: 4.107027053833008\n",
      "Epoch: 90, step: 150/390, loss: 4.041064262390137\n",
      "Epoch: 90, step: 200/390, loss: 4.135415554046631\n",
      "Epoch: 90, step: 250/390, loss: 4.0681586265563965\n",
      "Epoch: 90, step: 300/390, loss: 4.063676357269287\n",
      "Epoch: 90, step: 350/390, loss: 4.074821949005127\n",
      "Epoch: 90 completed, average loss: 4.084117079392458, time taken: 0.9693760553995768 mins\n",
      "Epoch: 91, step: 50/390, loss: 4.083003997802734\n",
      "Epoch: 91, step: 100/390, loss: 4.09567928314209\n",
      "Epoch: 91, step: 150/390, loss: 4.055205821990967\n",
      "Epoch: 91, step: 200/390, loss: 4.078257083892822\n",
      "Epoch: 91, step: 250/390, loss: 4.076884746551514\n",
      "Epoch: 91, step: 300/390, loss: 4.115089416503906\n",
      "Epoch: 91, step: 350/390, loss: 4.015933513641357\n",
      "Epoch: 91 completed, average loss: 4.081632769413483, time taken: 0.9547543168067932 mins\n",
      "Epoch: 92, step: 50/390, loss: 4.08249568939209\n",
      "Epoch: 92, step: 100/390, loss: 4.162118434906006\n",
      "Epoch: 92, step: 150/390, loss: 4.030879497528076\n",
      "Epoch: 92, step: 200/390, loss: 4.068545818328857\n",
      "Epoch: 92, step: 250/390, loss: 4.074679374694824\n",
      "Epoch: 92, step: 300/390, loss: 4.055522918701172\n",
      "Epoch: 92, step: 350/390, loss: 4.1755146980285645\n",
      "Epoch: 92 completed, average loss: 4.07984439776494, time taken: 0.9612534801165263 mins\n",
      "Epoch: 93, step: 50/390, loss: 4.089203834533691\n",
      "Epoch: 93, step: 100/390, loss: 4.090646743774414\n",
      "Epoch: 93, step: 150/390, loss: 4.007428169250488\n",
      "Epoch: 93, step: 200/390, loss: 4.138332366943359\n",
      "Epoch: 93, step: 250/390, loss: 4.212996959686279\n",
      "Epoch: 93, step: 300/390, loss: 4.041937351226807\n",
      "Epoch: 93, step: 350/390, loss: 4.126255035400391\n",
      "Epoch: 93 completed, average loss: 4.0828093333122055, time taken: 0.9407881657282512 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94, step: 50/390, loss: 4.140028953552246\n",
      "Epoch: 94, step: 100/390, loss: 4.065598487854004\n",
      "Epoch: 94, step: 150/390, loss: 4.128742218017578\n",
      "Epoch: 94, step: 200/390, loss: 4.101351261138916\n",
      "Epoch: 94, step: 250/390, loss: 4.048216342926025\n",
      "Epoch: 94, step: 300/390, loss: 4.117559909820557\n",
      "Epoch: 94, step: 350/390, loss: 4.046790599822998\n",
      "Epoch: 94 completed, average loss: 4.076703632794894, time taken: 0.9464420040448507 mins\n",
      "Epoch: 95, step: 50/390, loss: 4.023066520690918\n",
      "Epoch: 95, step: 100/390, loss: 4.097072124481201\n",
      "Epoch: 95, step: 150/390, loss: 4.046652317047119\n",
      "Epoch: 95, step: 200/390, loss: 4.025625228881836\n",
      "Epoch: 95, step: 250/390, loss: 4.046693801879883\n",
      "Epoch: 95, step: 300/390, loss: 4.076125621795654\n",
      "Epoch: 95, step: 350/390, loss: 4.094606876373291\n",
      "Epoch: 95 completed, average loss: 4.075824690476442, time taken: 0.9436774969100952 mins\n",
      "Epoch: 96, step: 50/390, loss: 4.0668768882751465\n",
      "Epoch: 96, step: 100/390, loss: 4.114541530609131\n",
      "Epoch: 96, step: 150/390, loss: 4.015188694000244\n",
      "Epoch: 96, step: 200/390, loss: 4.105757713317871\n",
      "Epoch: 96, step: 250/390, loss: 4.138119220733643\n",
      "Epoch: 96, step: 300/390, loss: 4.075400352478027\n",
      "Epoch: 96, step: 350/390, loss: 4.020852088928223\n",
      "Epoch: 96 completed, average loss: 4.077481279617701, time taken: 0.9690410494804382 mins\n",
      "Epoch: 97, step: 50/390, loss: 4.060894966125488\n",
      "Epoch: 97, step: 100/390, loss: 4.004445552825928\n",
      "Epoch: 97, step: 150/390, loss: 4.021990776062012\n",
      "Epoch: 97, step: 200/390, loss: 4.064247131347656\n",
      "Epoch: 97, step: 250/390, loss: 4.073286533355713\n",
      "Epoch: 97, step: 300/390, loss: 4.081127166748047\n",
      "Epoch: 97, step: 350/390, loss: 4.063448905944824\n",
      "Epoch: 97 completed, average loss: 4.073049748860873, time taken: 0.927834419409434 mins\n",
      "Epoch: 98, step: 50/390, loss: 4.036177158355713\n",
      "Epoch: 98, step: 100/390, loss: 4.080540180206299\n",
      "Epoch: 98, step: 150/390, loss: 4.069962978363037\n",
      "Epoch: 98, step: 200/390, loss: 4.145665168762207\n",
      "Epoch: 98, step: 250/390, loss: 4.011308193206787\n",
      "Epoch: 98, step: 300/390, loss: 4.097780704498291\n",
      "Epoch: 98, step: 350/390, loss: 4.122869968414307\n",
      "Epoch: 98 completed, average loss: 4.07095326093527, time taken: 0.9398197054862976 mins\n",
      "Epoch: 99, step: 50/390, loss: 3.9978208541870117\n",
      "Epoch: 99, step: 100/390, loss: 4.0143890380859375\n",
      "Epoch: 99, step: 150/390, loss: 4.104569435119629\n",
      "Epoch: 99, step: 200/390, loss: 4.074904918670654\n",
      "Epoch: 99, step: 250/390, loss: 4.069139003753662\n",
      "Epoch: 99, step: 300/390, loss: 4.136653900146484\n",
      "Epoch: 99, step: 350/390, loss: 4.042323589324951\n",
      "Epoch: 99 completed, average loss: 4.073775318952707, time taken: 0.9395120938618978 mins\n"
     ]
    }
   ],
   "source": [
    "proj_dim = 64\n",
    "model = SimClr('resnet50',proj_dim).cuda()\n",
    "temperature = 0.5\n",
    "#criterion = nt_xent_loss\n",
    "criterion = SimCLR_Loss(128,0.5)\n",
    "optimizer = \"Adam\"\n",
    "model, train_loss = train_simclr(train_loader_simclr,model,criterion,optimizer,100,128,True,\"/home/ky2446/saved-models/CIFAR10-RES50-SIMCLR-BS128-PD64-ADAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3514975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"NT-XENT Loss\")\n",
    "plt.title(\"CIFAR10 ResNet-50 SimClr BS:128,PD:64, OP: Adam\")\n",
    "plt.plot(train_loss)\n",
    "plt.savefig(\"/home/ky2446/figures/CIFAR10-RES50-SIMCLR-BS128-PD64-ADAM.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "481f44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/ky2446/training-logs/CIFAR10-RES50-BS128-PD64-ADAM\", \"wb\") as fp:   #Pickling\n",
    "  pickle.dump(train_loss, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce1d096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
