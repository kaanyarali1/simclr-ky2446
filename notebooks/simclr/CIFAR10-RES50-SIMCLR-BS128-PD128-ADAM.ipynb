{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d37e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# setting path\n",
    "sys.path.append(\"/home/ky2446/simclr\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/layers\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/models\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/loss\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/optim\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/dataloader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00cb535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simclrpy import SimClr\n",
    "from ntxent import nt_xent_loss\n",
    "from ntxentgit import SimCLR_Loss\n",
    "from augment import TransformsSimCLR\n",
    "from utils import *\n",
    "from LARS import LARS\n",
    "from downstream import DownStream\n",
    "from dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec01285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fcd2851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader_simclr = train_loader_simclr(\"CIFAR10\",128)\n",
    "test_loader = test_loader(\"CIFAR10\",128)\n",
    "test_images, test_labels = get_testimgs_list(\"CIFAR10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5cad178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, step: 50/390, loss: 5.5414862632751465\n",
      "Epoch: 0, step: 100/390, loss: 5.371105194091797\n",
      "Epoch: 0, step: 150/390, loss: 5.318394184112549\n",
      "Epoch: 0, step: 200/390, loss: 5.381066799163818\n",
      "Epoch: 0, step: 250/390, loss: 5.262279033660889\n",
      "Epoch: 0, step: 300/390, loss: 5.220109462738037\n",
      "Epoch: 0, step: 350/390, loss: 5.196467876434326\n",
      "Epoch: 0 completed, average loss: 5.34846875606439, time taken: 0.9870331168174744 mins\n",
      "Epoch: 1, step: 50/390, loss: 5.284117221832275\n",
      "Epoch: 1, step: 100/390, loss: 5.246016502380371\n",
      "Epoch: 1, step: 150/390, loss: 5.141538143157959\n",
      "Epoch: 1, step: 200/390, loss: 5.164479732513428\n",
      "Epoch: 1, step: 250/390, loss: 5.079343318939209\n",
      "Epoch: 1, step: 300/390, loss: 5.178979873657227\n",
      "Epoch: 1, step: 350/390, loss: 5.118096351623535\n",
      "Epoch: 1 completed, average loss: 5.123054549632928, time taken: 0.951126758257548 mins\n",
      "Epoch: 2, step: 50/390, loss: 5.077322006225586\n",
      "Epoch: 2, step: 100/390, loss: 5.025410175323486\n",
      "Epoch: 2, step: 150/390, loss: 4.947624683380127\n",
      "Epoch: 2, step: 200/390, loss: 4.991295337677002\n",
      "Epoch: 2, step: 250/390, loss: 4.900151252746582\n",
      "Epoch: 2, step: 300/390, loss: 4.815151691436768\n",
      "Epoch: 2, step: 350/390, loss: 4.8397216796875\n",
      "Epoch: 2 completed, average loss: 4.947563827954806, time taken: 0.9575389782587688 mins\n",
      "Epoch: 3, step: 50/390, loss: 4.799567222595215\n",
      "Epoch: 3, step: 100/390, loss: 4.702054977416992\n",
      "Epoch: 3, step: 150/390, loss: 4.790186882019043\n",
      "Epoch: 3, step: 200/390, loss: 4.665197849273682\n",
      "Epoch: 3, step: 250/390, loss: 4.694301605224609\n",
      "Epoch: 3, step: 300/390, loss: 4.6990156173706055\n",
      "Epoch: 3, step: 350/390, loss: 4.608032703399658\n",
      "Epoch: 3 completed, average loss: 4.697364868261875, time taken: 0.9597801566123962 mins\n",
      "Epoch: 4, step: 50/390, loss: 4.701630115509033\n",
      "Epoch: 4, step: 100/390, loss: 4.6329522132873535\n",
      "Epoch: 4, step: 150/390, loss: 4.5953569412231445\n",
      "Epoch: 4, step: 200/390, loss: 4.6493706703186035\n",
      "Epoch: 4, step: 250/390, loss: 4.674173355102539\n",
      "Epoch: 4, step: 300/390, loss: 4.589487552642822\n",
      "Epoch: 4, step: 350/390, loss: 4.509423732757568\n",
      "Epoch: 4 completed, average loss: 4.604848729647123, time taken: 0.9697056770324707 mins\n",
      "Epoch: 5, step: 50/390, loss: 4.606378555297852\n",
      "Epoch: 5, step: 100/390, loss: 4.563136577606201\n",
      "Epoch: 5, step: 150/390, loss: 4.512136459350586\n",
      "Epoch: 5, step: 200/390, loss: 4.493958950042725\n",
      "Epoch: 5, step: 250/390, loss: 4.549200534820557\n",
      "Epoch: 5, step: 300/390, loss: 4.555805683135986\n",
      "Epoch: 5, step: 350/390, loss: 4.515902996063232\n",
      "Epoch: 5 completed, average loss: 4.55222556407635, time taken: 0.95286678870519 mins\n",
      "Epoch: 6, step: 50/390, loss: 4.572412014007568\n",
      "Epoch: 6, step: 100/390, loss: 4.606318950653076\n",
      "Epoch: 6, step: 150/390, loss: 4.514082908630371\n",
      "Epoch: 6, step: 200/390, loss: 4.499112129211426\n",
      "Epoch: 6, step: 250/390, loss: 4.531177997589111\n",
      "Epoch: 6, step: 300/390, loss: 4.549072265625\n",
      "Epoch: 6, step: 350/390, loss: 4.461330890655518\n",
      "Epoch: 6 completed, average loss: 4.504702264834673, time taken: 0.9902867794036865 mins\n",
      "Epoch: 7, step: 50/390, loss: 4.394497871398926\n",
      "Epoch: 7, step: 100/390, loss: 4.554698944091797\n",
      "Epoch: 7, step: 150/390, loss: 4.52004337310791\n",
      "Epoch: 7, step: 200/390, loss: 4.548115253448486\n",
      "Epoch: 7, step: 250/390, loss: 4.435166358947754\n",
      "Epoch: 7, step: 300/390, loss: 4.464866638183594\n",
      "Epoch: 7, step: 350/390, loss: 4.421727180480957\n",
      "Epoch: 7 completed, average loss: 4.458831474108574, time taken: 0.9815312385559082 mins\n",
      "Epoch: 8, step: 50/390, loss: 4.494613170623779\n",
      "Epoch: 8, step: 100/390, loss: 4.48476505279541\n",
      "Epoch: 8, step: 150/390, loss: 4.402466773986816\n",
      "Epoch: 8, step: 200/390, loss: 4.359216690063477\n",
      "Epoch: 8, step: 250/390, loss: 4.39024019241333\n",
      "Epoch: 8, step: 300/390, loss: 4.410972595214844\n",
      "Epoch: 8, step: 350/390, loss: 4.425506591796875\n",
      "Epoch: 8 completed, average loss: 4.430428374119294, time taken: 0.9568591992060343 mins\n",
      "Epoch: 9, step: 50/390, loss: 4.365774631500244\n",
      "Epoch: 9, step: 100/390, loss: 4.404294490814209\n",
      "Epoch: 9, step: 150/390, loss: 4.317472457885742\n",
      "Epoch: 9, step: 200/390, loss: 4.43095588684082\n",
      "Epoch: 9, step: 250/390, loss: 4.408891677856445\n",
      "Epoch: 9, step: 300/390, loss: 4.312527656555176\n",
      "Epoch: 9, step: 350/390, loss: 4.391406059265137\n",
      "Epoch: 9 completed, average loss: 4.392001163042509, time taken: 0.9757952292760214 mins\n",
      "Epoch: 10, step: 50/390, loss: 4.386119842529297\n",
      "Epoch: 10, step: 100/390, loss: 4.323120594024658\n",
      "Epoch: 10, step: 150/390, loss: 4.391035556793213\n",
      "Epoch: 10, step: 200/390, loss: 4.390627861022949\n",
      "Epoch: 10, step: 250/390, loss: 4.4347944259643555\n",
      "Epoch: 10, step: 300/390, loss: 4.350399017333984\n",
      "Epoch: 10, step: 350/390, loss: 4.296088695526123\n",
      "Epoch: 10 completed, average loss: 4.367097764137464, time taken: 0.9865824540456136 mins\n",
      "Epoch: 11, step: 50/390, loss: 4.383263111114502\n",
      "Epoch: 11, step: 100/390, loss: 4.364121437072754\n",
      "Epoch: 11, step: 150/390, loss: 4.345621109008789\n",
      "Epoch: 11, step: 200/390, loss: 4.327195167541504\n",
      "Epoch: 11, step: 250/390, loss: 4.331887245178223\n",
      "Epoch: 11, step: 300/390, loss: 4.314703941345215\n",
      "Epoch: 11, step: 350/390, loss: 4.372031211853027\n",
      "Epoch: 11 completed, average loss: 4.34646899149968, time taken: 0.9507065614064535 mins\n",
      "Epoch: 12, step: 50/390, loss: 4.366281509399414\n",
      "Epoch: 12, step: 100/390, loss: 4.3226094245910645\n",
      "Epoch: 12, step: 150/390, loss: 4.288608074188232\n",
      "Epoch: 12, step: 200/390, loss: 4.3348212242126465\n",
      "Epoch: 12, step: 250/390, loss: 4.297730922698975\n",
      "Epoch: 12, step: 300/390, loss: 4.2714033126831055\n",
      "Epoch: 12, step: 350/390, loss: 4.283066272735596\n",
      "Epoch: 12 completed, average loss: 4.326803356561905, time taken: 0.959914747873942 mins\n",
      "Epoch: 13, step: 50/390, loss: 4.286518573760986\n",
      "Epoch: 13, step: 100/390, loss: 4.379530429840088\n",
      "Epoch: 13, step: 150/390, loss: 4.284949779510498\n",
      "Epoch: 13, step: 200/390, loss: 4.298254013061523\n",
      "Epoch: 13, step: 250/390, loss: 4.319102764129639\n",
      "Epoch: 13, step: 300/390, loss: 4.306041717529297\n",
      "Epoch: 13, step: 350/390, loss: 4.269976615905762\n",
      "Epoch: 13 completed, average loss: 4.31526093849769, time taken: 0.9456753730773926 mins\n",
      "Epoch: 14, step: 50/390, loss: 4.286560535430908\n",
      "Epoch: 14, step: 100/390, loss: 4.299847602844238\n",
      "Epoch: 14, step: 150/390, loss: 4.274563789367676\n",
      "Epoch: 14, step: 200/390, loss: 4.273364067077637\n",
      "Epoch: 14, step: 250/390, loss: 4.267334938049316\n",
      "Epoch: 14, step: 300/390, loss: 4.280229568481445\n",
      "Epoch: 14, step: 350/390, loss: 4.300197124481201\n",
      "Epoch: 14 completed, average loss: 4.296373221813104, time taken: 0.9596756776173909 mins\n",
      "Epoch: 15, step: 50/390, loss: 4.219682216644287\n",
      "Epoch: 15, step: 100/390, loss: 4.2241411209106445\n",
      "Epoch: 15, step: 150/390, loss: 4.243668079376221\n",
      "Epoch: 15, step: 200/390, loss: 4.2995758056640625\n",
      "Epoch: 15, step: 250/390, loss: 4.256631851196289\n",
      "Epoch: 15, step: 300/390, loss: 4.24872350692749\n",
      "Epoch: 15, step: 350/390, loss: 4.280665397644043\n",
      "Epoch: 15 completed, average loss: 4.285499443152012, time taken: 0.9556278546651205 mins\n",
      "Epoch: 16, step: 50/390, loss: 4.292306423187256\n",
      "Epoch: 16, step: 100/390, loss: 4.299023628234863\n",
      "Epoch: 16, step: 150/390, loss: 4.295038223266602\n",
      "Epoch: 16, step: 200/390, loss: 4.277665615081787\n",
      "Epoch: 16, step: 250/390, loss: 4.350138187408447\n",
      "Epoch: 16, step: 300/390, loss: 4.25050163269043\n",
      "Epoch: 16, step: 350/390, loss: 4.285499572753906\n",
      "Epoch: 16 completed, average loss: 4.274089373075045, time taken: 0.9817703644434611 mins\n",
      "Epoch: 17, step: 50/390, loss: 4.264936447143555\n",
      "Epoch: 17, step: 100/390, loss: 4.288022518157959\n",
      "Epoch: 17, step: 150/390, loss: 4.279555797576904\n",
      "Epoch: 17, step: 200/390, loss: 4.317836761474609\n",
      "Epoch: 17, step: 250/390, loss: 4.182825088500977\n",
      "Epoch: 17, step: 300/390, loss: 4.296506881713867\n",
      "Epoch: 17, step: 350/390, loss: 4.2518792152404785\n",
      "Epoch: 17 completed, average loss: 4.267970686692458, time taken: 0.9308634559313457 mins\n",
      "Epoch: 18, step: 50/390, loss: 4.323095321655273\n",
      "Epoch: 18, step: 100/390, loss: 4.219846725463867\n",
      "Epoch: 18, step: 150/390, loss: 4.316168785095215\n",
      "Epoch: 18, step: 200/390, loss: 4.291171073913574\n",
      "Epoch: 18, step: 250/390, loss: 4.231777667999268\n",
      "Epoch: 18, step: 300/390, loss: 4.225269794464111\n",
      "Epoch: 18, step: 350/390, loss: 4.236800670623779\n",
      "Epoch: 18 completed, average loss: 4.258388057121864, time taken: 0.9472508390744527 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, step: 50/390, loss: 4.263918399810791\n",
      "Epoch: 19, step: 100/390, loss: 4.204599857330322\n",
      "Epoch: 19, step: 150/390, loss: 4.206061840057373\n",
      "Epoch: 19, step: 200/390, loss: 4.229191780090332\n",
      "Epoch: 19, step: 250/390, loss: 4.196382522583008\n",
      "Epoch: 19, step: 300/390, loss: 4.2990617752075195\n",
      "Epoch: 19, step: 350/390, loss: 4.2760162353515625\n",
      "Epoch: 19 completed, average loss: 4.249769066541623, time taken: 0.9764932076136271 mins\n",
      "Epoch: 20, step: 50/390, loss: 4.266952037811279\n",
      "Epoch: 20, step: 100/390, loss: 4.2106032371521\n",
      "Epoch: 20, step: 150/390, loss: 4.215514659881592\n",
      "Epoch: 20, step: 200/390, loss: 4.200046539306641\n",
      "Epoch: 20, step: 250/390, loss: 4.1561279296875\n",
      "Epoch: 20, step: 300/390, loss: 4.236349105834961\n",
      "Epoch: 20, step: 350/390, loss: 4.238303184509277\n",
      "Epoch: 20 completed, average loss: 4.241718402275672, time taken: 0.9900427182515462 mins\n",
      "Epoch: 21, step: 50/390, loss: 4.257730007171631\n",
      "Epoch: 21, step: 100/390, loss: 4.268267631530762\n",
      "Epoch: 21, step: 150/390, loss: 4.235455513000488\n",
      "Epoch: 21, step: 200/390, loss: 4.2233452796936035\n",
      "Epoch: 21, step: 250/390, loss: 4.2624192237854\n",
      "Epoch: 21, step: 300/390, loss: 4.28361177444458\n",
      "Epoch: 21, step: 350/390, loss: 4.1871337890625\n",
      "Epoch: 21 completed, average loss: 4.237025086085001, time taken: 0.959232219060262 mins\n",
      "Epoch: 22, step: 50/390, loss: 4.220736503601074\n",
      "Epoch: 22, step: 100/390, loss: 4.285200119018555\n",
      "Epoch: 22, step: 150/390, loss: 4.25084114074707\n",
      "Epoch: 22, step: 200/390, loss: 4.210544586181641\n",
      "Epoch: 22, step: 250/390, loss: 4.254298686981201\n",
      "Epoch: 22, step: 300/390, loss: 4.216526508331299\n",
      "Epoch: 22, step: 350/390, loss: 4.275630950927734\n",
      "Epoch: 22 completed, average loss: 4.232624333944076, time taken: 0.9781889955202738 mins\n",
      "Epoch: 23, step: 50/390, loss: 4.234935760498047\n",
      "Epoch: 23, step: 100/390, loss: 4.202847480773926\n",
      "Epoch: 23, step: 150/390, loss: 4.285343170166016\n",
      "Epoch: 23, step: 200/390, loss: 4.154587745666504\n",
      "Epoch: 23, step: 250/390, loss: 4.191490650177002\n",
      "Epoch: 23, step: 300/390, loss: 4.259558200836182\n",
      "Epoch: 23, step: 350/390, loss: 4.192903518676758\n",
      "Epoch: 23 completed, average loss: 4.224856388874543, time taken: 0.9654422283172608 mins\n",
      "Epoch: 24, step: 50/390, loss: 4.1791253089904785\n",
      "Epoch: 24, step: 100/390, loss: 4.255544662475586\n",
      "Epoch: 24, step: 150/390, loss: 4.222660541534424\n",
      "Epoch: 24, step: 200/390, loss: 4.187952041625977\n",
      "Epoch: 24, step: 250/390, loss: 4.2440571784973145\n",
      "Epoch: 24, step: 300/390, loss: 4.220394134521484\n",
      "Epoch: 24, step: 350/390, loss: 4.131452560424805\n",
      "Epoch: 24 completed, average loss: 4.2202314645816115, time taken: 0.9584414641062419 mins\n",
      "Epoch: 25, step: 50/390, loss: 4.2685065269470215\n",
      "Epoch: 25, step: 100/390, loss: 4.235469818115234\n",
      "Epoch: 25, step: 150/390, loss: 4.284566402435303\n",
      "Epoch: 25, step: 200/390, loss: 4.1606855392456055\n",
      "Epoch: 25, step: 250/390, loss: 4.232806205749512\n",
      "Epoch: 25, step: 300/390, loss: 4.132445812225342\n",
      "Epoch: 25, step: 350/390, loss: 4.188199996948242\n",
      "Epoch: 25 completed, average loss: 4.2170043370662595, time taken: 0.9373247345288594 mins\n",
      "Epoch: 26, step: 50/390, loss: 4.2144622802734375\n",
      "Epoch: 26, step: 100/390, loss: 4.235257625579834\n",
      "Epoch: 26, step: 150/390, loss: 4.23637056350708\n",
      "Epoch: 26, step: 200/390, loss: 4.262187957763672\n",
      "Epoch: 26, step: 250/390, loss: 4.169793605804443\n",
      "Epoch: 26, step: 300/390, loss: 4.2057390213012695\n",
      "Epoch: 26, step: 350/390, loss: 4.285928726196289\n",
      "Epoch: 26 completed, average loss: 4.211781192437196, time taken: 0.9426088929176331 mins\n",
      "Epoch: 27, step: 50/390, loss: 4.280499458312988\n",
      "Epoch: 27, step: 100/390, loss: 4.191112518310547\n",
      "Epoch: 27, step: 150/390, loss: 4.17876672744751\n",
      "Epoch: 27, step: 200/390, loss: 4.21418571472168\n",
      "Epoch: 27, step: 250/390, loss: 4.201690673828125\n",
      "Epoch: 27, step: 300/390, loss: 4.231592655181885\n",
      "Epoch: 27, step: 350/390, loss: 4.196731090545654\n",
      "Epoch: 27 completed, average loss: 4.2122917199746155, time taken: 0.9593194246292114 mins\n",
      "Epoch: 28, step: 50/390, loss: 4.161509037017822\n",
      "Epoch: 28, step: 100/390, loss: 4.2816267013549805\n",
      "Epoch: 28, step: 150/390, loss: 4.261277198791504\n",
      "Epoch: 28, step: 200/390, loss: 4.250894546508789\n",
      "Epoch: 28, step: 250/390, loss: 4.2464799880981445\n",
      "Epoch: 28, step: 300/390, loss: 4.12535285949707\n",
      "Epoch: 28, step: 350/390, loss: 4.221554756164551\n",
      "Epoch: 28 completed, average loss: 4.203735043452336, time taken: 0.9562578757603963 mins\n",
      "Epoch: 29, step: 50/390, loss: 4.18421745300293\n",
      "Epoch: 29, step: 100/390, loss: 4.143392562866211\n",
      "Epoch: 29, step: 150/390, loss: 4.196857929229736\n",
      "Epoch: 29, step: 200/390, loss: 4.213259220123291\n",
      "Epoch: 29, step: 250/390, loss: 4.212531566619873\n",
      "Epoch: 29, step: 300/390, loss: 4.192818641662598\n",
      "Epoch: 29, step: 350/390, loss: 4.198773384094238\n",
      "Epoch: 29 completed, average loss: 4.2034448354672165, time taken: 0.9677282333374023 mins\n",
      "Epoch: 30, step: 50/390, loss: 4.17701530456543\n",
      "Epoch: 30, step: 100/390, loss: 4.312351226806641\n",
      "Epoch: 30, step: 150/390, loss: 4.255443572998047\n",
      "Epoch: 30, step: 200/390, loss: 4.225093364715576\n",
      "Epoch: 30, step: 250/390, loss: 4.201242923736572\n",
      "Epoch: 30, step: 300/390, loss: 4.201911449432373\n",
      "Epoch: 30, step: 350/390, loss: 4.182379722595215\n",
      "Epoch: 30 completed, average loss: 4.194615376301301, time taken: 0.9561697681744893 mins\n",
      "Epoch: 31, step: 50/390, loss: 4.225478172302246\n",
      "Epoch: 31, step: 100/390, loss: 4.091142177581787\n",
      "Epoch: 31, step: 150/390, loss: 4.146697521209717\n",
      "Epoch: 31, step: 200/390, loss: 4.2210869789123535\n",
      "Epoch: 31, step: 250/390, loss: 4.254541397094727\n",
      "Epoch: 31, step: 300/390, loss: 4.185920715332031\n",
      "Epoch: 31, step: 350/390, loss: 4.209383010864258\n",
      "Epoch: 31 completed, average loss: 4.190792075181618, time taken: 0.9680066386858622 mins\n",
      "Epoch: 32, step: 50/390, loss: 4.1463494300842285\n",
      "Epoch: 32, step: 100/390, loss: 4.270381927490234\n",
      "Epoch: 32, step: 150/390, loss: 4.23224401473999\n",
      "Epoch: 32, step: 200/390, loss: 4.1358184814453125\n",
      "Epoch: 32, step: 250/390, loss: 4.215398788452148\n",
      "Epoch: 32, step: 300/390, loss: 4.2088704109191895\n",
      "Epoch: 32, step: 350/390, loss: 4.139066219329834\n",
      "Epoch: 32 completed, average loss: 4.186938678301297, time taken: 0.9610163648923238 mins\n",
      "Epoch: 33, step: 50/390, loss: 4.172576904296875\n",
      "Epoch: 33, step: 100/390, loss: 4.098280429840088\n",
      "Epoch: 33, step: 150/390, loss: 4.137205600738525\n",
      "Epoch: 33, step: 200/390, loss: 4.133944988250732\n",
      "Epoch: 33, step: 250/390, loss: 4.20102071762085\n",
      "Epoch: 33, step: 300/390, loss: 4.144312858581543\n",
      "Epoch: 33, step: 350/390, loss: 4.169513702392578\n",
      "Epoch: 33 completed, average loss: 4.181867458881476, time taken: 0.9614357630411784 mins\n",
      "Epoch: 34, step: 50/390, loss: 4.239780426025391\n",
      "Epoch: 34, step: 100/390, loss: 4.2204909324646\n",
      "Epoch: 34, step: 150/390, loss: 4.1207075119018555\n",
      "Epoch: 34, step: 200/390, loss: 4.167041778564453\n",
      "Epoch: 34, step: 250/390, loss: 4.166520595550537\n",
      "Epoch: 34, step: 300/390, loss: 4.100964546203613\n",
      "Epoch: 34, step: 350/390, loss: 4.241872787475586\n",
      "Epoch: 34 completed, average loss: 4.1778795829186075, time taken: 0.9738776644070943 mins\n",
      "Epoch: 35, step: 50/390, loss: 4.132264614105225\n",
      "Epoch: 35, step: 100/390, loss: 4.169370651245117\n",
      "Epoch: 35, step: 150/390, loss: 4.1826276779174805\n",
      "Epoch: 35, step: 200/390, loss: 4.197511672973633\n",
      "Epoch: 35, step: 250/390, loss: 4.170219898223877\n",
      "Epoch: 35, step: 300/390, loss: 4.173878192901611\n",
      "Epoch: 35, step: 350/390, loss: 4.131162166595459\n",
      "Epoch: 35 completed, average loss: 4.175516841350458, time taken: 0.9521946310997009 mins\n",
      "Epoch: 36, step: 50/390, loss: 4.179657936096191\n",
      "Epoch: 36, step: 100/390, loss: 4.155959129333496\n",
      "Epoch: 36, step: 150/390, loss: 4.240345001220703\n",
      "Epoch: 36, step: 200/390, loss: 4.245048999786377\n",
      "Epoch: 36, step: 250/390, loss: 4.193163871765137\n",
      "Epoch: 36, step: 300/390, loss: 4.294877052307129\n",
      "Epoch: 36, step: 350/390, loss: 4.165560722351074\n",
      "Epoch: 36 completed, average loss: 4.1742523939181595, time taken: 0.9276649594306946 mins\n",
      "Epoch: 37, step: 50/390, loss: 4.162296772003174\n",
      "Epoch: 37, step: 100/390, loss: 4.178203105926514\n",
      "Epoch: 37, step: 150/390, loss: 4.204754829406738\n",
      "Epoch: 37, step: 200/390, loss: 4.195912837982178\n",
      "Epoch: 37, step: 250/390, loss: 4.221259117126465\n",
      "Epoch: 37, step: 300/390, loss: 4.092552185058594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, step: 350/390, loss: 4.214574337005615\n",
      "Epoch: 37 completed, average loss: 4.174222995073367, time taken: 0.9904507915178935 mins\n",
      "Epoch: 38, step: 50/390, loss: 4.109114646911621\n",
      "Epoch: 38, step: 100/390, loss: 4.163270950317383\n",
      "Epoch: 38, step: 150/390, loss: 4.168603897094727\n",
      "Epoch: 38, step: 200/390, loss: 4.142715930938721\n",
      "Epoch: 38, step: 250/390, loss: 4.2454514503479\n",
      "Epoch: 38, step: 300/390, loss: 4.1030144691467285\n",
      "Epoch: 38, step: 350/390, loss: 4.084095001220703\n",
      "Epoch: 38 completed, average loss: 4.165929986269046, time taken: 0.9714562892913818 mins\n",
      "Epoch: 39, step: 50/390, loss: 4.1229705810546875\n",
      "Epoch: 39, step: 100/390, loss: 4.235676288604736\n",
      "Epoch: 39, step: 150/390, loss: 4.182544708251953\n",
      "Epoch: 39, step: 200/390, loss: 4.142885208129883\n",
      "Epoch: 39, step: 250/390, loss: 4.252424240112305\n",
      "Epoch: 39, step: 300/390, loss: 4.1799516677856445\n",
      "Epoch: 39, step: 350/390, loss: 4.228949069976807\n",
      "Epoch: 39 completed, average loss: 4.164566674599281, time taken: 0.9594590266545614 mins\n",
      "Epoch: 40, step: 50/390, loss: 4.180942535400391\n",
      "Epoch: 40, step: 100/390, loss: 4.111096382141113\n",
      "Epoch: 40, step: 150/390, loss: 4.123426914215088\n",
      "Epoch: 40, step: 200/390, loss: 4.124037265777588\n",
      "Epoch: 40, step: 250/390, loss: 4.178646564483643\n",
      "Epoch: 40, step: 300/390, loss: 4.168557167053223\n",
      "Epoch: 40, step: 350/390, loss: 4.216250419616699\n",
      "Epoch: 40 completed, average loss: 4.163384688206208, time taken: 0.9857370615005493 mins\n",
      "Epoch: 41, step: 50/390, loss: 4.210806846618652\n",
      "Epoch: 41, step: 100/390, loss: 4.08656120300293\n",
      "Epoch: 41, step: 150/390, loss: 4.214909076690674\n",
      "Epoch: 41, step: 200/390, loss: 4.19921875\n",
      "Epoch: 41, step: 250/390, loss: 4.19263219833374\n",
      "Epoch: 41, step: 300/390, loss: 4.152836322784424\n",
      "Epoch: 41, step: 350/390, loss: 4.134336948394775\n",
      "Epoch: 41 completed, average loss: 4.157270328815167, time taken: 0.9569841623306274 mins\n",
      "Epoch: 42, step: 50/390, loss: 4.131514072418213\n",
      "Epoch: 42, step: 100/390, loss: 4.1453328132629395\n",
      "Epoch: 42, step: 150/390, loss: 4.221246242523193\n",
      "Epoch: 42, step: 200/390, loss: 4.111969470977783\n",
      "Epoch: 42, step: 250/390, loss: 4.2515339851379395\n",
      "Epoch: 42, step: 300/390, loss: 4.148986339569092\n",
      "Epoch: 42, step: 350/390, loss: 4.1543097496032715\n",
      "Epoch: 42 completed, average loss: 4.156416001686683, time taken: 0.939590859413147 mins\n",
      "Epoch: 43, step: 50/390, loss: 4.172407150268555\n",
      "Epoch: 43, step: 100/390, loss: 4.17130708694458\n",
      "Epoch: 43, step: 150/390, loss: 4.119048595428467\n",
      "Epoch: 43, step: 200/390, loss: 4.161621570587158\n",
      "Epoch: 43, step: 250/390, loss: 4.181528091430664\n",
      "Epoch: 43, step: 300/390, loss: 4.101028919219971\n",
      "Epoch: 43, step: 350/390, loss: 4.113993167877197\n",
      "Epoch: 43 completed, average loss: 4.150807463817108, time taken: 0.9591895381609599 mins\n",
      "Epoch: 44, step: 50/390, loss: 4.150391101837158\n",
      "Epoch: 44, step: 100/390, loss: 4.103973865509033\n",
      "Epoch: 44, step: 150/390, loss: 4.106464862823486\n",
      "Epoch: 44, step: 200/390, loss: 4.163451671600342\n",
      "Epoch: 44, step: 250/390, loss: 4.156062126159668\n",
      "Epoch: 44, step: 300/390, loss: 4.12424898147583\n",
      "Epoch: 44, step: 350/390, loss: 4.069227695465088\n",
      "Epoch: 44 completed, average loss: 4.153530684495584, time taken: 0.9841500560442606 mins\n",
      "Epoch: 45, step: 50/390, loss: 4.205005168914795\n",
      "Epoch: 45, step: 100/390, loss: 4.205426216125488\n",
      "Epoch: 45, step: 150/390, loss: 4.138823986053467\n",
      "Epoch: 45, step: 200/390, loss: 4.145519256591797\n",
      "Epoch: 45, step: 250/390, loss: 4.171753883361816\n",
      "Epoch: 45, step: 300/390, loss: 4.154829025268555\n",
      "Epoch: 45, step: 350/390, loss: 4.205151557922363\n",
      "Epoch: 45 completed, average loss: 4.14702061506418, time taken: 0.952915879090627 mins\n",
      "Epoch: 46, step: 50/390, loss: 4.108977317810059\n",
      "Epoch: 46, step: 100/390, loss: 4.108336925506592\n",
      "Epoch: 46, step: 150/390, loss: 4.178992748260498\n",
      "Epoch: 46, step: 200/390, loss: 4.16699743270874\n",
      "Epoch: 46, step: 250/390, loss: 4.134361267089844\n",
      "Epoch: 46, step: 300/390, loss: 4.173322677612305\n",
      "Epoch: 46, step: 350/390, loss: 4.129947662353516\n",
      "Epoch: 46 completed, average loss: 4.144042225373097, time taken: 0.9714442133903504 mins\n",
      "Epoch: 47, step: 50/390, loss: 4.208387851715088\n",
      "Epoch: 47, step: 100/390, loss: 4.217709064483643\n",
      "Epoch: 47, step: 150/390, loss: 4.092992305755615\n",
      "Epoch: 47, step: 200/390, loss: 4.234234809875488\n",
      "Epoch: 47, step: 250/390, loss: 4.117236137390137\n",
      "Epoch: 47, step: 300/390, loss: 4.07942533493042\n",
      "Epoch: 47, step: 350/390, loss: 4.154196739196777\n",
      "Epoch: 47 completed, average loss: 4.146374998337183, time taken: 0.9399388710657756 mins\n",
      "Epoch: 48, step: 50/390, loss: 4.094837665557861\n",
      "Epoch: 48, step: 100/390, loss: 4.164943695068359\n",
      "Epoch: 48, step: 150/390, loss: 4.106394290924072\n",
      "Epoch: 48, step: 200/390, loss: 4.091479301452637\n",
      "Epoch: 48, step: 250/390, loss: 4.128700256347656\n",
      "Epoch: 48, step: 300/390, loss: 4.110480785369873\n",
      "Epoch: 48, step: 350/390, loss: 4.11023473739624\n",
      "Epoch: 48 completed, average loss: 4.144766161992, time taken: 0.9579892039299012 mins\n",
      "Epoch: 49, step: 50/390, loss: 4.031029224395752\n",
      "Epoch: 49, step: 100/390, loss: 4.1298508644104\n",
      "Epoch: 49, step: 150/390, loss: 4.18001651763916\n",
      "Epoch: 49, step: 200/390, loss: 4.199058532714844\n",
      "Epoch: 49, step: 250/390, loss: 4.213833332061768\n",
      "Epoch: 49, step: 300/390, loss: 4.208159923553467\n",
      "Epoch: 49, step: 350/390, loss: 4.103666305541992\n",
      "Epoch: 49 completed, average loss: 4.14079063244355, time taken: 0.9751163880030315 mins\n",
      "Epoch: 50, step: 50/390, loss: 4.130588531494141\n",
      "Epoch: 50, step: 100/390, loss: 4.103224277496338\n",
      "Epoch: 50, step: 150/390, loss: 4.138125419616699\n",
      "Epoch: 50, step: 200/390, loss: 4.1210737228393555\n",
      "Epoch: 50, step: 250/390, loss: 4.130333423614502\n",
      "Epoch: 50, step: 300/390, loss: 4.156921863555908\n",
      "Epoch: 50, step: 350/390, loss: 4.126934051513672\n",
      "Epoch: 50 completed, average loss: 4.139360010929597, time taken: 0.9688035130500794 mins\n",
      "Epoch: 51, step: 50/390, loss: 4.117786407470703\n",
      "Epoch: 51, step: 100/390, loss: 4.220998764038086\n",
      "Epoch: 51, step: 150/390, loss: 4.128716468811035\n",
      "Epoch: 51, step: 200/390, loss: 4.190618515014648\n",
      "Epoch: 51, step: 250/390, loss: 4.16301155090332\n",
      "Epoch: 51, step: 300/390, loss: 4.153282165527344\n",
      "Epoch: 51, step: 350/390, loss: 4.156885623931885\n",
      "Epoch: 51 completed, average loss: 4.1377336819966635, time taken: 0.986977203687032 mins\n",
      "Epoch: 52, step: 50/390, loss: 4.107762813568115\n",
      "Epoch: 52, step: 100/390, loss: 4.1744465827941895\n",
      "Epoch: 52, step: 150/390, loss: 4.106166839599609\n",
      "Epoch: 52, step: 200/390, loss: 4.044016361236572\n",
      "Epoch: 52, step: 250/390, loss: 4.114112854003906\n",
      "Epoch: 52, step: 300/390, loss: 4.118671417236328\n",
      "Epoch: 52, step: 350/390, loss: 4.106591701507568\n",
      "Epoch: 52 completed, average loss: 4.134126463914529, time taken: 0.9616565744082133 mins\n",
      "Epoch: 53, step: 50/390, loss: 4.151736259460449\n",
      "Epoch: 53, step: 100/390, loss: 4.066200256347656\n",
      "Epoch: 53, step: 150/390, loss: 4.214912414550781\n",
      "Epoch: 53, step: 200/390, loss: 4.113059043884277\n",
      "Epoch: 53, step: 250/390, loss: 4.173335075378418\n",
      "Epoch: 53, step: 300/390, loss: 4.169376373291016\n",
      "Epoch: 53, step: 350/390, loss: 4.068202972412109\n",
      "Epoch: 53 completed, average loss: 4.131601087863629, time taken: 0.9604243000348409 mins\n",
      "Epoch: 54, step: 50/390, loss: 4.126720428466797\n",
      "Epoch: 54, step: 100/390, loss: 4.158949851989746\n",
      "Epoch: 54, step: 150/390, loss: 4.093256950378418\n",
      "Epoch: 54, step: 200/390, loss: 4.111024379730225\n",
      "Epoch: 54, step: 250/390, loss: 4.0660552978515625\n",
      "Epoch: 54, step: 300/390, loss: 4.166322231292725\n",
      "Epoch: 54, step: 350/390, loss: 4.13671350479126\n",
      "Epoch: 54 completed, average loss: 4.1320435756292095, time taken: 0.9436299721399943 mins\n",
      "Epoch: 55, step: 50/390, loss: 4.169372081756592\n",
      "Epoch: 55, step: 100/390, loss: 4.0986409187316895\n",
      "Epoch: 55, step: 150/390, loss: 4.156726360321045\n",
      "Epoch: 55, step: 200/390, loss: 4.0410332679748535\n",
      "Epoch: 55, step: 250/390, loss: 4.115692615509033\n",
      "Epoch: 55, step: 300/390, loss: 4.146560192108154\n",
      "Epoch: 55, step: 350/390, loss: 4.093033790588379\n",
      "Epoch: 55 completed, average loss: 4.127885609406691, time taken: 1.0027329047520956 mins\n",
      "Epoch: 56, step: 50/390, loss: 4.131932258605957\n",
      "Epoch: 56, step: 100/390, loss: 4.091735363006592\n",
      "Epoch: 56, step: 150/390, loss: 4.1835174560546875\n",
      "Epoch: 56, step: 200/390, loss: 4.12484073638916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56, step: 250/390, loss: 4.1511664390563965\n",
      "Epoch: 56, step: 300/390, loss: 4.164666175842285\n",
      "Epoch: 56, step: 350/390, loss: 4.15152645111084\n",
      "Epoch: 56 completed, average loss: 4.129079813834949, time taken: 0.9742003083229065 mins\n",
      "Epoch: 57, step: 50/390, loss: 4.0912957191467285\n",
      "Epoch: 57, step: 100/390, loss: 4.165437698364258\n",
      "Epoch: 57, step: 150/390, loss: 4.153955936431885\n",
      "Epoch: 57, step: 200/390, loss: 4.028379440307617\n",
      "Epoch: 57, step: 250/390, loss: 4.122908592224121\n",
      "Epoch: 57, step: 300/390, loss: 4.116876125335693\n",
      "Epoch: 57, step: 350/390, loss: 4.072394847869873\n",
      "Epoch: 57 completed, average loss: 4.125855651879922, time taken: 1.01100089152654 mins\n",
      "Epoch: 58, step: 50/390, loss: 4.071999549865723\n",
      "Epoch: 58, step: 100/390, loss: 4.0980753898620605\n",
      "Epoch: 58, step: 150/390, loss: 4.113412857055664\n",
      "Epoch: 58, step: 200/390, loss: 4.088448524475098\n",
      "Epoch: 58, step: 250/390, loss: 4.197882652282715\n",
      "Epoch: 58, step: 300/390, loss: 4.118973731994629\n",
      "Epoch: 58, step: 350/390, loss: 4.176389694213867\n",
      "Epoch: 58 completed, average loss: 4.1244734067183275, time taken: 0.9599241574605306 mins\n",
      "Epoch: 59, step: 50/390, loss: 4.02445650100708\n",
      "Epoch: 59, step: 100/390, loss: 4.114657878875732\n",
      "Epoch: 59, step: 150/390, loss: 4.151109218597412\n",
      "Epoch: 59, step: 200/390, loss: 4.139463901519775\n",
      "Epoch: 59, step: 250/390, loss: 4.06016731262207\n",
      "Epoch: 59, step: 300/390, loss: 4.114264011383057\n",
      "Epoch: 59, step: 350/390, loss: 4.07545280456543\n",
      "Epoch: 59 completed, average loss: 4.1188378395178376, time taken: 0.9662322600682577 mins\n",
      "Epoch: 60, step: 50/390, loss: 4.101663112640381\n",
      "Epoch: 60, step: 100/390, loss: 4.135768890380859\n",
      "Epoch: 60, step: 150/390, loss: 4.114717483520508\n",
      "Epoch: 60, step: 200/390, loss: 4.080986022949219\n",
      "Epoch: 60, step: 250/390, loss: 4.152747631072998\n",
      "Epoch: 60, step: 300/390, loss: 4.080294132232666\n",
      "Epoch: 60, step: 350/390, loss: 4.110653400421143\n",
      "Epoch: 60 completed, average loss: 4.1184963397490675, time taken: 0.9714498877525329 mins\n",
      "Epoch: 61, step: 50/390, loss: 4.057651519775391\n",
      "Epoch: 61, step: 100/390, loss: 4.139535427093506\n",
      "Epoch: 61, step: 150/390, loss: 4.128998756408691\n",
      "Epoch: 61, step: 200/390, loss: 4.153764724731445\n",
      "Epoch: 61, step: 250/390, loss: 4.117727756500244\n",
      "Epoch: 61, step: 300/390, loss: 4.16245698928833\n",
      "Epoch: 61, step: 350/390, loss: 4.07113790512085\n",
      "Epoch: 61 completed, average loss: 4.117467509783231, time taken: 0.9668824076652527 mins\n",
      "Epoch: 62, step: 50/390, loss: 4.140314102172852\n",
      "Epoch: 62, step: 100/390, loss: 4.125393390655518\n",
      "Epoch: 62, step: 150/390, loss: 4.071854591369629\n",
      "Epoch: 62, step: 200/390, loss: 4.172961711883545\n",
      "Epoch: 62, step: 250/390, loss: 4.120188236236572\n",
      "Epoch: 62, step: 300/390, loss: 4.153667449951172\n",
      "Epoch: 62, step: 350/390, loss: 4.1859517097473145\n",
      "Epoch: 62 completed, average loss: 4.118948992704734, time taken: 0.9932559649149577 mins\n",
      "Epoch: 63, step: 50/390, loss: 4.080310821533203\n",
      "Epoch: 63, step: 100/390, loss: 4.189957618713379\n",
      "Epoch: 63, step: 150/390, loss: 4.0747857093811035\n",
      "Epoch: 63, step: 200/390, loss: 4.1347737312316895\n",
      "Epoch: 63, step: 250/390, loss: 4.083703517913818\n",
      "Epoch: 63, step: 300/390, loss: 4.187891960144043\n",
      "Epoch: 63, step: 350/390, loss: 4.135700225830078\n",
      "Epoch: 63 completed, average loss: 4.117629907070062, time taken: 0.9792030930519104 mins\n",
      "Epoch: 64, step: 50/390, loss: 4.168549060821533\n",
      "Epoch: 64, step: 100/390, loss: 4.167443752288818\n",
      "Epoch: 64, step: 150/390, loss: 4.120105743408203\n",
      "Epoch: 64, step: 200/390, loss: 4.0458083152771\n",
      "Epoch: 64, step: 250/390, loss: 4.044586181640625\n",
      "Epoch: 64, step: 300/390, loss: 4.13370418548584\n",
      "Epoch: 64, step: 350/390, loss: 4.101688385009766\n",
      "Epoch: 64 completed, average loss: 4.111921021265862, time taken: 0.969169036547343 mins\n",
      "Epoch: 65, step: 50/390, loss: 4.152095794677734\n",
      "Epoch: 65, step: 100/390, loss: 4.142813682556152\n",
      "Epoch: 65, step: 150/390, loss: 4.05617094039917\n",
      "Epoch: 65, step: 200/390, loss: 4.037472248077393\n",
      "Epoch: 65, step: 250/390, loss: 4.098854064941406\n",
      "Epoch: 65, step: 300/390, loss: 4.1298418045043945\n",
      "Epoch: 65, step: 350/390, loss: 4.093670845031738\n",
      "Epoch: 65 completed, average loss: 4.113684019675621, time taken: 0.9550161361694336 mins\n",
      "Epoch: 66, step: 50/390, loss: 4.110476493835449\n",
      "Epoch: 66, step: 100/390, loss: 4.086720943450928\n",
      "Epoch: 66, step: 150/390, loss: 4.117764472961426\n",
      "Epoch: 66, step: 200/390, loss: 4.064570903778076\n",
      "Epoch: 66, step: 250/390, loss: 4.143367767333984\n",
      "Epoch: 66, step: 300/390, loss: 4.1492486000061035\n",
      "Epoch: 66, step: 350/390, loss: 4.0877366065979\n",
      "Epoch: 66 completed, average loss: 4.109049634444408, time taken: 0.9945226828257243 mins\n",
      "Epoch: 67, step: 50/390, loss: 4.140464782714844\n",
      "Epoch: 67, step: 100/390, loss: 4.059386730194092\n",
      "Epoch: 67, step: 150/390, loss: 4.127762794494629\n",
      "Epoch: 67, step: 200/390, loss: 4.055667877197266\n",
      "Epoch: 67, step: 250/390, loss: 4.105722904205322\n",
      "Epoch: 67, step: 300/390, loss: 4.138107776641846\n",
      "Epoch: 67, step: 350/390, loss: 4.088907241821289\n",
      "Epoch: 67 completed, average loss: 4.109241911692497, time taken: 0.951261059443156 mins\n",
      "Epoch: 68, step: 50/390, loss: 4.128016471862793\n",
      "Epoch: 68, step: 100/390, loss: 4.06960391998291\n",
      "Epoch: 68, step: 150/390, loss: 4.081214904785156\n",
      "Epoch: 68, step: 200/390, loss: 4.095214366912842\n",
      "Epoch: 68, step: 250/390, loss: 4.148099899291992\n",
      "Epoch: 68, step: 300/390, loss: 4.1083221435546875\n",
      "Epoch: 68, step: 350/390, loss: 4.11796760559082\n",
      "Epoch: 68 completed, average loss: 4.105512987650358, time taken: 0.9608218749364217 mins\n",
      "Epoch: 69, step: 50/390, loss: 4.084764003753662\n",
      "Epoch: 69, step: 100/390, loss: 4.059515953063965\n",
      "Epoch: 69, step: 150/390, loss: 4.138316631317139\n",
      "Epoch: 69, step: 200/390, loss: 4.089140892028809\n",
      "Epoch: 69, step: 250/390, loss: 4.10079288482666\n",
      "Epoch: 69, step: 300/390, loss: 4.1286725997924805\n",
      "Epoch: 69, step: 350/390, loss: 4.130565643310547\n",
      "Epoch: 69 completed, average loss: 4.1104480865674144, time taken: 0.9661276896794637 mins\n",
      "Epoch: 70, step: 50/390, loss: 4.094857692718506\n",
      "Epoch: 70, step: 100/390, loss: 4.157690048217773\n",
      "Epoch: 70, step: 150/390, loss: 4.1028900146484375\n",
      "Epoch: 70, step: 200/390, loss: 4.065433979034424\n",
      "Epoch: 70, step: 250/390, loss: 4.090520858764648\n",
      "Epoch: 70, step: 300/390, loss: 4.10591459274292\n",
      "Epoch: 70, step: 350/390, loss: 4.133314609527588\n",
      "Epoch: 70 completed, average loss: 4.103200419743856, time taken: 0.9633435408274332 mins\n",
      "Epoch: 71, step: 50/390, loss: 4.246665000915527\n",
      "Epoch: 71, step: 100/390, loss: 4.121737003326416\n",
      "Epoch: 71, step: 150/390, loss: 4.046368598937988\n",
      "Epoch: 71, step: 200/390, loss: 4.1154680252075195\n",
      "Epoch: 71, step: 250/390, loss: 4.093610763549805\n",
      "Epoch: 71, step: 300/390, loss: 4.095148086547852\n",
      "Epoch: 71, step: 350/390, loss: 4.079412460327148\n",
      "Epoch: 71 completed, average loss: 4.099850188768827, time taken: 0.9826734940210978 mins\n",
      "Epoch: 72, step: 50/390, loss: 4.06577205657959\n",
      "Epoch: 72, step: 100/390, loss: 4.046764373779297\n",
      "Epoch: 72, step: 150/390, loss: 4.104135513305664\n",
      "Epoch: 72, step: 200/390, loss: 4.141395568847656\n",
      "Epoch: 72, step: 250/390, loss: 4.133179664611816\n",
      "Epoch: 72, step: 300/390, loss: 4.0985918045043945\n",
      "Epoch: 72, step: 350/390, loss: 4.099629878997803\n",
      "Epoch: 72 completed, average loss: 4.102097649452014, time taken: 0.9780133128166199 mins\n",
      "Epoch: 73, step: 50/390, loss: 4.0731329917907715\n",
      "Epoch: 73, step: 100/390, loss: 4.188872337341309\n",
      "Epoch: 73, step: 150/390, loss: 4.05462121963501\n",
      "Epoch: 73, step: 200/390, loss: 4.099803924560547\n",
      "Epoch: 73, step: 250/390, loss: 4.077952861785889\n",
      "Epoch: 73, step: 300/390, loss: 4.132190227508545\n",
      "Epoch: 73, step: 350/390, loss: 4.047921657562256\n",
      "Epoch: 73 completed, average loss: 4.103189259920365, time taken: 0.9952614108721415 mins\n",
      "Epoch: 74, step: 50/390, loss: 4.052785396575928\n",
      "Epoch: 74, step: 100/390, loss: 4.117247104644775\n",
      "Epoch: 74, step: 150/390, loss: 4.0372538566589355\n",
      "Epoch: 74, step: 200/390, loss: 4.134371280670166\n",
      "Epoch: 74, step: 250/390, loss: 4.057150840759277\n",
      "Epoch: 74, step: 300/390, loss: 4.142437934875488\n",
      "Epoch: 74, step: 350/390, loss: 4.151082992553711\n",
      "Epoch: 74 completed, average loss: 4.097704047423143, time taken: 0.9569996158281963 mins\n",
      "Epoch: 75, step: 50/390, loss: 4.155605792999268\n",
      "Epoch: 75, step: 100/390, loss: 4.023662567138672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75, step: 150/390, loss: 4.108127117156982\n",
      "Epoch: 75, step: 200/390, loss: 4.08010196685791\n",
      "Epoch: 75, step: 250/390, loss: 4.118242263793945\n",
      "Epoch: 75, step: 300/390, loss: 4.082887649536133\n",
      "Epoch: 75, step: 350/390, loss: 4.137568950653076\n",
      "Epoch: 75 completed, average loss: 4.098064912893833, time taken: 0.9759297490119934 mins\n",
      "Epoch: 76, step: 50/390, loss: 4.108755588531494\n",
      "Epoch: 76, step: 100/390, loss: 4.1060566902160645\n",
      "Epoch: 76, step: 150/390, loss: 4.0877366065979\n",
      "Epoch: 76, step: 200/390, loss: 4.12782096862793\n",
      "Epoch: 76, step: 250/390, loss: 4.227372646331787\n",
      "Epoch: 76, step: 300/390, loss: 4.244753360748291\n",
      "Epoch: 76, step: 350/390, loss: 4.070405006408691\n",
      "Epoch: 76 completed, average loss: 4.097563994236482, time taken: 0.9326974272727966 mins\n",
      "Epoch: 77, step: 50/390, loss: 4.115870475769043\n",
      "Epoch: 77, step: 100/390, loss: 4.09794282913208\n",
      "Epoch: 77, step: 150/390, loss: 4.118002414703369\n",
      "Epoch: 77, step: 200/390, loss: 4.137993335723877\n",
      "Epoch: 77, step: 250/390, loss: 4.0883636474609375\n",
      "Epoch: 77, step: 300/390, loss: 4.084688663482666\n",
      "Epoch: 77, step: 350/390, loss: 4.10041618347168\n",
      "Epoch: 77 completed, average loss: 4.092413369203225, time taken: 0.9734537720680236 mins\n",
      "Epoch: 78, step: 50/390, loss: 4.114985942840576\n",
      "Epoch: 78, step: 100/390, loss: 4.078459739685059\n",
      "Epoch: 78, step: 150/390, loss: 4.139769554138184\n",
      "Epoch: 78, step: 200/390, loss: 4.085330486297607\n",
      "Epoch: 78, step: 250/390, loss: 4.140524387359619\n",
      "Epoch: 78, step: 300/390, loss: 4.199490070343018\n",
      "Epoch: 78, step: 350/390, loss: 4.111949443817139\n",
      "Epoch: 78 completed, average loss: 4.097691690616118, time taken: 0.9388102332750956 mins\n",
      "Epoch: 79, step: 50/390, loss: 4.083543300628662\n",
      "Epoch: 79, step: 100/390, loss: 4.006677627563477\n",
      "Epoch: 79, step: 150/390, loss: 4.102289199829102\n",
      "Epoch: 79, step: 200/390, loss: 3.9990036487579346\n",
      "Epoch: 79, step: 250/390, loss: 4.178950309753418\n",
      "Epoch: 79, step: 300/390, loss: 4.058469772338867\n",
      "Epoch: 79, step: 350/390, loss: 4.169122695922852\n",
      "Epoch: 79 completed, average loss: 4.0924014262664015, time taken: 0.9700294574101765 mins\n",
      "Epoch: 80, step: 50/390, loss: 4.056685447692871\n",
      "Epoch: 80, step: 100/390, loss: 4.063654899597168\n",
      "Epoch: 80, step: 150/390, loss: 4.040679454803467\n",
      "Epoch: 80, step: 200/390, loss: 4.113160610198975\n",
      "Epoch: 80, step: 250/390, loss: 4.139594078063965\n",
      "Epoch: 80, step: 300/390, loss: 4.150275230407715\n",
      "Epoch: 80, step: 350/390, loss: 4.141903400421143\n",
      "Epoch: 80 completed, average loss: 4.091299734360132, time taken: 0.9492515166600545 mins\n",
      "Epoch: 81, step: 50/390, loss: 4.0415167808532715\n",
      "Epoch: 81, step: 100/390, loss: 4.173892021179199\n",
      "Epoch: 81, step: 150/390, loss: 4.120481967926025\n",
      "Epoch: 81, step: 200/390, loss: 4.0991950035095215\n",
      "Epoch: 81, step: 250/390, loss: 4.068405628204346\n",
      "Epoch: 81, step: 300/390, loss: 4.0513153076171875\n",
      "Epoch: 81, step: 350/390, loss: 4.205534934997559\n",
      "Epoch: 81 completed, average loss: 4.091569036092514, time taken: 0.9517283837000529 mins\n",
      "Epoch: 82, step: 50/390, loss: 4.0737223625183105\n",
      "Epoch: 82, step: 100/390, loss: 4.019384384155273\n",
      "Epoch: 82, step: 150/390, loss: 4.134690761566162\n",
      "Epoch: 82, step: 200/390, loss: 4.097499370574951\n",
      "Epoch: 82, step: 250/390, loss: 4.0647783279418945\n",
      "Epoch: 82, step: 300/390, loss: 4.08771276473999\n",
      "Epoch: 82, step: 350/390, loss: 4.098083972930908\n",
      "Epoch: 82 completed, average loss: 4.087517477915838, time taken: 0.9592459599177042 mins\n",
      "Epoch: 83, step: 50/390, loss: 4.009950637817383\n",
      "Epoch: 83, step: 100/390, loss: 4.082154750823975\n",
      "Epoch: 83, step: 150/390, loss: 4.207086563110352\n",
      "Epoch: 83, step: 200/390, loss: 4.128530502319336\n",
      "Epoch: 83, step: 250/390, loss: 4.091245174407959\n",
      "Epoch: 83, step: 300/390, loss: 4.125014781951904\n",
      "Epoch: 83, step: 350/390, loss: 4.123129367828369\n",
      "Epoch: 83 completed, average loss: 4.089238752462925, time taken: 0.9446600635846456 mins\n",
      "Epoch: 84, step: 50/390, loss: 4.10385799407959\n",
      "Epoch: 84, step: 100/390, loss: 4.077176094055176\n",
      "Epoch: 84, step: 150/390, loss: 4.095196723937988\n",
      "Epoch: 84, step: 200/390, loss: 4.042187213897705\n",
      "Epoch: 84, step: 250/390, loss: 4.047859191894531\n",
      "Epoch: 84, step: 300/390, loss: 4.090890407562256\n",
      "Epoch: 84, step: 350/390, loss: 4.1521735191345215\n",
      "Epoch: 84 completed, average loss: 4.088322552045186, time taken: 0.9761422594388326 mins\n",
      "Epoch: 85, step: 50/390, loss: 4.1407084465026855\n",
      "Epoch: 85, step: 100/390, loss: 4.085384368896484\n",
      "Epoch: 85, step: 150/390, loss: 4.095994472503662\n",
      "Epoch: 85, step: 200/390, loss: 4.138078212738037\n",
      "Epoch: 85, step: 250/390, loss: 4.110518932342529\n",
      "Epoch: 85, step: 300/390, loss: 4.030954837799072\n",
      "Epoch: 85, step: 350/390, loss: 4.17340087890625\n",
      "Epoch: 85 completed, average loss: 4.090589676147852, time taken: 0.9643216570218404 mins\n",
      "Epoch: 86, step: 50/390, loss: 4.109650611877441\n",
      "Epoch: 86, step: 100/390, loss: 4.122559070587158\n",
      "Epoch: 86, step: 150/390, loss: 4.023810386657715\n",
      "Epoch: 86, step: 200/390, loss: 4.108339309692383\n",
      "Epoch: 86, step: 250/390, loss: 4.079370975494385\n",
      "Epoch: 86, step: 300/390, loss: 4.055309295654297\n",
      "Epoch: 86, step: 350/390, loss: 4.0279693603515625\n",
      "Epoch: 86 completed, average loss: 4.087655346210187, time taken: 0.9647313396135966 mins\n",
      "Epoch: 87, step: 50/390, loss: 4.0188751220703125\n",
      "Epoch: 87, step: 100/390, loss: 4.1310014724731445\n",
      "Epoch: 87, step: 150/390, loss: 4.0120415687561035\n",
      "Epoch: 87, step: 200/390, loss: 4.0660014152526855\n",
      "Epoch: 87, step: 250/390, loss: 4.071521282196045\n",
      "Epoch: 87, step: 300/390, loss: 4.091853141784668\n",
      "Epoch: 87, step: 350/390, loss: 4.016661643981934\n",
      "Epoch: 87 completed, average loss: 4.081921493090116, time taken: 0.9526030421257019 mins\n",
      "Epoch: 88, step: 50/390, loss: 4.05944299697876\n",
      "Epoch: 88, step: 100/390, loss: 4.074339866638184\n",
      "Epoch: 88, step: 150/390, loss: 4.196156978607178\n",
      "Epoch: 88, step: 200/390, loss: 4.082754135131836\n",
      "Epoch: 88, step: 250/390, loss: 4.033514022827148\n",
      "Epoch: 88, step: 300/390, loss: 4.1034746170043945\n",
      "Epoch: 88, step: 350/390, loss: 4.094700813293457\n",
      "Epoch: 88 completed, average loss: 4.083200676624592, time taken: 0.9823049902915955 mins\n",
      "Epoch: 89, step: 50/390, loss: 4.086368560791016\n",
      "Epoch: 89, step: 100/390, loss: 4.047245979309082\n",
      "Epoch: 89, step: 150/390, loss: 4.116544246673584\n",
      "Epoch: 89, step: 200/390, loss: 4.092113018035889\n",
      "Epoch: 89, step: 250/390, loss: 4.052023887634277\n",
      "Epoch: 89, step: 300/390, loss: 4.10874605178833\n",
      "Epoch: 89, step: 350/390, loss: 4.110930442810059\n",
      "Epoch: 89 completed, average loss: 4.078911628478613, time taken: 0.9740699728329977 mins\n",
      "Epoch: 90, step: 50/390, loss: 4.084436893463135\n",
      "Epoch: 90, step: 100/390, loss: 4.111419200897217\n",
      "Epoch: 90, step: 150/390, loss: 4.111683368682861\n",
      "Epoch: 90, step: 200/390, loss: 4.117575168609619\n",
      "Epoch: 90, step: 250/390, loss: 4.1106486320495605\n",
      "Epoch: 90, step: 300/390, loss: 4.068995952606201\n",
      "Epoch: 90, step: 350/390, loss: 4.091670513153076\n",
      "Epoch: 90 completed, average loss: 4.083974242210388, time taken: 1.0042797684669496 mins\n",
      "Epoch: 91, step: 50/390, loss: 4.061505317687988\n",
      "Epoch: 91, step: 100/390, loss: 4.082195281982422\n",
      "Epoch: 91, step: 150/390, loss: 4.098756790161133\n",
      "Epoch: 91, step: 200/390, loss: 4.106318950653076\n",
      "Epoch: 91, step: 250/390, loss: 4.14794397354126\n",
      "Epoch: 91, step: 300/390, loss: 4.11350679397583\n",
      "Epoch: 91, step: 350/390, loss: 4.003654479980469\n",
      "Epoch: 91 completed, average loss: 4.081749112178118, time taken: 0.9503635168075562 mins\n",
      "Epoch: 92, step: 50/390, loss: 4.105993747711182\n",
      "Epoch: 92, step: 100/390, loss: 4.126840114593506\n",
      "Epoch: 92, step: 150/390, loss: 4.118295192718506\n",
      "Epoch: 92, step: 200/390, loss: 4.107036113739014\n",
      "Epoch: 92, step: 250/390, loss: 4.099170207977295\n",
      "Epoch: 92, step: 300/390, loss: 4.008313179016113\n",
      "Epoch: 92, step: 350/390, loss: 4.04928731918335\n",
      "Epoch: 92 completed, average loss: 4.079238090759668, time taken: 0.9789072195688884 mins\n",
      "Epoch: 93, step: 50/390, loss: 4.053740978240967\n",
      "Epoch: 93, step: 100/390, loss: 4.075143337249756\n",
      "Epoch: 93, step: 150/390, loss: 4.073639392852783\n",
      "Epoch: 93, step: 200/390, loss: 4.022592544555664\n",
      "Epoch: 93, step: 250/390, loss: 4.053462505340576\n",
      "Epoch: 93, step: 300/390, loss: 4.139766693115234\n",
      "Epoch: 93, step: 350/390, loss: 4.061147212982178\n",
      "Epoch: 93 completed, average loss: 4.080354329867241, time taken: 0.9632980982462566 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94, step: 50/390, loss: 4.194573879241943\n",
      "Epoch: 94, step: 100/390, loss: 4.017246723175049\n",
      "Epoch: 94, step: 150/390, loss: 4.063704013824463\n",
      "Epoch: 94, step: 200/390, loss: 4.094419002532959\n",
      "Epoch: 94, step: 250/390, loss: 4.059899806976318\n",
      "Epoch: 94, step: 300/390, loss: 3.9948954582214355\n",
      "Epoch: 94, step: 350/390, loss: 4.107999324798584\n",
      "Epoch: 94 completed, average loss: 4.075818498318012, time taken: 0.9497871597607931 mins\n",
      "Epoch: 95, step: 50/390, loss: 4.061428546905518\n",
      "Epoch: 95, step: 100/390, loss: 4.097206115722656\n",
      "Epoch: 95, step: 150/390, loss: 4.101658344268799\n",
      "Epoch: 95, step: 200/390, loss: 4.183224678039551\n",
      "Epoch: 95, step: 250/390, loss: 4.048154354095459\n",
      "Epoch: 95, step: 300/390, loss: 4.029404163360596\n",
      "Epoch: 95, step: 350/390, loss: 4.048642635345459\n",
      "Epoch: 95 completed, average loss: 4.07419001689324, time taken: 0.9642489234606425 mins\n",
      "Epoch: 96, step: 50/390, loss: 4.123319625854492\n",
      "Epoch: 96, step: 100/390, loss: 3.9883499145507812\n",
      "Epoch: 96, step: 150/390, loss: 4.050082206726074\n",
      "Epoch: 96, step: 200/390, loss: 4.056695938110352\n",
      "Epoch: 96, step: 250/390, loss: 4.082876205444336\n",
      "Epoch: 96, step: 300/390, loss: 4.062376499176025\n",
      "Epoch: 96, step: 350/390, loss: 4.080268383026123\n",
      "Epoch: 96 completed, average loss: 4.079679531317491, time taken: 0.9896605531374614 mins\n",
      "Epoch: 97, step: 50/390, loss: 4.035122871398926\n",
      "Epoch: 97, step: 100/390, loss: 4.058006763458252\n",
      "Epoch: 97, step: 150/390, loss: 4.020018577575684\n",
      "Epoch: 97, step: 200/390, loss: 4.012053489685059\n",
      "Epoch: 97, step: 250/390, loss: 4.130051136016846\n",
      "Epoch: 97, step: 300/390, loss: 4.077326774597168\n",
      "Epoch: 97, step: 350/390, loss: 3.9684154987335205\n",
      "Epoch: 97 completed, average loss: 4.071169727887863, time taken: 0.958479646841685 mins\n",
      "Epoch: 98, step: 50/390, loss: 4.123101234436035\n",
      "Epoch: 98, step: 100/390, loss: 4.128922462463379\n",
      "Epoch: 98, step: 150/390, loss: 4.170634746551514\n",
      "Epoch: 98, step: 200/390, loss: 4.064028739929199\n",
      "Epoch: 98, step: 250/390, loss: 4.0407562255859375\n",
      "Epoch: 98, step: 300/390, loss: 4.031967639923096\n",
      "Epoch: 98, step: 350/390, loss: 4.117758750915527\n",
      "Epoch: 98 completed, average loss: 4.074748423771981, time taken: 0.9532017827033996 mins\n",
      "Epoch: 99, step: 50/390, loss: 4.089450359344482\n",
      "Epoch: 99, step: 100/390, loss: 4.023958206176758\n",
      "Epoch: 99, step: 150/390, loss: 4.060495853424072\n",
      "Epoch: 99, step: 200/390, loss: 4.150862693786621\n",
      "Epoch: 99, step: 250/390, loss: 4.131770610809326\n",
      "Epoch: 99, step: 300/390, loss: 4.090113162994385\n",
      "Epoch: 99, step: 350/390, loss: 4.062849998474121\n",
      "Epoch: 99 completed, average loss: 4.069034753701626, time taken: 0.9309685627619425 mins\n"
     ]
    }
   ],
   "source": [
    "proj_dim = 128\n",
    "model = SimClr('resnet50',proj_dim).cuda()\n",
    "temperature = 0.5\n",
    "#criterion = nt_xent_loss\n",
    "criterion = SimCLR_Loss(128,0.5)\n",
    "optimizer = \"Adam\"\n",
    "model, train_loss = train_simclr(train_loader_simclr,model,criterion,optimizer,100,128,True,\"/home/ky2446/saved-models/CIFAR10-RES50-SIMCLR-BS128-PD128-ADAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6607168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"NT-XENT Loss\")\n",
    "plt.title(\"CIFAR10 ResNet-50 SimClr BS:128, OP: Adam\")\n",
    "plt.plot(train_loss)\n",
    "plt.savefig(\"/home/ky2446/figures/CIFAR10-RES50-SIMCLR-BS128-PD128-ADAM.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
