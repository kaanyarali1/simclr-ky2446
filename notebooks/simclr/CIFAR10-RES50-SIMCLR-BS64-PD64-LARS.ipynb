{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2404b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# setting path\n",
    "sys.path.append(\"/home/ky2446/simclr\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/layers\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/models\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/loss\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/optim\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/dataloader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24671858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simclrpy import SimClr\n",
    "from ntxent import nt_xent_loss\n",
    "from ntxentgit import SimCLR_Loss\n",
    "from augment import TransformsSimCLR\n",
    "from utils import *\n",
    "from LARS import LARS\n",
    "from downstream import DownStream\n",
    "from dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a724a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ed8179c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader_simclr = train_loader_simclr(\"CIFAR10\",64)\n",
    "test_loader = test_loader(\"CIFAR10\",64)\n",
    "test_images, test_labels = get_testimgs_list(\"CIFAR10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be5a0956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ky2446/simclr/simclr/optim/LARS.py:136: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272178570/work/torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
      "  next_v.mul_(momentum).add_(scaled_lr, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, step: 50/781, loss: 4.843530178070068\n",
      "Epoch: 0, step: 100/781, loss: 4.822958469390869\n",
      "Epoch: 0, step: 150/781, loss: 4.797622203826904\n",
      "Epoch: 0, step: 200/781, loss: 4.747465133666992\n",
      "Epoch: 0, step: 250/781, loss: 4.803780555725098\n",
      "Epoch: 0, step: 300/781, loss: 4.7117133140563965\n",
      "Epoch: 0, step: 350/781, loss: 4.781681537628174\n",
      "Epoch: 0, step: 400/781, loss: 4.650078296661377\n",
      "Epoch: 0, step: 450/781, loss: 4.601426124572754\n",
      "Epoch: 0, step: 500/781, loss: 4.765931606292725\n",
      "Epoch: 0, step: 550/781, loss: 4.735428333282471\n",
      "Epoch: 0, step: 600/781, loss: 4.773936748504639\n",
      "Epoch: 0, step: 650/781, loss: 4.670652389526367\n",
      "Epoch: 0, step: 700/781, loss: 4.537928581237793\n",
      "Epoch: 0, step: 750/781, loss: 4.487289905548096\n",
      "Epoch: 0 completed, average loss: 4.722154781546696, time taken: 1.563093900680542 mins\n",
      "Epoch: 1, step: 50/781, loss: 4.5180511474609375\n",
      "Epoch: 1, step: 100/781, loss: 4.449725151062012\n",
      "Epoch: 1, step: 150/781, loss: 4.475844383239746\n",
      "Epoch: 1, step: 200/781, loss: 4.517467498779297\n",
      "Epoch: 1, step: 250/781, loss: 4.610311985015869\n",
      "Epoch: 1, step: 300/781, loss: 4.497966289520264\n",
      "Epoch: 1, step: 350/781, loss: 4.5562543869018555\n",
      "Epoch: 1, step: 400/781, loss: 4.300105094909668\n",
      "Epoch: 1, step: 450/781, loss: 4.287399768829346\n",
      "Epoch: 1, step: 500/781, loss: 4.699551105499268\n",
      "Epoch: 1, step: 550/781, loss: 4.3427414894104\n",
      "Epoch: 1, step: 600/781, loss: 4.415960788726807\n",
      "Epoch: 1, step: 650/781, loss: 4.2822794914245605\n",
      "Epoch: 1, step: 700/781, loss: 4.348025798797607\n",
      "Epoch: 1, step: 750/781, loss: 4.334409713745117\n",
      "Epoch: 1 completed, average loss: 4.471093001347345, time taken: 1.5536410570144654 mins\n",
      "Epoch: 2, step: 50/781, loss: 4.397507190704346\n",
      "Epoch: 2, step: 100/781, loss: 4.391139030456543\n",
      "Epoch: 2, step: 150/781, loss: 4.396671295166016\n",
      "Epoch: 2, step: 200/781, loss: 4.259359836578369\n",
      "Epoch: 2, step: 250/781, loss: 4.36132287979126\n",
      "Epoch: 2, step: 300/781, loss: 4.329649448394775\n",
      "Epoch: 2, step: 350/781, loss: 4.438384532928467\n",
      "Epoch: 2, step: 400/781, loss: 4.251744747161865\n",
      "Epoch: 2, step: 450/781, loss: 4.34060001373291\n",
      "Epoch: 2, step: 500/781, loss: 4.317135810852051\n",
      "Epoch: 2, step: 550/781, loss: 4.229837417602539\n",
      "Epoch: 2, step: 600/781, loss: 4.235466957092285\n",
      "Epoch: 2, step: 650/781, loss: 4.39175271987915\n",
      "Epoch: 2, step: 700/781, loss: 4.16370153427124\n",
      "Epoch: 2, step: 750/781, loss: 4.260411262512207\n",
      "Epoch: 2 completed, average loss: 4.311365698424863, time taken: 1.5519051988919577 mins\n",
      "Epoch: 3, step: 50/781, loss: 4.154374599456787\n",
      "Epoch: 3, step: 100/781, loss: 4.250304698944092\n",
      "Epoch: 3, step: 150/781, loss: 4.371739387512207\n",
      "Epoch: 3, step: 200/781, loss: 4.00374698638916\n",
      "Epoch: 3, step: 250/781, loss: 4.3606367111206055\n",
      "Epoch: 3, step: 300/781, loss: 4.226711273193359\n",
      "Epoch: 3, step: 350/781, loss: 4.279383182525635\n",
      "Epoch: 3, step: 400/781, loss: 4.337272644042969\n",
      "Epoch: 3, step: 450/781, loss: 4.261546611785889\n",
      "Epoch: 3, step: 500/781, loss: 4.2334160804748535\n",
      "Epoch: 3, step: 550/781, loss: 4.113314151763916\n",
      "Epoch: 3, step: 600/781, loss: 4.139459609985352\n",
      "Epoch: 3, step: 650/781, loss: 4.187556266784668\n",
      "Epoch: 3, step: 700/781, loss: 4.0493597984313965\n",
      "Epoch: 3, step: 750/781, loss: 4.148148536682129\n",
      "Epoch: 3 completed, average loss: 4.207260404139872, time taken: 1.5515164335568745 mins\n",
      "Epoch: 4, step: 50/781, loss: 3.966215133666992\n",
      "Epoch: 4, step: 100/781, loss: 4.254190444946289\n",
      "Epoch: 4, step: 150/781, loss: 4.227138519287109\n",
      "Epoch: 4, step: 200/781, loss: 4.232961177825928\n",
      "Epoch: 4, step: 250/781, loss: 4.196771621704102\n",
      "Epoch: 4, step: 300/781, loss: 4.0638346672058105\n",
      "Epoch: 4, step: 350/781, loss: 4.127202987670898\n",
      "Epoch: 4, step: 400/781, loss: 4.0452775955200195\n",
      "Epoch: 4, step: 450/781, loss: 4.19473123550415\n",
      "Epoch: 4, step: 500/781, loss: 4.073159694671631\n",
      "Epoch: 4, step: 550/781, loss: 4.25116491317749\n",
      "Epoch: 4, step: 600/781, loss: 4.147405624389648\n",
      "Epoch: 4, step: 650/781, loss: 4.185753345489502\n",
      "Epoch: 4, step: 700/781, loss: 4.093012809753418\n",
      "Epoch: 4, step: 750/781, loss: 4.125601291656494\n",
      "Epoch: 4 completed, average loss: 4.114690637161118, time taken: 1.5536243041356406 mins\n",
      "Epoch: 5, step: 50/781, loss: 4.191314697265625\n",
      "Epoch: 5, step: 100/781, loss: 4.13667106628418\n",
      "Epoch: 5, step: 150/781, loss: 4.23349142074585\n",
      "Epoch: 5, step: 200/781, loss: 4.057234287261963\n",
      "Epoch: 5, step: 250/781, loss: 4.066826820373535\n",
      "Epoch: 5, step: 300/781, loss: 3.8775763511657715\n",
      "Epoch: 5, step: 350/781, loss: 4.016664505004883\n",
      "Epoch: 5, step: 400/781, loss: 4.258892059326172\n",
      "Epoch: 5, step: 450/781, loss: 3.965068817138672\n",
      "Epoch: 5, step: 500/781, loss: 4.124870300292969\n",
      "Epoch: 5, step: 550/781, loss: 3.995157241821289\n",
      "Epoch: 5, step: 600/781, loss: 4.026650905609131\n",
      "Epoch: 5, step: 650/781, loss: 4.164985179901123\n",
      "Epoch: 5, step: 700/781, loss: 3.9432053565979004\n",
      "Epoch: 5, step: 750/781, loss: 4.077124118804932\n",
      "Epoch: 5 completed, average loss: 4.0411017026547125, time taken: 1.55793749888738 mins\n",
      "Epoch: 6, step: 50/781, loss: 3.9473788738250732\n",
      "Epoch: 6, step: 100/781, loss: 4.026544094085693\n",
      "Epoch: 6, step: 150/781, loss: 3.863628387451172\n",
      "Epoch: 6, step: 200/781, loss: 4.1270599365234375\n",
      "Epoch: 6, step: 250/781, loss: 3.895066738128662\n",
      "Epoch: 6, step: 300/781, loss: 4.018928527832031\n",
      "Epoch: 6, step: 350/781, loss: 3.8558528423309326\n",
      "Epoch: 6, step: 400/781, loss: 3.8746283054351807\n",
      "Epoch: 6, step: 450/781, loss: 4.011600017547607\n",
      "Epoch: 6, step: 500/781, loss: 3.8817906379699707\n",
      "Epoch: 6, step: 550/781, loss: 3.996903657913208\n",
      "Epoch: 6, step: 600/781, loss: 3.950413703918457\n",
      "Epoch: 6, step: 650/781, loss: 4.002634048461914\n",
      "Epoch: 6, step: 700/781, loss: 3.8887600898742676\n",
      "Epoch: 6, step: 750/781, loss: 3.934002637863159\n",
      "Epoch: 6 completed, average loss: 3.9866920128064027, time taken: 1.5532889525095621 mins\n",
      "Epoch: 7, step: 50/781, loss: 3.956225633621216\n",
      "Epoch: 7, step: 100/781, loss: 3.960008144378662\n",
      "Epoch: 7, step: 150/781, loss: 3.8904056549072266\n",
      "Epoch: 7, step: 200/781, loss: 3.9150712490081787\n",
      "Epoch: 7, step: 250/781, loss: 4.133031368255615\n",
      "Epoch: 7, step: 300/781, loss: 3.858234405517578\n",
      "Epoch: 7, step: 350/781, loss: 3.948310613632202\n",
      "Epoch: 7, step: 400/781, loss: 4.087009906768799\n",
      "Epoch: 7, step: 450/781, loss: 3.8192696571350098\n",
      "Epoch: 7, step: 500/781, loss: 3.7599575519561768\n",
      "Epoch: 7, step: 550/781, loss: 3.897691488265991\n",
      "Epoch: 7, step: 600/781, loss: 3.8974714279174805\n",
      "Epoch: 7, step: 650/781, loss: 3.979081392288208\n",
      "Epoch: 7, step: 700/781, loss: 3.9721410274505615\n",
      "Epoch: 7, step: 750/781, loss: 3.7692794799804688\n",
      "Epoch: 7 completed, average loss: 3.9390969615281772, time taken: 1.5596081773440043 mins\n",
      "Epoch: 8, step: 50/781, loss: 3.8334949016571045\n",
      "Epoch: 8, step: 100/781, loss: 3.9353015422821045\n",
      "Epoch: 8, step: 150/781, loss: 3.9588565826416016\n",
      "Epoch: 8, step: 200/781, loss: 4.004052639007568\n",
      "Epoch: 8, step: 250/781, loss: 4.065521240234375\n",
      "Epoch: 8, step: 300/781, loss: 3.8208889961242676\n",
      "Epoch: 8, step: 350/781, loss: 3.905090808868408\n",
      "Epoch: 8, step: 400/781, loss: 3.9041225910186768\n",
      "Epoch: 8, step: 450/781, loss: 3.7911994457244873\n",
      "Epoch: 8, step: 500/781, loss: 3.8688528537750244\n",
      "Epoch: 8, step: 550/781, loss: 3.8958539962768555\n",
      "Epoch: 8, step: 600/781, loss: 3.794593095779419\n",
      "Epoch: 8, step: 650/781, loss: 3.8859474658966064\n",
      "Epoch: 8, step: 700/781, loss: 3.8353965282440186\n",
      "Epoch: 8, step: 750/781, loss: 3.931274652481079\n",
      "Epoch: 8 completed, average loss: 3.9043846124265627, time taken: 1.5517693320910135 mins\n",
      "Epoch: 9, step: 50/781, loss: 3.905304193496704\n",
      "Epoch: 9, step: 100/781, loss: 3.9652228355407715\n",
      "Epoch: 9, step: 150/781, loss: 3.9206466674804688\n",
      "Epoch: 9, step: 200/781, loss: 3.803715705871582\n",
      "Epoch: 9, step: 250/781, loss: 4.039433479309082\n",
      "Epoch: 9, step: 300/781, loss: 3.8352532386779785\n",
      "Epoch: 9, step: 350/781, loss: 3.9409358501434326\n",
      "Epoch: 9, step: 400/781, loss: 3.8359293937683105\n",
      "Epoch: 9, step: 450/781, loss: 3.9237313270568848\n",
      "Epoch: 9, step: 500/781, loss: 3.870990514755249\n",
      "Epoch: 9, step: 550/781, loss: 3.8316264152526855\n",
      "Epoch: 9, step: 600/781, loss: 3.859278917312622\n",
      "Epoch: 9, step: 650/781, loss: 3.7981295585632324\n",
      "Epoch: 9, step: 700/781, loss: 3.8805058002471924\n",
      "Epoch: 9, step: 750/781, loss: 3.752925395965576\n",
      "Epoch: 9 completed, average loss: 3.872402290375987, time taken: 1.5532919049263 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, step: 50/781, loss: 3.8781254291534424\n",
      "Epoch: 10, step: 100/781, loss: 4.048069953918457\n",
      "Epoch: 10, step: 150/781, loss: 3.897671699523926\n",
      "Epoch: 10, step: 200/781, loss: 4.026020526885986\n",
      "Epoch: 10, step: 250/781, loss: 3.7982077598571777\n",
      "Epoch: 10, step: 300/781, loss: 3.8708059787750244\n",
      "Epoch: 10, step: 350/781, loss: 3.8085947036743164\n",
      "Epoch: 10, step: 400/781, loss: 3.78415846824646\n",
      "Epoch: 10, step: 450/781, loss: 3.816857099533081\n",
      "Epoch: 10, step: 500/781, loss: 3.978353261947632\n",
      "Epoch: 10, step: 550/781, loss: 3.8009371757507324\n",
      "Epoch: 10, step: 600/781, loss: 4.037231922149658\n",
      "Epoch: 10, step: 650/781, loss: 3.9810802936553955\n",
      "Epoch: 10, step: 700/781, loss: 3.7048864364624023\n",
      "Epoch: 10, step: 750/781, loss: 3.878308057785034\n",
      "Epoch: 10 completed, average loss: 3.844144400500152, time taken: 1.549321452776591 mins\n",
      "Epoch: 11, step: 50/781, loss: 3.857409954071045\n",
      "Epoch: 11, step: 100/781, loss: 3.7833683490753174\n",
      "Epoch: 11, step: 150/781, loss: 3.7908036708831787\n",
      "Epoch: 11, step: 200/781, loss: 3.781248092651367\n",
      "Epoch: 11, step: 250/781, loss: 3.7395200729370117\n",
      "Epoch: 11, step: 300/781, loss: 3.6881601810455322\n",
      "Epoch: 11, step: 350/781, loss: 3.7353947162628174\n",
      "Epoch: 11, step: 400/781, loss: 3.830734968185425\n",
      "Epoch: 11, step: 450/781, loss: 3.8355112075805664\n",
      "Epoch: 11, step: 500/781, loss: 3.7383334636688232\n",
      "Epoch: 11, step: 550/781, loss: 3.8818769454956055\n",
      "Epoch: 11, step: 600/781, loss: 3.7877063751220703\n",
      "Epoch: 11, step: 650/781, loss: 3.7930383682250977\n",
      "Epoch: 11, step: 700/781, loss: 3.9000000953674316\n",
      "Epoch: 11, step: 750/781, loss: 3.688636541366577\n",
      "Epoch: 11 completed, average loss: 3.821641293438998, time taken: 1.5517363627751668 mins\n",
      "Epoch: 12, step: 50/781, loss: 3.736239194869995\n",
      "Epoch: 12, step: 100/781, loss: 3.9364960193634033\n",
      "Epoch: 12, step: 150/781, loss: 3.899822235107422\n",
      "Epoch: 12, step: 200/781, loss: 3.950392961502075\n",
      "Epoch: 12, step: 250/781, loss: 3.768601894378662\n",
      "Epoch: 12, step: 300/781, loss: 3.736225128173828\n",
      "Epoch: 12, step: 350/781, loss: 3.7921555042266846\n",
      "Epoch: 12, step: 400/781, loss: 3.932852268218994\n",
      "Epoch: 12, step: 450/781, loss: 3.9034132957458496\n",
      "Epoch: 12, step: 500/781, loss: 3.8014185428619385\n",
      "Epoch: 12, step: 550/781, loss: 3.7794244289398193\n",
      "Epoch: 12, step: 600/781, loss: 3.759028911590576\n",
      "Epoch: 12, step: 650/781, loss: 3.7403550148010254\n",
      "Epoch: 12, step: 700/781, loss: 3.767092704772949\n",
      "Epoch: 12, step: 750/781, loss: 3.7760965824127197\n",
      "Epoch: 12 completed, average loss: 3.796884388380258, time taken: 1.5539789517720541 mins\n",
      "Epoch: 13, step: 50/781, loss: 3.74914288520813\n",
      "Epoch: 13, step: 100/781, loss: 3.7621219158172607\n",
      "Epoch: 13, step: 150/781, loss: 3.889786958694458\n",
      "Epoch: 13, step: 200/781, loss: 3.9207160472869873\n",
      "Epoch: 13, step: 250/781, loss: 3.7878377437591553\n",
      "Epoch: 13, step: 300/781, loss: 3.77836537361145\n",
      "Epoch: 13, step: 350/781, loss: 3.759612798690796\n",
      "Epoch: 13, step: 400/781, loss: 3.7329697608947754\n",
      "Epoch: 13, step: 450/781, loss: 3.7304883003234863\n",
      "Epoch: 13, step: 500/781, loss: 3.6904056072235107\n",
      "Epoch: 13, step: 550/781, loss: 3.775127649307251\n",
      "Epoch: 13, step: 600/781, loss: 3.775057077407837\n",
      "Epoch: 13, step: 650/781, loss: 3.7950305938720703\n",
      "Epoch: 13, step: 700/781, loss: 3.6852149963378906\n",
      "Epoch: 13, step: 750/781, loss: 3.8748037815093994\n",
      "Epoch: 13 completed, average loss: 3.7747770103693923, time taken: 1.5524885813395182 mins\n",
      "Epoch: 14, step: 50/781, loss: 3.671360731124878\n",
      "Epoch: 14, step: 100/781, loss: 3.8682847023010254\n",
      "Epoch: 14, step: 150/781, loss: 3.74650239944458\n",
      "Epoch: 14, step: 200/781, loss: 3.826179265975952\n",
      "Epoch: 14, step: 250/781, loss: 3.7600021362304688\n",
      "Epoch: 14, step: 300/781, loss: 3.8670194149017334\n",
      "Epoch: 14, step: 350/781, loss: 3.723590612411499\n",
      "Epoch: 14, step: 400/781, loss: 3.766148090362549\n",
      "Epoch: 14, step: 450/781, loss: 3.7651350498199463\n",
      "Epoch: 14, step: 500/781, loss: 3.8772881031036377\n",
      "Epoch: 14, step: 550/781, loss: 3.807065486907959\n",
      "Epoch: 14, step: 600/781, loss: 3.702244281768799\n",
      "Epoch: 14, step: 650/781, loss: 3.7609329223632812\n",
      "Epoch: 14, step: 700/781, loss: 3.7444264888763428\n",
      "Epoch: 14, step: 750/781, loss: 3.658949375152588\n",
      "Epoch: 14 completed, average loss: 3.755213285072512, time taken: 1.5524377822875977 mins\n",
      "Epoch: 15, step: 50/781, loss: 3.7847988605499268\n",
      "Epoch: 15, step: 100/781, loss: 3.7592110633850098\n",
      "Epoch: 15, step: 150/781, loss: 3.6722841262817383\n",
      "Epoch: 15, step: 200/781, loss: 3.7187747955322266\n",
      "Epoch: 15, step: 250/781, loss: 3.697843551635742\n",
      "Epoch: 15, step: 300/781, loss: 3.6934471130371094\n",
      "Epoch: 15, step: 350/781, loss: 3.6545650959014893\n",
      "Epoch: 15, step: 400/781, loss: 3.714402914047241\n",
      "Epoch: 15, step: 450/781, loss: 3.8567259311676025\n",
      "Epoch: 15, step: 500/781, loss: 3.7335381507873535\n",
      "Epoch: 15, step: 550/781, loss: 3.718963146209717\n",
      "Epoch: 15, step: 600/781, loss: 3.593235492706299\n",
      "Epoch: 15, step: 650/781, loss: 3.6737678050994873\n",
      "Epoch: 15, step: 700/781, loss: 3.7127978801727295\n",
      "Epoch: 15, step: 750/781, loss: 3.8488922119140625\n",
      "Epoch: 15 completed, average loss: 3.725272506513608, time taken: 1.55182280143102 mins\n",
      "Epoch: 16, step: 50/781, loss: 3.7460083961486816\n",
      "Epoch: 16, step: 100/781, loss: 3.6884894371032715\n",
      "Epoch: 16, step: 150/781, loss: 3.7435011863708496\n",
      "Epoch: 16, step: 200/781, loss: 3.7288503646850586\n",
      "Epoch: 16, step: 250/781, loss: 3.7039687633514404\n",
      "Epoch: 16, step: 300/781, loss: 3.7048943042755127\n",
      "Epoch: 16, step: 350/781, loss: 3.663245916366577\n",
      "Epoch: 16, step: 400/781, loss: 3.7126290798187256\n",
      "Epoch: 16, step: 450/781, loss: 3.6975905895233154\n",
      "Epoch: 16, step: 500/781, loss: 3.7256579399108887\n",
      "Epoch: 16, step: 550/781, loss: 3.7399301528930664\n",
      "Epoch: 16, step: 600/781, loss: 3.695283889770508\n",
      "Epoch: 16, step: 650/781, loss: 3.6603527069091797\n",
      "Epoch: 16, step: 700/781, loss: 3.6442625522613525\n",
      "Epoch: 16, step: 750/781, loss: 3.6995630264282227\n",
      "Epoch: 16 completed, average loss: 3.7086112032168654, time taken: 1.550984752178192 mins\n",
      "Epoch: 17, step: 50/781, loss: 3.693751335144043\n",
      "Epoch: 17, step: 100/781, loss: 3.777405023574829\n",
      "Epoch: 17, step: 150/781, loss: 3.6692147254943848\n",
      "Epoch: 17, step: 200/781, loss: 3.7147042751312256\n",
      "Epoch: 17, step: 250/781, loss: 3.7075681686401367\n",
      "Epoch: 17, step: 300/781, loss: 3.8291735649108887\n",
      "Epoch: 17, step: 350/781, loss: 3.6960091590881348\n",
      "Epoch: 17, step: 400/781, loss: 3.586343288421631\n",
      "Epoch: 17, step: 450/781, loss: 3.854827404022217\n",
      "Epoch: 17, step: 500/781, loss: 3.661998987197876\n",
      "Epoch: 17, step: 550/781, loss: 3.7219064235687256\n",
      "Epoch: 17, step: 600/781, loss: 3.7012171745300293\n",
      "Epoch: 17, step: 650/781, loss: 3.7161953449249268\n",
      "Epoch: 17, step: 700/781, loss: 3.6841306686401367\n",
      "Epoch: 17, step: 750/781, loss: 3.607215166091919\n",
      "Epoch: 17 completed, average loss: 3.696379557767079, time taken: 1.5529550592104593 mins\n",
      "Epoch: 18, step: 50/781, loss: 3.7476143836975098\n",
      "Epoch: 18, step: 100/781, loss: 3.6147263050079346\n",
      "Epoch: 18, step: 150/781, loss: 3.5919880867004395\n",
      "Epoch: 18, step: 200/781, loss: 3.6160495281219482\n",
      "Epoch: 18, step: 250/781, loss: 3.738004207611084\n",
      "Epoch: 18, step: 300/781, loss: 3.727707862854004\n",
      "Epoch: 18, step: 350/781, loss: 3.7530698776245117\n",
      "Epoch: 18, step: 400/781, loss: 3.714719772338867\n",
      "Epoch: 18, step: 450/781, loss: 3.73852801322937\n",
      "Epoch: 18, step: 500/781, loss: 3.79641056060791\n",
      "Epoch: 18, step: 550/781, loss: 3.805267095565796\n",
      "Epoch: 18, step: 600/781, loss: 3.65159010887146\n",
      "Epoch: 18, step: 650/781, loss: 3.677299976348877\n",
      "Epoch: 18, step: 700/781, loss: 3.678394079208374\n",
      "Epoch: 18, step: 750/781, loss: 3.654392957687378\n",
      "Epoch: 18 completed, average loss: 3.6822783846250724, time taken: 1.5514062563578288 mins\n",
      "Epoch: 19, step: 50/781, loss: 3.709807872772217\n",
      "Epoch: 19, step: 100/781, loss: 3.6713221073150635\n",
      "Epoch: 19, step: 150/781, loss: 3.6687841415405273\n",
      "Epoch: 19, step: 200/781, loss: 3.601790428161621\n",
      "Epoch: 19, step: 250/781, loss: 3.6614270210266113\n",
      "Epoch: 19, step: 300/781, loss: 3.5635311603546143\n",
      "Epoch: 19, step: 350/781, loss: 3.598057270050049\n",
      "Epoch: 19, step: 400/781, loss: 3.5889174938201904\n",
      "Epoch: 19, step: 450/781, loss: 3.6583433151245117\n",
      "Epoch: 19, step: 500/781, loss: 3.638101577758789\n",
      "Epoch: 19, step: 550/781, loss: 3.7132880687713623\n",
      "Epoch: 19, step: 600/781, loss: 3.5989184379577637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, step: 650/781, loss: 3.66091251373291\n",
      "Epoch: 19, step: 700/781, loss: 3.6247684955596924\n",
      "Epoch: 19, step: 750/781, loss: 3.6117563247680664\n",
      "Epoch: 19 completed, average loss: 3.6646373769537894, time taken: 1.5532511472702026 mins\n",
      "Epoch: 20, step: 50/781, loss: 3.768737316131592\n",
      "Epoch: 20, step: 100/781, loss: 3.688645601272583\n",
      "Epoch: 20, step: 150/781, loss: 3.831454277038574\n",
      "Epoch: 20, step: 200/781, loss: 3.6320180892944336\n",
      "Epoch: 20, step: 250/781, loss: 3.609309673309326\n",
      "Epoch: 20, step: 300/781, loss: 3.591216564178467\n",
      "Epoch: 20, step: 350/781, loss: 3.590656042098999\n",
      "Epoch: 20, step: 400/781, loss: 3.637171983718872\n",
      "Epoch: 20, step: 450/781, loss: 3.7418458461761475\n",
      "Epoch: 20, step: 500/781, loss: 3.595303535461426\n",
      "Epoch: 20, step: 550/781, loss: 3.701089382171631\n",
      "Epoch: 20, step: 600/781, loss: 3.739346981048584\n",
      "Epoch: 20, step: 650/781, loss: 3.669617176055908\n",
      "Epoch: 20, step: 700/781, loss: 3.624412775039673\n",
      "Epoch: 20, step: 750/781, loss: 3.723264694213867\n",
      "Epoch: 20 completed, average loss: 3.649352263549531, time taken: 1.5558535655339558 mins\n",
      "Epoch: 21, step: 50/781, loss: 3.679997205734253\n",
      "Epoch: 21, step: 100/781, loss: 3.6432676315307617\n",
      "Epoch: 21, step: 150/781, loss: 3.5998780727386475\n",
      "Epoch: 21, step: 200/781, loss: 3.5305566787719727\n",
      "Epoch: 21, step: 250/781, loss: 3.5726399421691895\n",
      "Epoch: 21, step: 300/781, loss: 3.704366445541382\n",
      "Epoch: 21, step: 350/781, loss: 3.6565613746643066\n",
      "Epoch: 21, step: 400/781, loss: 3.573695659637451\n",
      "Epoch: 21, step: 450/781, loss: 3.6337697505950928\n",
      "Epoch: 21, step: 500/781, loss: 3.6041038036346436\n",
      "Epoch: 21, step: 550/781, loss: 3.487945079803467\n",
      "Epoch: 21, step: 600/781, loss: 3.5144007205963135\n",
      "Epoch: 21, step: 650/781, loss: 3.5879509449005127\n",
      "Epoch: 21, step: 700/781, loss: 3.576184034347534\n",
      "Epoch: 21, step: 750/781, loss: 3.6780662536621094\n",
      "Epoch: 21 completed, average loss: 3.6404785502430115, time taken: 1.5522997498512268 mins\n",
      "Epoch: 22, step: 50/781, loss: 3.648983955383301\n",
      "Epoch: 22, step: 100/781, loss: 3.684025526046753\n",
      "Epoch: 22, step: 150/781, loss: 3.72379207611084\n",
      "Epoch: 22, step: 200/781, loss: 3.826253890991211\n",
      "Epoch: 22, step: 250/781, loss: 3.589172601699829\n",
      "Epoch: 22, step: 300/781, loss: 3.662449598312378\n",
      "Epoch: 22, step: 350/781, loss: 3.6863601207733154\n",
      "Epoch: 22, step: 400/781, loss: 3.5969812870025635\n",
      "Epoch: 22, step: 450/781, loss: 3.5389721393585205\n",
      "Epoch: 22, step: 500/781, loss: 3.5602197647094727\n",
      "Epoch: 22, step: 550/781, loss: 3.6504108905792236\n",
      "Epoch: 22, step: 600/781, loss: 3.6183366775512695\n",
      "Epoch: 22, step: 650/781, loss: 3.7061197757720947\n",
      "Epoch: 22, step: 700/781, loss: 3.6048343181610107\n",
      "Epoch: 22, step: 750/781, loss: 3.5451276302337646\n",
      "Epoch: 22 completed, average loss: 3.6339715125466125, time taken: 1.552908194065094 mins\n",
      "Epoch: 23, step: 50/781, loss: 3.6282098293304443\n",
      "Epoch: 23, step: 100/781, loss: 3.7270395755767822\n",
      "Epoch: 23, step: 150/781, loss: 3.5603227615356445\n",
      "Epoch: 23, step: 200/781, loss: 3.600407600402832\n",
      "Epoch: 23, step: 250/781, loss: 3.569470167160034\n",
      "Epoch: 23, step: 300/781, loss: 3.638730049133301\n",
      "Epoch: 23, step: 350/781, loss: 3.5901026725769043\n",
      "Epoch: 23, step: 400/781, loss: 3.54681658744812\n",
      "Epoch: 23, step: 450/781, loss: 3.715463161468506\n",
      "Epoch: 23, step: 500/781, loss: 3.633227586746216\n",
      "Epoch: 23, step: 550/781, loss: 3.5616023540496826\n",
      "Epoch: 23, step: 600/781, loss: 3.6576733589172363\n",
      "Epoch: 23, step: 650/781, loss: 3.5637564659118652\n",
      "Epoch: 23, step: 700/781, loss: 3.564415216445923\n",
      "Epoch: 23, step: 750/781, loss: 3.6273748874664307\n",
      "Epoch: 23 completed, average loss: 3.621535958157001, time taken: 1.551677691936493 mins\n",
      "Epoch: 24, step: 50/781, loss: 3.6966898441314697\n",
      "Epoch: 24, step: 100/781, loss: 3.5863208770751953\n",
      "Epoch: 24, step: 150/781, loss: 3.6735951900482178\n",
      "Epoch: 24, step: 200/781, loss: 3.6069908142089844\n",
      "Epoch: 24, step: 250/781, loss: 3.505284547805786\n",
      "Epoch: 24, step: 300/781, loss: 3.6608669757843018\n",
      "Epoch: 24, step: 350/781, loss: 3.5470376014709473\n",
      "Epoch: 24, step: 400/781, loss: 3.621656656265259\n",
      "Epoch: 24, step: 450/781, loss: 3.641498565673828\n",
      "Epoch: 24, step: 500/781, loss: 3.5504791736602783\n",
      "Epoch: 24, step: 550/781, loss: 3.5824291706085205\n",
      "Epoch: 24, step: 600/781, loss: 3.5580430030822754\n",
      "Epoch: 24, step: 650/781, loss: 3.6122188568115234\n",
      "Epoch: 24, step: 700/781, loss: 3.575493097305298\n",
      "Epoch: 24, step: 750/781, loss: 3.648195505142212\n",
      "Epoch: 24 completed, average loss: 3.6111427202114834, time taken: 1.5505154291788736 mins\n",
      "Epoch: 25, step: 50/781, loss: 3.5731308460235596\n",
      "Epoch: 25, step: 100/781, loss: 3.5835232734680176\n",
      "Epoch: 25, step: 150/781, loss: 3.5851588249206543\n",
      "Epoch: 25, step: 200/781, loss: 3.5204803943634033\n",
      "Epoch: 25, step: 250/781, loss: 3.491489887237549\n",
      "Epoch: 25, step: 300/781, loss: 3.579364538192749\n",
      "Epoch: 25, step: 350/781, loss: 3.683051109313965\n",
      "Epoch: 25, step: 400/781, loss: 3.6090803146362305\n",
      "Epoch: 25, step: 450/781, loss: 3.6198058128356934\n",
      "Epoch: 25, step: 500/781, loss: 3.6227524280548096\n",
      "Epoch: 25, step: 550/781, loss: 3.6431338787078857\n",
      "Epoch: 25, step: 600/781, loss: 3.553896188735962\n",
      "Epoch: 25, step: 650/781, loss: 3.5668931007385254\n",
      "Epoch: 25, step: 700/781, loss: 3.609952449798584\n",
      "Epoch: 25, step: 750/781, loss: 3.5036089420318604\n",
      "Epoch: 25 completed, average loss: 3.6057939654581066, time taken: 1.552790927886963 mins\n",
      "Epoch: 26, step: 50/781, loss: 3.5672547817230225\n",
      "Epoch: 26, step: 100/781, loss: 3.5275416374206543\n",
      "Epoch: 26, step: 150/781, loss: 3.513808250427246\n",
      "Epoch: 26, step: 200/781, loss: 3.5903637409210205\n",
      "Epoch: 26, step: 250/781, loss: 3.626687526702881\n",
      "Epoch: 26, step: 300/781, loss: 3.5789954662323\n",
      "Epoch: 26, step: 350/781, loss: 3.5656800270080566\n",
      "Epoch: 26, step: 400/781, loss: 3.5818660259246826\n",
      "Epoch: 26, step: 450/781, loss: 3.630450963973999\n",
      "Epoch: 26, step: 500/781, loss: 3.606969118118286\n",
      "Epoch: 26, step: 550/781, loss: 3.5179460048675537\n",
      "Epoch: 26, step: 600/781, loss: 3.57918119430542\n",
      "Epoch: 26, step: 650/781, loss: 3.5211541652679443\n",
      "Epoch: 26, step: 700/781, loss: 3.6411850452423096\n",
      "Epoch: 26, step: 750/781, loss: 3.5627896785736084\n",
      "Epoch: 26 completed, average loss: 3.5981723132725714, time taken: 1.553090802828471 mins\n",
      "Epoch: 27, step: 50/781, loss: 3.519340991973877\n",
      "Epoch: 27, step: 100/781, loss: 3.686136484146118\n",
      "Epoch: 27, step: 150/781, loss: 3.5471677780151367\n",
      "Epoch: 27, step: 200/781, loss: 3.5824718475341797\n",
      "Epoch: 27, step: 250/781, loss: 3.689302921295166\n",
      "Epoch: 27, step: 300/781, loss: 3.63690447807312\n",
      "Epoch: 27, step: 350/781, loss: 3.666307210922241\n",
      "Epoch: 27, step: 400/781, loss: 3.446068286895752\n",
      "Epoch: 27, step: 450/781, loss: 3.5936169624328613\n",
      "Epoch: 27, step: 500/781, loss: 3.520094156265259\n",
      "Epoch: 27, step: 550/781, loss: 3.6768221855163574\n",
      "Epoch: 27, step: 600/781, loss: 3.5606255531311035\n",
      "Epoch: 27, step: 650/781, loss: 3.5399169921875\n",
      "Epoch: 27, step: 700/781, loss: 3.5325615406036377\n",
      "Epoch: 27, step: 750/781, loss: 3.556967258453369\n",
      "Epoch: 27 completed, average loss: 3.5908595135819437, time taken: 1.5502834518750508 mins\n",
      "Epoch: 28, step: 50/781, loss: 3.551323652267456\n",
      "Epoch: 28, step: 100/781, loss: 3.5592525005340576\n",
      "Epoch: 28, step: 150/781, loss: 3.7148125171661377\n",
      "Epoch: 28, step: 200/781, loss: 3.690213441848755\n",
      "Epoch: 28, step: 250/781, loss: 3.5700011253356934\n",
      "Epoch: 28, step: 300/781, loss: 3.5908937454223633\n",
      "Epoch: 28, step: 350/781, loss: 3.484772205352783\n",
      "Epoch: 28, step: 400/781, loss: 3.566524028778076\n",
      "Epoch: 28, step: 450/781, loss: 3.5492355823516846\n",
      "Epoch: 28, step: 500/781, loss: 3.5420138835906982\n",
      "Epoch: 28, step: 550/781, loss: 3.5099029541015625\n",
      "Epoch: 28, step: 600/781, loss: 3.6072916984558105\n",
      "Epoch: 28, step: 650/781, loss: 3.6049997806549072\n",
      "Epoch: 28, step: 700/781, loss: 3.5567612648010254\n",
      "Epoch: 28, step: 750/781, loss: 3.68162202835083\n",
      "Epoch: 28 completed, average loss: 3.5839590583659624, time taken: 1.55322105884552 mins\n",
      "Epoch: 29, step: 50/781, loss: 3.529369592666626\n",
      "Epoch: 29, step: 100/781, loss: 3.4875121116638184\n",
      "Epoch: 29, step: 150/781, loss: 3.5974020957946777\n",
      "Epoch: 29, step: 200/781, loss: 3.742990732192993\n",
      "Epoch: 29, step: 250/781, loss: 3.563136339187622\n",
      "Epoch: 29, step: 300/781, loss: 3.592085123062134\n",
      "Epoch: 29, step: 350/781, loss: 3.6898739337921143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, step: 400/781, loss: 3.4945850372314453\n",
      "Epoch: 29, step: 450/781, loss: 3.6351089477539062\n",
      "Epoch: 29, step: 500/781, loss: 3.636779308319092\n",
      "Epoch: 29, step: 550/781, loss: 3.6786932945251465\n",
      "Epoch: 29, step: 600/781, loss: 3.5777230262756348\n",
      "Epoch: 29, step: 650/781, loss: 3.730759620666504\n",
      "Epoch: 29, step: 700/781, loss: 3.558215618133545\n",
      "Epoch: 29, step: 750/781, loss: 3.62347412109375\n",
      "Epoch: 29 completed, average loss: 3.5788255748309186, time taken: 1.5527249495188395 mins\n",
      "Epoch: 30, step: 50/781, loss: 3.5182106494903564\n",
      "Epoch: 30, step: 100/781, loss: 3.59334397315979\n",
      "Epoch: 30, step: 150/781, loss: 3.56459903717041\n",
      "Epoch: 30, step: 200/781, loss: 3.509345769882202\n",
      "Epoch: 30, step: 250/781, loss: 3.548887014389038\n",
      "Epoch: 30, step: 300/781, loss: 3.5883219242095947\n",
      "Epoch: 30, step: 350/781, loss: 3.466919183731079\n",
      "Epoch: 30, step: 400/781, loss: 3.539268970489502\n",
      "Epoch: 30, step: 450/781, loss: 3.5792453289031982\n",
      "Epoch: 30, step: 500/781, loss: 3.5318503379821777\n",
      "Epoch: 30, step: 550/781, loss: 3.6557981967926025\n",
      "Epoch: 30, step: 600/781, loss: 3.5401275157928467\n",
      "Epoch: 30, step: 650/781, loss: 3.5940704345703125\n",
      "Epoch: 30, step: 700/781, loss: 3.6060256958007812\n",
      "Epoch: 30, step: 750/781, loss: 3.613744020462036\n",
      "Epoch: 30 completed, average loss: 3.5725740168372435, time taken: 1.5529991507530212 mins\n",
      "Epoch: 31, step: 50/781, loss: 3.53729248046875\n",
      "Epoch: 31, step: 100/781, loss: 3.4767210483551025\n",
      "Epoch: 31, step: 150/781, loss: 3.5874791145324707\n",
      "Epoch: 31, step: 200/781, loss: 3.6056854724884033\n",
      "Epoch: 31, step: 250/781, loss: 3.55198073387146\n",
      "Epoch: 31, step: 300/781, loss: 3.4959616661071777\n",
      "Epoch: 31, step: 350/781, loss: 3.5112409591674805\n",
      "Epoch: 31, step: 400/781, loss: 3.6013176441192627\n",
      "Epoch: 31, step: 450/781, loss: 3.578747510910034\n",
      "Epoch: 31, step: 500/781, loss: 3.6319146156311035\n",
      "Epoch: 31, step: 550/781, loss: 3.4941606521606445\n",
      "Epoch: 31, step: 600/781, loss: 3.6801488399505615\n",
      "Epoch: 31, step: 650/781, loss: 3.484367847442627\n",
      "Epoch: 31, step: 700/781, loss: 3.5888938903808594\n",
      "Epoch: 31, step: 750/781, loss: 3.5481674671173096\n",
      "Epoch: 31 completed, average loss: 3.5643963954207534, time taken: 1.552272633711497 mins\n",
      "Epoch: 32, step: 50/781, loss: 3.5672874450683594\n",
      "Epoch: 32, step: 100/781, loss: 3.614604949951172\n",
      "Epoch: 32, step: 150/781, loss: 3.6501803398132324\n",
      "Epoch: 32, step: 200/781, loss: 3.645132541656494\n",
      "Epoch: 32, step: 250/781, loss: 3.597259998321533\n",
      "Epoch: 32, step: 300/781, loss: 3.5178353786468506\n",
      "Epoch: 32, step: 350/781, loss: 3.456946849822998\n",
      "Epoch: 32, step: 400/781, loss: 3.6509499549865723\n",
      "Epoch: 32, step: 450/781, loss: 3.620803117752075\n",
      "Epoch: 32, step: 500/781, loss: 3.5433692932128906\n",
      "Epoch: 32, step: 550/781, loss: 3.5913350582122803\n",
      "Epoch: 32, step: 600/781, loss: 3.5398001670837402\n",
      "Epoch: 32, step: 650/781, loss: 3.501270055770874\n",
      "Epoch: 32, step: 700/781, loss: 3.601818561553955\n",
      "Epoch: 32, step: 750/781, loss: 3.5266354084014893\n",
      "Epoch: 32 completed, average loss: 3.561756283006656, time taken: 1.5544214487075805 mins\n",
      "Epoch: 33, step: 50/781, loss: 3.5604147911071777\n",
      "Epoch: 33, step: 100/781, loss: 3.5311951637268066\n",
      "Epoch: 33, step: 150/781, loss: 3.6004278659820557\n",
      "Epoch: 33, step: 200/781, loss: 3.531338930130005\n",
      "Epoch: 33, step: 250/781, loss: 3.5154244899749756\n",
      "Epoch: 33, step: 300/781, loss: 3.5694637298583984\n",
      "Epoch: 33, step: 350/781, loss: 3.5285677909851074\n",
      "Epoch: 33, step: 400/781, loss: 3.5105385780334473\n",
      "Epoch: 33, step: 450/781, loss: 3.529054880142212\n",
      "Epoch: 33, step: 500/781, loss: 3.4947195053100586\n",
      "Epoch: 33, step: 550/781, loss: 3.5301711559295654\n",
      "Epoch: 33, step: 600/781, loss: 3.607267141342163\n",
      "Epoch: 33, step: 650/781, loss: 3.5466864109039307\n",
      "Epoch: 33, step: 700/781, loss: 3.5397584438323975\n",
      "Epoch: 33, step: 750/781, loss: 3.6336567401885986\n",
      "Epoch: 33 completed, average loss: 3.556640949200424, time taken: 1.5595824241638183 mins\n",
      "Epoch: 34, step: 50/781, loss: 3.5982906818389893\n",
      "Epoch: 34, step: 100/781, loss: 3.645838975906372\n",
      "Epoch: 34, step: 150/781, loss: 3.514605760574341\n",
      "Epoch: 34, step: 200/781, loss: 3.5887160301208496\n",
      "Epoch: 34, step: 250/781, loss: 3.4812333583831787\n",
      "Epoch: 34, step: 300/781, loss: 3.5262324810028076\n",
      "Epoch: 34, step: 350/781, loss: 3.5352578163146973\n",
      "Epoch: 34, step: 400/781, loss: 3.5391736030578613\n",
      "Epoch: 34, step: 450/781, loss: 3.5445985794067383\n",
      "Epoch: 34, step: 500/781, loss: 3.5536680221557617\n",
      "Epoch: 34, step: 550/781, loss: 3.570234775543213\n",
      "Epoch: 34, step: 600/781, loss: 3.6710195541381836\n",
      "Epoch: 34, step: 650/781, loss: 3.488577365875244\n",
      "Epoch: 34, step: 700/781, loss: 3.5960938930511475\n",
      "Epoch: 34, step: 750/781, loss: 3.5894365310668945\n",
      "Epoch: 34 completed, average loss: 3.5511248951226895, time taken: 1.5509700218836466 mins\n",
      "Epoch: 35, step: 50/781, loss: 3.547337055206299\n",
      "Epoch: 35, step: 100/781, loss: 3.4715113639831543\n",
      "Epoch: 35, step: 150/781, loss: 3.535691738128662\n",
      "Epoch: 35, step: 200/781, loss: 3.5255136489868164\n",
      "Epoch: 35, step: 250/781, loss: 3.426588773727417\n",
      "Epoch: 35, step: 300/781, loss: 3.540651321411133\n",
      "Epoch: 35, step: 350/781, loss: 3.5100924968719482\n",
      "Epoch: 35, step: 400/781, loss: 3.5366697311401367\n",
      "Epoch: 35, step: 450/781, loss: 3.53818941116333\n",
      "Epoch: 35, step: 500/781, loss: 3.5863184928894043\n",
      "Epoch: 35, step: 550/781, loss: 3.5553455352783203\n",
      "Epoch: 35, step: 600/781, loss: 3.5774550437927246\n",
      "Epoch: 35, step: 650/781, loss: 3.4594147205352783\n",
      "Epoch: 35, step: 700/781, loss: 3.532454252243042\n",
      "Epoch: 35, step: 750/781, loss: 3.506417751312256\n",
      "Epoch: 35 completed, average loss: 3.5452056306577675, time taken: 1.551211122671763 mins\n",
      "Epoch: 36, step: 50/781, loss: 3.536024808883667\n",
      "Epoch: 36, step: 100/781, loss: 3.542318105697632\n",
      "Epoch: 36, step: 150/781, loss: 3.549232006072998\n",
      "Epoch: 36, step: 200/781, loss: 3.5835838317871094\n",
      "Epoch: 36, step: 250/781, loss: 3.5340404510498047\n",
      "Epoch: 36, step: 300/781, loss: 3.591684341430664\n",
      "Epoch: 36, step: 350/781, loss: 3.577397346496582\n",
      "Epoch: 36, step: 400/781, loss: 3.569112777709961\n",
      "Epoch: 36, step: 450/781, loss: 3.5341920852661133\n",
      "Epoch: 36, step: 500/781, loss: 3.590782880783081\n",
      "Epoch: 36, step: 550/781, loss: 3.531214475631714\n",
      "Epoch: 36, step: 600/781, loss: 3.470201015472412\n",
      "Epoch: 36, step: 650/781, loss: 3.553528308868408\n",
      "Epoch: 36, step: 700/781, loss: 3.44242525100708\n",
      "Epoch: 36, step: 750/781, loss: 3.5349490642547607\n",
      "Epoch: 36 completed, average loss: 3.5406264993201146, time taken: 1.5512385408083598 mins\n",
      "Epoch: 37, step: 50/781, loss: 3.5491743087768555\n",
      "Epoch: 37, step: 100/781, loss: 3.482675075531006\n",
      "Epoch: 37, step: 150/781, loss: 3.475611925125122\n",
      "Epoch: 37, step: 200/781, loss: 3.560454845428467\n",
      "Epoch: 37, step: 250/781, loss: 3.4663379192352295\n",
      "Epoch: 37, step: 300/781, loss: 3.5258567333221436\n",
      "Epoch: 37, step: 350/781, loss: 3.5681557655334473\n",
      "Epoch: 37, step: 400/781, loss: 3.578372001647949\n",
      "Epoch: 37, step: 450/781, loss: 3.6120479106903076\n",
      "Epoch: 37, step: 500/781, loss: 3.5531678199768066\n",
      "Epoch: 37, step: 550/781, loss: 3.5749523639678955\n",
      "Epoch: 37, step: 600/781, loss: 3.4640941619873047\n",
      "Epoch: 37, step: 650/781, loss: 3.514775276184082\n",
      "Epoch: 37, step: 700/781, loss: 3.5996363162994385\n",
      "Epoch: 37, step: 750/781, loss: 3.579379081726074\n",
      "Epoch: 37 completed, average loss: 3.5368113801665557, time taken: 1.5523688594500225 mins\n",
      "Epoch: 38, step: 50/781, loss: 3.5321030616760254\n",
      "Epoch: 38, step: 100/781, loss: 3.5039026737213135\n",
      "Epoch: 38, step: 150/781, loss: 3.445030927658081\n",
      "Epoch: 38, step: 200/781, loss: 3.479614734649658\n",
      "Epoch: 38, step: 250/781, loss: 3.489262342453003\n",
      "Epoch: 38, step: 300/781, loss: 3.58601975440979\n",
      "Epoch: 38, step: 350/781, loss: 3.5846123695373535\n",
      "Epoch: 38, step: 400/781, loss: 3.582960605621338\n",
      "Epoch: 38, step: 450/781, loss: 3.5355162620544434\n",
      "Epoch: 38, step: 500/781, loss: 3.5653860569000244\n",
      "Epoch: 38, step: 550/781, loss: 3.579493761062622\n",
      "Epoch: 38, step: 600/781, loss: 3.58296275138855\n",
      "Epoch: 38, step: 650/781, loss: 3.436405897140503\n",
      "Epoch: 38, step: 700/781, loss: 3.6078968048095703\n",
      "Epoch: 38, step: 750/781, loss: 3.475933313369751\n",
      "Epoch: 38 completed, average loss: 3.533204889175376, time taken: 1.5532835006713868 mins\n",
      "Epoch: 39, step: 50/781, loss: 3.4782190322875977\n",
      "Epoch: 39, step: 100/781, loss: 3.6221816539764404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, step: 150/781, loss: 3.4899566173553467\n",
      "Epoch: 39, step: 200/781, loss: 3.536442756652832\n",
      "Epoch: 39, step: 250/781, loss: 3.5557968616485596\n",
      "Epoch: 39, step: 300/781, loss: 3.520402669906616\n",
      "Epoch: 39, step: 350/781, loss: 3.5519142150878906\n",
      "Epoch: 39, step: 400/781, loss: 3.5372562408447266\n",
      "Epoch: 39, step: 450/781, loss: 3.4632551670074463\n",
      "Epoch: 39, step: 500/781, loss: 3.524106025695801\n",
      "Epoch: 39, step: 550/781, loss: 3.5379674434661865\n",
      "Epoch: 39, step: 600/781, loss: 3.5376172065734863\n",
      "Epoch: 39, step: 650/781, loss: 3.531787395477295\n",
      "Epoch: 39, step: 700/781, loss: 3.612990140914917\n",
      "Epoch: 39, step: 750/781, loss: 3.618516445159912\n",
      "Epoch: 39 completed, average loss: 3.5280080003408707, time taken: 1.549877111117045 mins\n",
      "Epoch: 40, step: 50/781, loss: 3.547140598297119\n",
      "Epoch: 40, step: 100/781, loss: 3.4574544429779053\n",
      "Epoch: 40, step: 150/781, loss: 3.5389621257781982\n",
      "Epoch: 40, step: 200/781, loss: 3.569620370864868\n",
      "Epoch: 40, step: 250/781, loss: 3.5445239543914795\n",
      "Epoch: 40, step: 300/781, loss: 3.609096050262451\n",
      "Epoch: 40, step: 350/781, loss: 3.5215156078338623\n",
      "Epoch: 40, step: 400/781, loss: 3.6934990882873535\n",
      "Epoch: 40, step: 450/781, loss: 3.5548436641693115\n",
      "Epoch: 40, step: 500/781, loss: 3.5428764820098877\n",
      "Epoch: 40, step: 550/781, loss: 3.5089187622070312\n",
      "Epoch: 40, step: 600/781, loss: 3.506129741668701\n",
      "Epoch: 40, step: 650/781, loss: 3.6304571628570557\n",
      "Epoch: 40, step: 700/781, loss: 3.504927635192871\n",
      "Epoch: 40, step: 750/781, loss: 3.527165412902832\n",
      "Epoch: 40 completed, average loss: 3.5247692048320696, time taken: 1.5499379873275756 mins\n",
      "Epoch: 41, step: 50/781, loss: 3.5496506690979004\n",
      "Epoch: 41, step: 100/781, loss: 3.5316896438598633\n",
      "Epoch: 41, step: 150/781, loss: 3.3878064155578613\n",
      "Epoch: 41, step: 200/781, loss: 3.4554193019866943\n",
      "Epoch: 41, step: 250/781, loss: 3.5285587310791016\n",
      "Epoch: 41, step: 300/781, loss: 3.6671764850616455\n",
      "Epoch: 41, step: 350/781, loss: 3.475884437561035\n",
      "Epoch: 41, step: 400/781, loss: 3.5657732486724854\n",
      "Epoch: 41, step: 450/781, loss: 3.538360834121704\n",
      "Epoch: 41, step: 500/781, loss: 3.565237283706665\n",
      "Epoch: 41, step: 550/781, loss: 3.525721788406372\n",
      "Epoch: 41, step: 600/781, loss: 3.488034963607788\n",
      "Epoch: 41, step: 650/781, loss: 3.4529950618743896\n",
      "Epoch: 41, step: 700/781, loss: 3.517479419708252\n",
      "Epoch: 41, step: 750/781, loss: 3.4144277572631836\n",
      "Epoch: 41 completed, average loss: 3.5220295399923485, time taken: 1.55330171585083 mins\n",
      "Epoch: 42, step: 50/781, loss: 3.480825662612915\n",
      "Epoch: 42, step: 100/781, loss: 3.4316065311431885\n",
      "Epoch: 42, step: 150/781, loss: 3.569498300552368\n",
      "Epoch: 42, step: 200/781, loss: 3.502667188644409\n",
      "Epoch: 42, step: 250/781, loss: 3.5331385135650635\n",
      "Epoch: 42, step: 300/781, loss: 3.4867076873779297\n",
      "Epoch: 42, step: 350/781, loss: 3.510467290878296\n",
      "Epoch: 42, step: 400/781, loss: 3.4978904724121094\n",
      "Epoch: 42, step: 450/781, loss: 3.432347059249878\n",
      "Epoch: 42, step: 500/781, loss: 3.5873420238494873\n",
      "Epoch: 42, step: 550/781, loss: 3.4418952465057373\n",
      "Epoch: 42, step: 600/781, loss: 3.587136745452881\n",
      "Epoch: 42, step: 650/781, loss: 3.5853593349456787\n",
      "Epoch: 42, step: 700/781, loss: 3.434990882873535\n",
      "Epoch: 42, step: 750/781, loss: 3.389308214187622\n",
      "Epoch: 42 completed, average loss: 3.518972010679648, time taken: 1.5536216616630554 mins\n",
      "Epoch: 43, step: 50/781, loss: 3.4639627933502197\n",
      "Epoch: 43, step: 100/781, loss: 3.5970969200134277\n",
      "Epoch: 43, step: 150/781, loss: 3.421614170074463\n",
      "Epoch: 43, step: 200/781, loss: 3.513154983520508\n",
      "Epoch: 43, step: 250/781, loss: 3.4810478687286377\n",
      "Epoch: 43, step: 300/781, loss: 3.5160579681396484\n",
      "Epoch: 43, step: 350/781, loss: 3.479865550994873\n",
      "Epoch: 43, step: 400/781, loss: 3.5796215534210205\n",
      "Epoch: 43, step: 450/781, loss: 3.4870450496673584\n",
      "Epoch: 43, step: 500/781, loss: 3.5033977031707764\n",
      "Epoch: 43, step: 550/781, loss: 3.601656198501587\n",
      "Epoch: 43, step: 600/781, loss: 3.5067849159240723\n",
      "Epoch: 43, step: 650/781, loss: 3.4475858211517334\n",
      "Epoch: 43, step: 700/781, loss: 3.444650650024414\n",
      "Epoch: 43, step: 750/781, loss: 3.4588282108306885\n",
      "Epoch: 43 completed, average loss: 3.515298466981602, time taken: 1.5572242776552836 mins\n",
      "Epoch: 44, step: 50/781, loss: 3.5270752906799316\n",
      "Epoch: 44, step: 100/781, loss: 3.4909420013427734\n",
      "Epoch: 44, step: 150/781, loss: 3.4348204135894775\n",
      "Epoch: 44, step: 200/781, loss: 3.500828742980957\n",
      "Epoch: 44, step: 250/781, loss: 3.5504415035247803\n",
      "Epoch: 44, step: 300/781, loss: 3.4704604148864746\n",
      "Epoch: 44, step: 350/781, loss: 3.6249427795410156\n",
      "Epoch: 44, step: 400/781, loss: 3.5252106189727783\n",
      "Epoch: 44, step: 450/781, loss: 3.5375959873199463\n",
      "Epoch: 44, step: 500/781, loss: 3.508140802383423\n",
      "Epoch: 44, step: 550/781, loss: 3.447567939758301\n",
      "Epoch: 44, step: 600/781, loss: 3.4231626987457275\n",
      "Epoch: 44, step: 650/781, loss: 3.5561904907226562\n",
      "Epoch: 44, step: 700/781, loss: 3.547034740447998\n",
      "Epoch: 44, step: 750/781, loss: 3.4938604831695557\n",
      "Epoch: 44 completed, average loss: 3.5104476019606548, time taken: 1.5510359247525534 mins\n",
      "Epoch: 45, step: 50/781, loss: 3.566058874130249\n",
      "Epoch: 45, step: 100/781, loss: 3.541398525238037\n",
      "Epoch: 45, step: 150/781, loss: 3.545072555541992\n",
      "Epoch: 45, step: 200/781, loss: 3.5381078720092773\n",
      "Epoch: 45, step: 250/781, loss: 3.5032050609588623\n",
      "Epoch: 45, step: 300/781, loss: 3.4727067947387695\n",
      "Epoch: 45, step: 350/781, loss: 3.4783029556274414\n",
      "Epoch: 45, step: 400/781, loss: 3.5211620330810547\n",
      "Epoch: 45, step: 450/781, loss: 3.5357441902160645\n",
      "Epoch: 45, step: 500/781, loss: 3.560129404067993\n",
      "Epoch: 45, step: 550/781, loss: 3.522454261779785\n",
      "Epoch: 45, step: 600/781, loss: 3.5313596725463867\n",
      "Epoch: 45, step: 650/781, loss: 3.4977216720581055\n",
      "Epoch: 45, step: 700/781, loss: 3.5165510177612305\n",
      "Epoch: 45, step: 750/781, loss: 3.501694679260254\n",
      "Epoch: 45 completed, average loss: 3.50751647601207, time taken: 1.550911577542623 mins\n",
      "Epoch: 46, step: 50/781, loss: 3.434967517852783\n",
      "Epoch: 46, step: 100/781, loss: 3.4318997859954834\n",
      "Epoch: 46, step: 150/781, loss: 3.563936948776245\n",
      "Epoch: 46, step: 200/781, loss: 3.4802029132843018\n",
      "Epoch: 46, step: 250/781, loss: 3.420182943344116\n",
      "Epoch: 46, step: 300/781, loss: 3.5460197925567627\n",
      "Epoch: 46, step: 350/781, loss: 3.547860622406006\n",
      "Epoch: 46, step: 400/781, loss: 3.4591846466064453\n",
      "Epoch: 46, step: 450/781, loss: 3.349871873855591\n",
      "Epoch: 46, step: 500/781, loss: 3.4412760734558105\n",
      "Epoch: 46, step: 550/781, loss: 3.443800449371338\n",
      "Epoch: 46, step: 600/781, loss: 3.4154365062713623\n",
      "Epoch: 46, step: 650/781, loss: 3.5730440616607666\n",
      "Epoch: 46, step: 700/781, loss: 3.55869197845459\n",
      "Epoch: 46, step: 750/781, loss: 3.5091359615325928\n",
      "Epoch: 46 completed, average loss: 3.5059340003205324, time taken: 1.5534974336624146 mins\n",
      "Epoch: 47, step: 50/781, loss: 3.528193235397339\n",
      "Epoch: 47, step: 100/781, loss: 3.4460248947143555\n",
      "Epoch: 47, step: 150/781, loss: 3.5550050735473633\n",
      "Epoch: 47, step: 200/781, loss: 3.463428020477295\n",
      "Epoch: 47, step: 250/781, loss: 3.481224775314331\n",
      "Epoch: 47, step: 300/781, loss: 3.4850401878356934\n",
      "Epoch: 47, step: 350/781, loss: 3.4494245052337646\n",
      "Epoch: 47, step: 400/781, loss: 3.4950454235076904\n",
      "Epoch: 47, step: 450/781, loss: 3.5328187942504883\n",
      "Epoch: 47, step: 500/781, loss: 3.5715279579162598\n",
      "Epoch: 47, step: 550/781, loss: 3.52866792678833\n",
      "Epoch: 47, step: 600/781, loss: 3.5514273643493652\n",
      "Epoch: 47, step: 650/781, loss: 3.450671672821045\n",
      "Epoch: 47, step: 700/781, loss: 3.496535301208496\n",
      "Epoch: 47, step: 750/781, loss: 3.4518935680389404\n",
      "Epoch: 47 completed, average loss: 3.5027069560086375, time taken: 1.5512135704358418 mins\n",
      "Epoch: 48, step: 50/781, loss: 3.466996908187866\n",
      "Epoch: 48, step: 100/781, loss: 3.446803092956543\n",
      "Epoch: 48, step: 150/781, loss: 3.525132656097412\n",
      "Epoch: 48, step: 200/781, loss: 3.5938868522644043\n",
      "Epoch: 48, step: 250/781, loss: 3.490471839904785\n",
      "Epoch: 48, step: 300/781, loss: 3.3995144367218018\n",
      "Epoch: 48, step: 350/781, loss: 3.495119094848633\n",
      "Epoch: 48, step: 400/781, loss: 3.4422049522399902\n",
      "Epoch: 48, step: 450/781, loss: 3.48199200630188\n",
      "Epoch: 48, step: 500/781, loss: 3.469679355621338\n",
      "Epoch: 48, step: 550/781, loss: 3.638327121734619\n",
      "Epoch: 48, step: 600/781, loss: 3.467221736907959\n",
      "Epoch: 48, step: 650/781, loss: 3.55773663520813\n",
      "Epoch: 48, step: 700/781, loss: 3.3827223777770996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, step: 750/781, loss: 3.445162534713745\n",
      "Epoch: 48 completed, average loss: 3.5011663928379932, time taken: 1.5553765694300334 mins\n",
      "Epoch: 49, step: 50/781, loss: 3.485962152481079\n",
      "Epoch: 49, step: 100/781, loss: 3.497652530670166\n",
      "Epoch: 49, step: 150/781, loss: 3.550025463104248\n",
      "Epoch: 49, step: 200/781, loss: 3.4824841022491455\n",
      "Epoch: 49, step: 250/781, loss: 3.5420339107513428\n",
      "Epoch: 49, step: 300/781, loss: 3.465829849243164\n",
      "Epoch: 49, step: 350/781, loss: 3.6196556091308594\n",
      "Epoch: 49, step: 400/781, loss: 3.5563461780548096\n",
      "Epoch: 49, step: 450/781, loss: 3.4904098510742188\n",
      "Epoch: 49, step: 500/781, loss: 3.555294990539551\n",
      "Epoch: 49, step: 550/781, loss: 3.441164493560791\n",
      "Epoch: 49, step: 600/781, loss: 3.424405574798584\n",
      "Epoch: 49, step: 650/781, loss: 3.444246292114258\n",
      "Epoch: 49, step: 700/781, loss: 3.4831769466400146\n",
      "Epoch: 49, step: 750/781, loss: 3.4491376876831055\n",
      "Epoch: 49 completed, average loss: 3.4960991960786827, time taken: 1.551851252714793 mins\n",
      "Epoch: 50, step: 50/781, loss: 3.5258004665374756\n",
      "Epoch: 50, step: 100/781, loss: 3.5055489540100098\n",
      "Epoch: 50, step: 150/781, loss: 3.4894211292266846\n",
      "Epoch: 50, step: 200/781, loss: 3.479644775390625\n",
      "Epoch: 50, step: 250/781, loss: 3.470028877258301\n",
      "Epoch: 50, step: 300/781, loss: 3.426145076751709\n",
      "Epoch: 50, step: 350/781, loss: 3.580425500869751\n",
      "Epoch: 50, step: 400/781, loss: 3.5484471321105957\n",
      "Epoch: 50, step: 450/781, loss: 3.4577677249908447\n",
      "Epoch: 50, step: 500/781, loss: 3.4323740005493164\n",
      "Epoch: 50, step: 550/781, loss: 3.5069165229797363\n",
      "Epoch: 50, step: 600/781, loss: 3.5732502937316895\n",
      "Epoch: 50, step: 650/781, loss: 3.5450007915496826\n",
      "Epoch: 50, step: 700/781, loss: 3.4872541427612305\n",
      "Epoch: 50, step: 750/781, loss: 3.5377254486083984\n",
      "Epoch: 50 completed, average loss: 3.495326250677072, time taken: 1.5536331256230673 mins\n",
      "Epoch: 51, step: 50/781, loss: 3.440262794494629\n",
      "Epoch: 51, step: 100/781, loss: 3.5233592987060547\n",
      "Epoch: 51, step: 150/781, loss: 3.446866035461426\n",
      "Epoch: 51, step: 200/781, loss: 3.5361785888671875\n",
      "Epoch: 51, step: 250/781, loss: 3.438115119934082\n",
      "Epoch: 51, step: 300/781, loss: 3.526935577392578\n",
      "Epoch: 51, step: 350/781, loss: 3.413214683532715\n",
      "Epoch: 51, step: 400/781, loss: 3.3959548473358154\n",
      "Epoch: 51, step: 450/781, loss: 3.5107169151306152\n",
      "Epoch: 51, step: 500/781, loss: 3.4849026203155518\n",
      "Epoch: 51, step: 550/781, loss: 3.4718830585479736\n",
      "Epoch: 51, step: 600/781, loss: 3.462268829345703\n",
      "Epoch: 51, step: 650/781, loss: 3.482264757156372\n",
      "Epoch: 51, step: 700/781, loss: 3.392031192779541\n",
      "Epoch: 51, step: 750/781, loss: 3.5606822967529297\n",
      "Epoch: 51 completed, average loss: 3.492777894614753, time taken: 1.5598772803942362 mins\n",
      "Epoch: 52, step: 50/781, loss: 3.4961047172546387\n",
      "Epoch: 52, step: 100/781, loss: 3.3658370971679688\n",
      "Epoch: 52, step: 150/781, loss: 3.5512611865997314\n",
      "Epoch: 52, step: 200/781, loss: 3.3875021934509277\n",
      "Epoch: 52, step: 250/781, loss: 3.4956655502319336\n",
      "Epoch: 52, step: 300/781, loss: 3.5727477073669434\n",
      "Epoch: 52, step: 350/781, loss: 3.4523143768310547\n",
      "Epoch: 52, step: 400/781, loss: 3.4739511013031006\n",
      "Epoch: 52, step: 450/781, loss: 3.5901641845703125\n",
      "Epoch: 52, step: 500/781, loss: 3.5449790954589844\n",
      "Epoch: 52, step: 550/781, loss: 3.446242094039917\n",
      "Epoch: 52, step: 600/781, loss: 3.610785961151123\n",
      "Epoch: 52, step: 650/781, loss: 3.4807162284851074\n",
      "Epoch: 52, step: 700/781, loss: 3.4823083877563477\n",
      "Epoch: 52, step: 750/781, loss: 3.416191339492798\n",
      "Epoch: 52 completed, average loss: 3.4879739302831787, time taken: 1.5581732670466104 mins\n",
      "Epoch: 53, step: 50/781, loss: 3.5106217861175537\n",
      "Epoch: 53, step: 100/781, loss: 3.455021858215332\n",
      "Epoch: 53, step: 150/781, loss: 3.4778318405151367\n",
      "Epoch: 53, step: 200/781, loss: 3.4852490425109863\n",
      "Epoch: 53, step: 250/781, loss: 3.5186939239501953\n",
      "Epoch: 53, step: 300/781, loss: 3.5827345848083496\n",
      "Epoch: 53, step: 350/781, loss: 3.491652488708496\n",
      "Epoch: 53, step: 400/781, loss: 3.475494623184204\n",
      "Epoch: 53, step: 450/781, loss: 3.5578365325927734\n",
      "Epoch: 53, step: 500/781, loss: 3.4411935806274414\n",
      "Epoch: 53, step: 550/781, loss: 3.5390024185180664\n",
      "Epoch: 53, step: 600/781, loss: 3.55043888092041\n",
      "Epoch: 53, step: 650/781, loss: 3.4159576892852783\n",
      "Epoch: 53, step: 700/781, loss: 3.402377128601074\n",
      "Epoch: 53, step: 750/781, loss: 3.4843175411224365\n",
      "Epoch: 53 completed, average loss: 3.486496995261628, time taken: 1.554076107343038 mins\n",
      "Epoch: 54, step: 50/781, loss: 3.5118536949157715\n",
      "Epoch: 54, step: 100/781, loss: 3.546117067337036\n",
      "Epoch: 54, step: 150/781, loss: 3.5559749603271484\n",
      "Epoch: 54, step: 200/781, loss: 3.373739242553711\n",
      "Epoch: 54, step: 250/781, loss: 3.4370627403259277\n",
      "Epoch: 54, step: 300/781, loss: 3.4169745445251465\n",
      "Epoch: 54, step: 350/781, loss: 3.4864156246185303\n",
      "Epoch: 54, step: 400/781, loss: 3.5282082557678223\n",
      "Epoch: 54, step: 450/781, loss: 3.562666416168213\n",
      "Epoch: 54, step: 500/781, loss: 3.4589669704437256\n",
      "Epoch: 54, step: 550/781, loss: 3.6106252670288086\n",
      "Epoch: 54, step: 600/781, loss: 3.4858806133270264\n",
      "Epoch: 54, step: 650/781, loss: 3.528947591781616\n",
      "Epoch: 54, step: 700/781, loss: 3.4871859550476074\n",
      "Epoch: 54, step: 750/781, loss: 3.3858695030212402\n",
      "Epoch: 54 completed, average loss: 3.4832148973218304, time taken: 1.5592328111330669 mins\n",
      "Epoch: 55, step: 50/781, loss: 3.489365577697754\n",
      "Epoch: 55, step: 100/781, loss: 3.4684906005859375\n",
      "Epoch: 55, step: 150/781, loss: 3.514465093612671\n",
      "Epoch: 55, step: 200/781, loss: 3.502161741256714\n",
      "Epoch: 55, step: 250/781, loss: 3.4004690647125244\n",
      "Epoch: 55, step: 300/781, loss: 3.59480881690979\n",
      "Epoch: 55, step: 350/781, loss: 3.546217679977417\n",
      "Epoch: 55, step: 400/781, loss: 3.491943120956421\n",
      "Epoch: 55, step: 450/781, loss: 3.548020839691162\n",
      "Epoch: 55, step: 500/781, loss: 3.51827073097229\n",
      "Epoch: 55, step: 550/781, loss: 3.4392683506011963\n",
      "Epoch: 55, step: 600/781, loss: 3.4311254024505615\n",
      "Epoch: 55, step: 650/781, loss: 3.470052480697632\n",
      "Epoch: 55, step: 700/781, loss: 3.4512500762939453\n",
      "Epoch: 55, step: 750/781, loss: 3.5434093475341797\n",
      "Epoch: 55 completed, average loss: 3.4850001356513185, time taken: 1.5528911391894022 mins\n",
      "Epoch: 56, step: 50/781, loss: 3.5123069286346436\n",
      "Epoch: 56, step: 100/781, loss: 3.4834017753601074\n",
      "Epoch: 56, step: 150/781, loss: 3.490178346633911\n",
      "Epoch: 56, step: 200/781, loss: 3.469482421875\n",
      "Epoch: 56, step: 250/781, loss: 3.4495909214019775\n",
      "Epoch: 56, step: 300/781, loss: 3.447692632675171\n",
      "Epoch: 56, step: 350/781, loss: 3.428515911102295\n",
      "Epoch: 56, step: 400/781, loss: 3.522496461868286\n",
      "Epoch: 56, step: 450/781, loss: 3.385971784591675\n",
      "Epoch: 56, step: 500/781, loss: 3.5272369384765625\n",
      "Epoch: 56, step: 550/781, loss: 3.4634900093078613\n",
      "Epoch: 56, step: 600/781, loss: 3.480803966522217\n",
      "Epoch: 56, step: 650/781, loss: 3.4411025047302246\n",
      "Epoch: 56, step: 700/781, loss: 3.4996988773345947\n",
      "Epoch: 56, step: 750/781, loss: 3.481504201889038\n",
      "Epoch: 56 completed, average loss: 3.4786196496819413, time taken: 1.557530661424001 mins\n",
      "Epoch: 57, step: 50/781, loss: 3.455470085144043\n",
      "Epoch: 57, step: 100/781, loss: 3.605937957763672\n",
      "Epoch: 57, step: 150/781, loss: 3.5064876079559326\n",
      "Epoch: 57, step: 200/781, loss: 3.4227724075317383\n",
      "Epoch: 57, step: 250/781, loss: 3.4468958377838135\n",
      "Epoch: 57, step: 300/781, loss: 3.443265438079834\n",
      "Epoch: 57, step: 350/781, loss: 3.4947450160980225\n",
      "Epoch: 57, step: 400/781, loss: 3.4229893684387207\n",
      "Epoch: 57, step: 450/781, loss: 3.4360764026641846\n",
      "Epoch: 57, step: 500/781, loss: 3.5527286529541016\n",
      "Epoch: 57, step: 550/781, loss: 3.5072550773620605\n",
      "Epoch: 57, step: 600/781, loss: 3.576936721801758\n",
      "Epoch: 57, step: 650/781, loss: 3.464906692504883\n",
      "Epoch: 57, step: 700/781, loss: 3.519401788711548\n",
      "Epoch: 57, step: 750/781, loss: 3.462134838104248\n",
      "Epoch: 57 completed, average loss: 3.475766146839352, time taken: 1.5559645771980286 mins\n",
      "Epoch: 58, step: 50/781, loss: 3.5335052013397217\n",
      "Epoch: 58, step: 100/781, loss: 3.421356439590454\n",
      "Epoch: 58, step: 150/781, loss: 3.4190332889556885\n",
      "Epoch: 58, step: 200/781, loss: 3.473613739013672\n",
      "Epoch: 58, step: 250/781, loss: 3.4351043701171875\n",
      "Epoch: 58, step: 300/781, loss: 3.5418243408203125\n",
      "Epoch: 58, step: 350/781, loss: 3.444887638092041\n",
      "Epoch: 58, step: 400/781, loss: 3.4554786682128906\n",
      "Epoch: 58, step: 450/781, loss: 3.57161283493042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58, step: 500/781, loss: 3.4447662830352783\n",
      "Epoch: 58, step: 550/781, loss: 3.5475246906280518\n",
      "Epoch: 58, step: 600/781, loss: 3.4404308795928955\n",
      "Epoch: 58, step: 650/781, loss: 3.4672024250030518\n",
      "Epoch: 58, step: 700/781, loss: 3.5236480236053467\n",
      "Epoch: 58, step: 750/781, loss: 3.5083093643188477\n",
      "Epoch: 58 completed, average loss: 3.473382928154685, time taken: 1.5505253156026204 mins\n",
      "Epoch: 59, step: 50/781, loss: 3.5024518966674805\n",
      "Epoch: 59, step: 100/781, loss: 3.4250905513763428\n",
      "Epoch: 59, step: 150/781, loss: 3.4156978130340576\n",
      "Epoch: 59, step: 200/781, loss: 3.6557555198669434\n",
      "Epoch: 59, step: 250/781, loss: 3.599533796310425\n",
      "Epoch: 59, step: 300/781, loss: 3.5016534328460693\n",
      "Epoch: 59, step: 350/781, loss: 3.4603493213653564\n",
      "Epoch: 59, step: 400/781, loss: 3.38916277885437\n",
      "Epoch: 59, step: 450/781, loss: 3.5371005535125732\n",
      "Epoch: 59, step: 500/781, loss: 3.4693992137908936\n",
      "Epoch: 59, step: 550/781, loss: 3.546224594116211\n",
      "Epoch: 59, step: 600/781, loss: 3.473160743713379\n",
      "Epoch: 59, step: 650/781, loss: 3.4388091564178467\n",
      "Epoch: 59, step: 700/781, loss: 3.5195374488830566\n",
      "Epoch: 59, step: 750/781, loss: 3.6069254875183105\n",
      "Epoch: 59 completed, average loss: 3.473351490787599, time taken: 1.551365570227305 mins\n",
      "Epoch: 60, step: 50/781, loss: 3.553323745727539\n",
      "Epoch: 60, step: 100/781, loss: 3.4710960388183594\n",
      "Epoch: 60, step: 150/781, loss: 3.4253036975860596\n",
      "Epoch: 60, step: 200/781, loss: 3.4613382816314697\n",
      "Epoch: 60, step: 250/781, loss: 3.4358019828796387\n",
      "Epoch: 60, step: 300/781, loss: 3.364457845687866\n",
      "Epoch: 60, step: 350/781, loss: 3.4736461639404297\n",
      "Epoch: 60, step: 400/781, loss: 3.435835123062134\n",
      "Epoch: 60, step: 450/781, loss: 3.5173003673553467\n",
      "Epoch: 60, step: 500/781, loss: 3.480327606201172\n",
      "Epoch: 60, step: 550/781, loss: 3.5357182025909424\n",
      "Epoch: 60, step: 600/781, loss: 3.4661970138549805\n",
      "Epoch: 60, step: 650/781, loss: 3.591963529586792\n",
      "Epoch: 60, step: 700/781, loss: 3.4917585849761963\n",
      "Epoch: 60, step: 750/781, loss: 3.4886841773986816\n",
      "Epoch: 60 completed, average loss: 3.4734430477958025, time taken: 1.553086769580841 mins\n",
      "Epoch: 61, step: 50/781, loss: 3.4184730052948\n",
      "Epoch: 61, step: 100/781, loss: 3.4967894554138184\n",
      "Epoch: 61, step: 150/781, loss: 3.509229898452759\n",
      "Epoch: 61, step: 200/781, loss: 3.3634328842163086\n",
      "Epoch: 61, step: 250/781, loss: 3.580496072769165\n",
      "Epoch: 61, step: 300/781, loss: 3.493999481201172\n",
      "Epoch: 61, step: 350/781, loss: 3.5103588104248047\n",
      "Epoch: 61, step: 400/781, loss: 3.443011522293091\n",
      "Epoch: 61, step: 450/781, loss: 3.581611394882202\n",
      "Epoch: 61, step: 500/781, loss: 3.399238348007202\n",
      "Epoch: 61, step: 550/781, loss: 3.516423463821411\n",
      "Epoch: 61, step: 600/781, loss: 3.571218967437744\n",
      "Epoch: 61, step: 650/781, loss: 3.443925142288208\n",
      "Epoch: 61, step: 700/781, loss: 3.5107498168945312\n",
      "Epoch: 61, step: 750/781, loss: 3.4620859622955322\n",
      "Epoch: 61 completed, average loss: 3.4708838343772936, time taken: 1.5522635618845622 mins\n",
      "Epoch: 62, step: 50/781, loss: 3.3264336585998535\n",
      "Epoch: 62, step: 100/781, loss: 3.4317634105682373\n",
      "Epoch: 62, step: 150/781, loss: 3.5197267532348633\n",
      "Epoch: 62, step: 200/781, loss: 3.4229531288146973\n",
      "Epoch: 62, step: 250/781, loss: 3.434694528579712\n",
      "Epoch: 62, step: 300/781, loss: 3.5173656940460205\n",
      "Epoch: 62, step: 350/781, loss: 3.4991579055786133\n",
      "Epoch: 62, step: 400/781, loss: 3.5209646224975586\n",
      "Epoch: 62, step: 450/781, loss: 3.548588275909424\n",
      "Epoch: 62, step: 500/781, loss: 3.602790355682373\n",
      "Epoch: 62, step: 550/781, loss: 3.460573673248291\n",
      "Epoch: 62, step: 600/781, loss: 3.541461944580078\n",
      "Epoch: 62, step: 650/781, loss: 3.398024082183838\n",
      "Epoch: 62, step: 700/781, loss: 3.538290500640869\n",
      "Epoch: 62, step: 750/781, loss: 3.4161009788513184\n",
      "Epoch: 62 completed, average loss: 3.4693298675644564, time taken: 1.550442361831665 mins\n",
      "Epoch: 63, step: 50/781, loss: 3.537841796875\n",
      "Epoch: 63, step: 100/781, loss: 3.5894370079040527\n",
      "Epoch: 63, step: 150/781, loss: 3.5673935413360596\n",
      "Epoch: 63, step: 200/781, loss: 3.517575263977051\n",
      "Epoch: 63, step: 250/781, loss: 3.4768612384796143\n",
      "Epoch: 63, step: 300/781, loss: 3.462102174758911\n",
      "Epoch: 63, step: 350/781, loss: 3.5630345344543457\n",
      "Epoch: 63, step: 400/781, loss: 3.478630781173706\n",
      "Epoch: 63, step: 450/781, loss: 3.5199673175811768\n",
      "Epoch: 63, step: 500/781, loss: 3.5518181324005127\n",
      "Epoch: 63, step: 550/781, loss: 3.379603385925293\n",
      "Epoch: 63, step: 600/781, loss: 3.4339141845703125\n",
      "Epoch: 63, step: 650/781, loss: 3.423285961151123\n",
      "Epoch: 63, step: 700/781, loss: 3.436713218688965\n",
      "Epoch: 63, step: 750/781, loss: 3.4413998126983643\n",
      "Epoch: 63 completed, average loss: 3.4681126689788777, time taken: 1.5499475598335266 mins\n",
      "Epoch: 64, step: 50/781, loss: 3.5607471466064453\n",
      "Epoch: 64, step: 100/781, loss: 3.4074547290802\n",
      "Epoch: 64, step: 150/781, loss: 3.398655652999878\n",
      "Epoch: 64, step: 200/781, loss: 3.396484136581421\n",
      "Epoch: 64, step: 250/781, loss: 3.510638952255249\n",
      "Epoch: 64, step: 300/781, loss: 3.400367259979248\n",
      "Epoch: 64, step: 350/781, loss: 3.524703025817871\n",
      "Epoch: 64, step: 400/781, loss: 3.4363245964050293\n",
      "Epoch: 64, step: 450/781, loss: 3.486509084701538\n",
      "Epoch: 64, step: 500/781, loss: 3.507650136947632\n",
      "Epoch: 64, step: 550/781, loss: 3.4630346298217773\n",
      "Epoch: 64, step: 600/781, loss: 3.46372652053833\n",
      "Epoch: 64, step: 650/781, loss: 3.432615280151367\n",
      "Epoch: 64, step: 700/781, loss: 3.484114408493042\n",
      "Epoch: 64, step: 750/781, loss: 3.443132162094116\n",
      "Epoch: 64 completed, average loss: 3.4633281646098433, time taken: 1.550485861301422 mins\n",
      "Epoch: 65, step: 50/781, loss: 3.434354305267334\n",
      "Epoch: 65, step: 100/781, loss: 3.4400322437286377\n",
      "Epoch: 65, step: 150/781, loss: 3.406376600265503\n",
      "Epoch: 65, step: 200/781, loss: 3.5541164875030518\n",
      "Epoch: 65, step: 250/781, loss: 3.5052871704101562\n",
      "Epoch: 65, step: 300/781, loss: 3.3744735717773438\n",
      "Epoch: 65, step: 350/781, loss: 3.3631176948547363\n",
      "Epoch: 65, step: 400/781, loss: 3.469203472137451\n",
      "Epoch: 65, step: 450/781, loss: 3.534864902496338\n",
      "Epoch: 65, step: 500/781, loss: 3.3698437213897705\n",
      "Epoch: 65, step: 550/781, loss: 3.3549768924713135\n",
      "Epoch: 65, step: 600/781, loss: 3.508707046508789\n",
      "Epoch: 65, step: 650/781, loss: 3.4074811935424805\n",
      "Epoch: 65, step: 700/781, loss: 3.5311310291290283\n",
      "Epoch: 65, step: 750/781, loss: 3.4606192111968994\n",
      "Epoch: 65 completed, average loss: 3.4613606532923544, time taken: 1.5502407670021057 mins\n",
      "Epoch: 66, step: 50/781, loss: 3.521620035171509\n",
      "Epoch: 66, step: 100/781, loss: 3.3959920406341553\n",
      "Epoch: 66, step: 150/781, loss: 3.4354701042175293\n",
      "Epoch: 66, step: 200/781, loss: 3.4226768016815186\n",
      "Epoch: 66, step: 250/781, loss: 3.530531167984009\n",
      "Epoch: 66, step: 300/781, loss: 3.473001480102539\n",
      "Epoch: 66, step: 350/781, loss: 3.4577829837799072\n",
      "Epoch: 66, step: 400/781, loss: 3.433647871017456\n",
      "Epoch: 66, step: 450/781, loss: 3.415877103805542\n",
      "Epoch: 66, step: 500/781, loss: 3.497249126434326\n",
      "Epoch: 66, step: 550/781, loss: 3.4916608333587646\n",
      "Epoch: 66, step: 600/781, loss: 3.518720865249634\n",
      "Epoch: 66, step: 650/781, loss: 3.4822468757629395\n",
      "Epoch: 66, step: 700/781, loss: 3.558940887451172\n",
      "Epoch: 66, step: 750/781, loss: 3.441650867462158\n",
      "Epoch: 66 completed, average loss: 3.4612856356954147, time taken: 1.5502923091252645 mins\n",
      "Epoch: 67, step: 50/781, loss: 3.3897502422332764\n",
      "Epoch: 67, step: 100/781, loss: 3.6460235118865967\n",
      "Epoch: 67, step: 150/781, loss: 3.4826574325561523\n",
      "Epoch: 67, step: 200/781, loss: 3.514378070831299\n",
      "Epoch: 67, step: 250/781, loss: 3.4356398582458496\n",
      "Epoch: 67, step: 300/781, loss: 3.4030144214630127\n",
      "Epoch: 67, step: 350/781, loss: 3.47951340675354\n",
      "Epoch: 67, step: 400/781, loss: 3.428635835647583\n",
      "Epoch: 67, step: 450/781, loss: 3.55210542678833\n",
      "Epoch: 67, step: 500/781, loss: 3.349889039993286\n",
      "Epoch: 67, step: 550/781, loss: 3.377089023590088\n",
      "Epoch: 67, step: 600/781, loss: 3.545060396194458\n",
      "Epoch: 67, step: 650/781, loss: 3.423539400100708\n",
      "Epoch: 67, step: 700/781, loss: 3.610280990600586\n",
      "Epoch: 67, step: 750/781, loss: 3.4462900161743164\n",
      "Epoch: 67 completed, average loss: 3.45886432529259, time taken: 1.5533082087834675 mins\n",
      "Epoch: 68, step: 50/781, loss: 3.4923956394195557\n",
      "Epoch: 68, step: 100/781, loss: 3.4000091552734375\n",
      "Epoch: 68, step: 150/781, loss: 3.4991097450256348\n",
      "Epoch: 68, step: 200/781, loss: 3.5330517292022705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68, step: 250/781, loss: 3.4928762912750244\n",
      "Epoch: 68, step: 300/781, loss: 3.5955862998962402\n",
      "Epoch: 68, step: 350/781, loss: 3.3766300678253174\n",
      "Epoch: 68, step: 400/781, loss: 3.4809844493865967\n",
      "Epoch: 68, step: 450/781, loss: 3.441685676574707\n",
      "Epoch: 68, step: 500/781, loss: 3.521982192993164\n",
      "Epoch: 68, step: 550/781, loss: 3.444291353225708\n",
      "Epoch: 68, step: 600/781, loss: 3.3969273567199707\n",
      "Epoch: 68, step: 650/781, loss: 3.519340991973877\n",
      "Epoch: 68, step: 700/781, loss: 3.4910120964050293\n",
      "Epoch: 68, step: 750/781, loss: 3.4246370792388916\n",
      "Epoch: 68 completed, average loss: 3.459767532714961, time taken: 1.5516724387804668 mins\n",
      "Epoch: 69, step: 50/781, loss: 3.4351398944854736\n",
      "Epoch: 69, step: 100/781, loss: 3.3615095615386963\n",
      "Epoch: 69, step: 150/781, loss: 3.3910391330718994\n",
      "Epoch: 69, step: 200/781, loss: 3.569730758666992\n",
      "Epoch: 69, step: 250/781, loss: 3.4223175048828125\n",
      "Epoch: 69, step: 300/781, loss: 3.453651189804077\n",
      "Epoch: 69, step: 350/781, loss: 3.459731101989746\n",
      "Epoch: 69, step: 400/781, loss: 3.518903970718384\n",
      "Epoch: 69, step: 450/781, loss: 3.461622476577759\n",
      "Epoch: 69, step: 500/781, loss: 3.5091347694396973\n",
      "Epoch: 69, step: 550/781, loss: 3.406982898712158\n",
      "Epoch: 69, step: 600/781, loss: 3.465005874633789\n",
      "Epoch: 69, step: 650/781, loss: 3.4227113723754883\n",
      "Epoch: 69, step: 700/781, loss: 3.4387142658233643\n",
      "Epoch: 69, step: 750/781, loss: 3.368645429611206\n",
      "Epoch: 69 completed, average loss: 3.458277816198547, time taken: 1.5489088336626688 mins\n",
      "Epoch: 70, step: 50/781, loss: 3.4139857292175293\n",
      "Epoch: 70, step: 100/781, loss: 3.3696653842926025\n",
      "Epoch: 70, step: 150/781, loss: 3.475450277328491\n",
      "Epoch: 70, step: 200/781, loss: 3.4378833770751953\n",
      "Epoch: 70, step: 250/781, loss: 3.3310320377349854\n",
      "Epoch: 70, step: 300/781, loss: 3.449608087539673\n",
      "Epoch: 70, step: 350/781, loss: 3.4661753177642822\n",
      "Epoch: 70, step: 400/781, loss: 3.458155632019043\n",
      "Epoch: 70, step: 450/781, loss: 3.50685977935791\n",
      "Epoch: 70, step: 500/781, loss: 3.4886553287506104\n",
      "Epoch: 70, step: 550/781, loss: 3.5165631771087646\n",
      "Epoch: 70, step: 600/781, loss: 3.4008188247680664\n",
      "Epoch: 70, step: 650/781, loss: 3.4943795204162598\n",
      "Epoch: 70, step: 700/781, loss: 3.567434072494507\n",
      "Epoch: 70, step: 750/781, loss: 3.4063923358917236\n",
      "Epoch: 70 completed, average loss: 3.4579722444776078, time taken: 1.5496586879094443 mins\n",
      "Epoch: 71, step: 50/781, loss: 3.4639101028442383\n",
      "Epoch: 71, step: 100/781, loss: 3.5329017639160156\n",
      "Epoch: 71, step: 150/781, loss: 3.47143292427063\n",
      "Epoch: 71, step: 200/781, loss: 3.4867360591888428\n",
      "Epoch: 71, step: 250/781, loss: 3.4318761825561523\n",
      "Epoch: 71, step: 300/781, loss: 3.4891722202301025\n",
      "Epoch: 71, step: 350/781, loss: 3.3568670749664307\n",
      "Epoch: 71, step: 400/781, loss: 3.502800941467285\n",
      "Epoch: 71, step: 450/781, loss: 3.5178260803222656\n",
      "Epoch: 71, step: 500/781, loss: 3.3553361892700195\n",
      "Epoch: 71, step: 550/781, loss: 3.3858978748321533\n",
      "Epoch: 71, step: 600/781, loss: 3.4970359802246094\n",
      "Epoch: 71, step: 650/781, loss: 3.4119138717651367\n",
      "Epoch: 71, step: 700/781, loss: 3.4429004192352295\n",
      "Epoch: 71, step: 750/781, loss: 3.480132579803467\n",
      "Epoch: 71 completed, average loss: 3.4550166942093345, time taken: 1.551169757048289 mins\n",
      "Epoch: 72, step: 50/781, loss: 3.5459372997283936\n",
      "Epoch: 72, step: 100/781, loss: 3.4950342178344727\n",
      "Epoch: 72, step: 150/781, loss: 3.4687142372131348\n",
      "Epoch: 72, step: 200/781, loss: 3.4228451251983643\n",
      "Epoch: 72, step: 250/781, loss: 3.5004982948303223\n",
      "Epoch: 72, step: 300/781, loss: 3.5328381061553955\n",
      "Epoch: 72, step: 350/781, loss: 3.4686596393585205\n",
      "Epoch: 72, step: 400/781, loss: 3.4147796630859375\n",
      "Epoch: 72, step: 450/781, loss: 3.5037271976470947\n",
      "Epoch: 72, step: 500/781, loss: 3.574749708175659\n",
      "Epoch: 72, step: 550/781, loss: 3.491934299468994\n",
      "Epoch: 72, step: 600/781, loss: 3.4967520236968994\n",
      "Epoch: 72, step: 650/781, loss: 3.5343921184539795\n",
      "Epoch: 72, step: 700/781, loss: 3.410465955734253\n",
      "Epoch: 72, step: 750/781, loss: 3.4479658603668213\n",
      "Epoch: 72 completed, average loss: 3.454423976463484, time taken: 1.5485136310259502 mins\n",
      "Epoch: 73, step: 50/781, loss: 3.4937803745269775\n",
      "Epoch: 73, step: 100/781, loss: 3.551238536834717\n",
      "Epoch: 73, step: 150/781, loss: 3.4578545093536377\n",
      "Epoch: 73, step: 200/781, loss: 3.495187520980835\n",
      "Epoch: 73, step: 250/781, loss: 3.3851866722106934\n",
      "Epoch: 73, step: 300/781, loss: 3.4426209926605225\n",
      "Epoch: 73, step: 350/781, loss: 3.4908838272094727\n",
      "Epoch: 73, step: 400/781, loss: 3.519150495529175\n",
      "Epoch: 73, step: 450/781, loss: 3.4591617584228516\n",
      "Epoch: 73, step: 500/781, loss: 3.58184552192688\n",
      "Epoch: 73, step: 550/781, loss: 3.497748374938965\n",
      "Epoch: 73, step: 600/781, loss: 3.48087477684021\n",
      "Epoch: 73, step: 650/781, loss: 3.3730130195617676\n",
      "Epoch: 73, step: 700/781, loss: 3.4863083362579346\n",
      "Epoch: 73, step: 750/781, loss: 3.46177339553833\n",
      "Epoch: 73 completed, average loss: 3.4511468892824024, time taken: 1.5518773595492046 mins\n",
      "Epoch: 74, step: 50/781, loss: 3.4023349285125732\n",
      "Epoch: 74, step: 100/781, loss: 3.395953893661499\n",
      "Epoch: 74, step: 150/781, loss: 3.374248743057251\n",
      "Epoch: 74, step: 200/781, loss: 3.51810622215271\n",
      "Epoch: 74, step: 250/781, loss: 3.4978768825531006\n",
      "Epoch: 74, step: 300/781, loss: 3.4780941009521484\n",
      "Epoch: 74, step: 350/781, loss: 3.3769309520721436\n",
      "Epoch: 74, step: 400/781, loss: 3.4759151935577393\n",
      "Epoch: 74, step: 450/781, loss: 3.425213575363159\n",
      "Epoch: 74, step: 500/781, loss: 3.3637771606445312\n",
      "Epoch: 74, step: 550/781, loss: 3.473644971847534\n",
      "Epoch: 74, step: 600/781, loss: 3.443310499191284\n",
      "Epoch: 74, step: 650/781, loss: 3.435783863067627\n",
      "Epoch: 74, step: 700/781, loss: 3.4117653369903564\n",
      "Epoch: 74, step: 750/781, loss: 3.4388933181762695\n",
      "Epoch: 74 completed, average loss: 3.4485956676180325, time taken: 1.5498228351275125 mins\n",
      "Epoch: 75, step: 50/781, loss: 3.4720523357391357\n",
      "Epoch: 75, step: 100/781, loss: 3.5009524822235107\n",
      "Epoch: 75, step: 150/781, loss: 3.400914192199707\n",
      "Epoch: 75, step: 200/781, loss: 3.398712635040283\n",
      "Epoch: 75, step: 250/781, loss: 3.504120111465454\n",
      "Epoch: 75, step: 300/781, loss: 3.514763355255127\n",
      "Epoch: 75, step: 350/781, loss: 3.4314537048339844\n",
      "Epoch: 75, step: 400/781, loss: 3.4929542541503906\n",
      "Epoch: 75, step: 450/781, loss: 3.406350612640381\n",
      "Epoch: 75, step: 500/781, loss: 3.468731641769409\n",
      "Epoch: 75, step: 550/781, loss: 3.4562668800354004\n",
      "Epoch: 75, step: 600/781, loss: 3.4164528846740723\n",
      "Epoch: 75, step: 650/781, loss: 3.4997639656066895\n",
      "Epoch: 75, step: 700/781, loss: 3.4623773097991943\n",
      "Epoch: 75, step: 750/781, loss: 3.479478120803833\n",
      "Epoch: 75 completed, average loss: 3.4452323974628913, time taken: 1.5598401387532552 mins\n",
      "Epoch: 76, step: 50/781, loss: 3.4483914375305176\n",
      "Epoch: 76, step: 100/781, loss: 3.415191411972046\n",
      "Epoch: 76, step: 150/781, loss: 3.5264601707458496\n",
      "Epoch: 76, step: 200/781, loss: 3.443392276763916\n",
      "Epoch: 76, step: 250/781, loss: 3.503934621810913\n",
      "Epoch: 76, step: 300/781, loss: 3.433417558670044\n",
      "Epoch: 76, step: 350/781, loss: 3.424914836883545\n",
      "Epoch: 76, step: 400/781, loss: 3.4268088340759277\n",
      "Epoch: 76, step: 450/781, loss: 3.4128546714782715\n",
      "Epoch: 76, step: 500/781, loss: 3.4918739795684814\n",
      "Epoch: 76, step: 550/781, loss: 3.428138256072998\n",
      "Epoch: 76, step: 600/781, loss: 3.5854721069335938\n",
      "Epoch: 76, step: 650/781, loss: 3.491760492324829\n",
      "Epoch: 76, step: 700/781, loss: 3.4293081760406494\n",
      "Epoch: 76, step: 750/781, loss: 3.40521240234375\n",
      "Epoch: 76 completed, average loss: 3.447675475085133, time taken: 1.5588012297948202 mins\n",
      "Epoch: 77, step: 50/781, loss: 3.45527720451355\n",
      "Epoch: 77, step: 100/781, loss: 3.462960720062256\n",
      "Epoch: 77, step: 150/781, loss: 3.4239933490753174\n",
      "Epoch: 77, step: 200/781, loss: 3.4195427894592285\n",
      "Epoch: 77, step: 250/781, loss: 3.445953607559204\n",
      "Epoch: 77, step: 300/781, loss: 3.3911685943603516\n",
      "Epoch: 77, step: 350/781, loss: 3.47359037399292\n",
      "Epoch: 77, step: 400/781, loss: 3.3619627952575684\n",
      "Epoch: 77, step: 450/781, loss: 3.5074992179870605\n",
      "Epoch: 77, step: 500/781, loss: 3.413872003555298\n",
      "Epoch: 77, step: 550/781, loss: 3.4510393142700195\n",
      "Epoch: 77, step: 600/781, loss: 3.3867156505584717\n",
      "Epoch: 77, step: 650/781, loss: 3.413886308670044\n",
      "Epoch: 77, step: 700/781, loss: 3.5100953578948975\n",
      "Epoch: 77, step: 750/781, loss: 3.4348597526550293\n",
      "Epoch: 77 completed, average loss: 3.4395927137357782, time taken: 1.5520156542460124 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78, step: 50/781, loss: 3.386902332305908\n",
      "Epoch: 78, step: 100/781, loss: 3.487103223800659\n",
      "Epoch: 78, step: 150/781, loss: 3.424356698989868\n",
      "Epoch: 78, step: 200/781, loss: 3.4115853309631348\n",
      "Epoch: 78, step: 250/781, loss: 3.395071268081665\n",
      "Epoch: 78, step: 300/781, loss: 3.464151620864868\n",
      "Epoch: 78, step: 350/781, loss: 3.369541645050049\n",
      "Epoch: 78, step: 400/781, loss: 3.428603172302246\n",
      "Epoch: 78, step: 450/781, loss: 3.3787496089935303\n",
      "Epoch: 78, step: 500/781, loss: 3.4797027111053467\n",
      "Epoch: 78, step: 550/781, loss: 3.4408302307128906\n",
      "Epoch: 78, step: 600/781, loss: 3.433391809463501\n",
      "Epoch: 78, step: 650/781, loss: 3.3732962608337402\n",
      "Epoch: 78, step: 700/781, loss: 3.5237677097320557\n",
      "Epoch: 78, step: 750/781, loss: 3.4968817234039307\n",
      "Epoch: 78 completed, average loss: 3.445766394025385, time taken: 1.5555007219314576 mins\n",
      "Epoch: 79, step: 50/781, loss: 3.4674811363220215\n",
      "Epoch: 79, step: 100/781, loss: 3.4688339233398438\n",
      "Epoch: 79, step: 150/781, loss: 3.4134361743927\n",
      "Epoch: 79, step: 200/781, loss: 3.382429599761963\n",
      "Epoch: 79, step: 250/781, loss: 3.400700092315674\n",
      "Epoch: 79, step: 300/781, loss: 3.468097448348999\n",
      "Epoch: 79, step: 350/781, loss: 3.3373780250549316\n",
      "Epoch: 79, step: 400/781, loss: 3.5017292499542236\n",
      "Epoch: 79, step: 450/781, loss: 3.479318857192993\n",
      "Epoch: 79, step: 500/781, loss: 3.472896099090576\n",
      "Epoch: 79, step: 550/781, loss: 3.4496684074401855\n",
      "Epoch: 79, step: 600/781, loss: 3.4068899154663086\n",
      "Epoch: 79, step: 650/781, loss: 3.4232077598571777\n",
      "Epoch: 79, step: 700/781, loss: 3.4215683937072754\n",
      "Epoch: 79, step: 750/781, loss: 3.441957950592041\n",
      "Epoch: 79 completed, average loss: 3.443334611826761, time taken: 1.5501785715421041 mins\n",
      "Epoch: 80, step: 50/781, loss: 3.3877930641174316\n",
      "Epoch: 80, step: 100/781, loss: 3.497828722000122\n",
      "Epoch: 80, step: 150/781, loss: 3.402683973312378\n",
      "Epoch: 80, step: 200/781, loss: 3.456399440765381\n",
      "Epoch: 80, step: 250/781, loss: 3.4205586910247803\n",
      "Epoch: 80, step: 300/781, loss: 3.507958173751831\n",
      "Epoch: 80, step: 350/781, loss: 3.3731698989868164\n",
      "Epoch: 80, step: 400/781, loss: 3.431762218475342\n",
      "Epoch: 80, step: 450/781, loss: 3.350738525390625\n",
      "Epoch: 80, step: 500/781, loss: 3.4429941177368164\n",
      "Epoch: 80, step: 550/781, loss: 3.503420352935791\n",
      "Epoch: 80, step: 600/781, loss: 3.471079111099243\n",
      "Epoch: 80, step: 650/781, loss: 3.4426796436309814\n",
      "Epoch: 80, step: 700/781, loss: 3.458061933517456\n",
      "Epoch: 80, step: 750/781, loss: 3.399614095687866\n",
      "Epoch: 80 completed, average loss: 3.4384352809793666, time taken: 1.5478443384170533 mins\n",
      "Epoch: 81, step: 50/781, loss: 3.4372658729553223\n",
      "Epoch: 81, step: 100/781, loss: 3.359501600265503\n",
      "Epoch: 81, step: 150/781, loss: 3.4227383136749268\n",
      "Epoch: 81, step: 200/781, loss: 3.4050683975219727\n",
      "Epoch: 81, step: 250/781, loss: 3.4719512462615967\n",
      "Epoch: 81, step: 300/781, loss: 3.467097043991089\n",
      "Epoch: 81, step: 350/781, loss: 3.3688766956329346\n",
      "Epoch: 81, step: 400/781, loss: 3.382714033126831\n",
      "Epoch: 81, step: 450/781, loss: 3.4039058685302734\n",
      "Epoch: 81, step: 500/781, loss: 3.38859486579895\n",
      "Epoch: 81, step: 550/781, loss: 3.461111545562744\n",
      "Epoch: 81, step: 600/781, loss: 3.4886250495910645\n",
      "Epoch: 81, step: 650/781, loss: 3.396498680114746\n",
      "Epoch: 81, step: 700/781, loss: 3.4860427379608154\n",
      "Epoch: 81, step: 750/781, loss: 3.4097139835357666\n",
      "Epoch: 81 completed, average loss: 3.441829598667374, time taken: 1.5557833234469096 mins\n",
      "Epoch: 82, step: 50/781, loss: 3.521986722946167\n",
      "Epoch: 82, step: 100/781, loss: 3.4493370056152344\n",
      "Epoch: 82, step: 150/781, loss: 3.510106325149536\n",
      "Epoch: 82, step: 200/781, loss: 3.4126176834106445\n",
      "Epoch: 82, step: 250/781, loss: 3.3927507400512695\n",
      "Epoch: 82, step: 300/781, loss: 3.441514015197754\n",
      "Epoch: 82, step: 350/781, loss: 3.5204083919525146\n",
      "Epoch: 82, step: 400/781, loss: 3.4327311515808105\n",
      "Epoch: 82, step: 450/781, loss: 3.444396495819092\n",
      "Epoch: 82, step: 500/781, loss: 3.410297393798828\n",
      "Epoch: 82, step: 550/781, loss: 3.431652784347534\n",
      "Epoch: 82, step: 600/781, loss: 3.3713181018829346\n",
      "Epoch: 82, step: 650/781, loss: 3.4358770847320557\n",
      "Epoch: 82, step: 700/781, loss: 3.4248907566070557\n",
      "Epoch: 82, step: 750/781, loss: 3.3967926502227783\n",
      "Epoch: 82 completed, average loss: 3.4375297553102735, time taken: 1.5526175379753113 mins\n",
      "Epoch: 83, step: 50/781, loss: 3.476452112197876\n",
      "Epoch: 83, step: 100/781, loss: 3.385066270828247\n",
      "Epoch: 83, step: 150/781, loss: 3.463088274002075\n",
      "Epoch: 83, step: 200/781, loss: 3.4621012210845947\n",
      "Epoch: 83, step: 250/781, loss: 3.487374782562256\n",
      "Epoch: 83, step: 300/781, loss: 3.42189884185791\n",
      "Epoch: 83, step: 350/781, loss: 3.4192638397216797\n",
      "Epoch: 83, step: 400/781, loss: 3.4529809951782227\n",
      "Epoch: 83, step: 450/781, loss: 3.438497304916382\n",
      "Epoch: 83, step: 500/781, loss: 3.332071542739868\n",
      "Epoch: 83, step: 550/781, loss: 3.5034961700439453\n",
      "Epoch: 83, step: 600/781, loss: 3.4989941120147705\n",
      "Epoch: 83, step: 650/781, loss: 3.448089122772217\n",
      "Epoch: 83, step: 700/781, loss: 3.4755122661590576\n",
      "Epoch: 83, step: 750/781, loss: 3.369976758956909\n",
      "Epoch: 83 completed, average loss: 3.4342910959534394, time taken: 1.5484183311462403 mins\n",
      "Epoch: 84, step: 50/781, loss: 3.4871115684509277\n",
      "Epoch: 84, step: 100/781, loss: 3.5152151584625244\n",
      "Epoch: 84, step: 150/781, loss: 3.4516117572784424\n",
      "Epoch: 84, step: 200/781, loss: 3.4951939582824707\n",
      "Epoch: 84, step: 250/781, loss: 3.5116262435913086\n",
      "Epoch: 84, step: 300/781, loss: 3.455029249191284\n",
      "Epoch: 84, step: 350/781, loss: 3.4145424365997314\n",
      "Epoch: 84, step: 400/781, loss: 3.3709826469421387\n",
      "Epoch: 84, step: 450/781, loss: 3.493601083755493\n",
      "Epoch: 84, step: 500/781, loss: 3.434802770614624\n",
      "Epoch: 84, step: 550/781, loss: 3.387385368347168\n",
      "Epoch: 84, step: 600/781, loss: 3.3768937587738037\n",
      "Epoch: 84, step: 650/781, loss: 3.3193728923797607\n",
      "Epoch: 84, step: 700/781, loss: 3.4659059047698975\n",
      "Epoch: 84, step: 750/781, loss: 3.44465708732605\n",
      "Epoch: 84 completed, average loss: 3.4360515182973788, time taken: 1.550249735514323 mins\n",
      "Epoch: 85, step: 50/781, loss: 3.4890198707580566\n",
      "Epoch: 85, step: 100/781, loss: 3.5188231468200684\n",
      "Epoch: 85, step: 150/781, loss: 3.3771374225616455\n",
      "Epoch: 85, step: 200/781, loss: 3.449307918548584\n",
      "Epoch: 85, step: 250/781, loss: 3.454582452774048\n",
      "Epoch: 85, step: 300/781, loss: 3.4946706295013428\n",
      "Epoch: 85, step: 350/781, loss: 3.4245991706848145\n",
      "Epoch: 85, step: 400/781, loss: 3.3759355545043945\n",
      "Epoch: 85, step: 450/781, loss: 3.4738924503326416\n",
      "Epoch: 85, step: 500/781, loss: 3.3810770511627197\n",
      "Epoch: 85, step: 550/781, loss: 3.379962205886841\n",
      "Epoch: 85, step: 600/781, loss: 3.5900726318359375\n",
      "Epoch: 85, step: 650/781, loss: 3.387972354888916\n",
      "Epoch: 85, step: 700/781, loss: 3.4827656745910645\n",
      "Epoch: 85, step: 750/781, loss: 3.4357781410217285\n",
      "Epoch: 85 completed, average loss: 3.433661431570212, time taken: 1.5482367475827534 mins\n",
      "Epoch: 86, step: 50/781, loss: 3.3785293102264404\n",
      "Epoch: 86, step: 100/781, loss: 3.405738115310669\n",
      "Epoch: 86, step: 150/781, loss: 3.5340054035186768\n",
      "Epoch: 86, step: 200/781, loss: 3.3558435440063477\n",
      "Epoch: 86, step: 250/781, loss: 3.482950448989868\n",
      "Epoch: 86, step: 300/781, loss: 3.3734469413757324\n",
      "Epoch: 86, step: 350/781, loss: 3.322850227355957\n",
      "Epoch: 86, step: 400/781, loss: 3.452291250228882\n",
      "Epoch: 86, step: 450/781, loss: 3.457428455352783\n",
      "Epoch: 86, step: 500/781, loss: 3.603256940841675\n",
      "Epoch: 86, step: 550/781, loss: 3.362691640853882\n",
      "Epoch: 86, step: 600/781, loss: 3.446446418762207\n",
      "Epoch: 86, step: 650/781, loss: 3.3631367683410645\n",
      "Epoch: 86, step: 700/781, loss: 3.434661865234375\n",
      "Epoch: 86, step: 750/781, loss: 3.518669843673706\n",
      "Epoch: 86 completed, average loss: 3.4347104635495076, time taken: 1.553362520535787 mins\n",
      "Epoch: 87, step: 50/781, loss: 3.412797212600708\n",
      "Epoch: 87, step: 100/781, loss: 3.4858672618865967\n",
      "Epoch: 87, step: 150/781, loss: 3.3868536949157715\n",
      "Epoch: 87, step: 200/781, loss: 3.4714369773864746\n",
      "Epoch: 87, step: 250/781, loss: 3.426485538482666\n",
      "Epoch: 87, step: 300/781, loss: 3.5691280364990234\n",
      "Epoch: 87, step: 350/781, loss: 3.3632917404174805\n",
      "Epoch: 87, step: 400/781, loss: 3.435163736343384\n",
      "Epoch: 87, step: 450/781, loss: 3.420111894607544\n",
      "Epoch: 87, step: 500/781, loss: 3.466442584991455\n",
      "Epoch: 87, step: 550/781, loss: 3.502929210662842\n",
      "Epoch: 87, step: 600/781, loss: 3.5212385654449463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87, step: 650/781, loss: 3.338291645050049\n",
      "Epoch: 87, step: 700/781, loss: 3.444603681564331\n",
      "Epoch: 87, step: 750/781, loss: 3.3826301097869873\n",
      "Epoch: 87 completed, average loss: 3.4332618160833928, time taken: 1.548884888490041 mins\n",
      "Epoch: 88, step: 50/781, loss: 3.378871202468872\n",
      "Epoch: 88, step: 100/781, loss: 3.535888910293579\n",
      "Epoch: 88, step: 150/781, loss: 3.4386680126190186\n",
      "Epoch: 88, step: 200/781, loss: 3.419398784637451\n",
      "Epoch: 88, step: 250/781, loss: 3.472996950149536\n",
      "Epoch: 88, step: 300/781, loss: 3.4347081184387207\n",
      "Epoch: 88, step: 350/781, loss: 3.381044864654541\n",
      "Epoch: 88, step: 400/781, loss: 3.4221930503845215\n",
      "Epoch: 88, step: 450/781, loss: 3.434091567993164\n",
      "Epoch: 88, step: 500/781, loss: 3.52830171585083\n",
      "Epoch: 88, step: 550/781, loss: 3.4620697498321533\n",
      "Epoch: 88, step: 600/781, loss: 3.3917338848114014\n",
      "Epoch: 88, step: 650/781, loss: 3.543002128601074\n",
      "Epoch: 88, step: 700/781, loss: 3.4759461879730225\n",
      "Epoch: 88, step: 750/781, loss: 3.4278669357299805\n",
      "Epoch: 88 completed, average loss: 3.432050172253852, time taken: 1.5485657850901287 mins\n",
      "Epoch: 89, step: 50/781, loss: 3.3797569274902344\n",
      "Epoch: 89, step: 100/781, loss: 3.4230966567993164\n",
      "Epoch: 89, step: 150/781, loss: 3.4020187854766846\n",
      "Epoch: 89, step: 200/781, loss: 3.4477741718292236\n",
      "Epoch: 89, step: 250/781, loss: 3.4717981815338135\n",
      "Epoch: 89, step: 300/781, loss: 3.3544843196868896\n",
      "Epoch: 89, step: 350/781, loss: 3.3551526069641113\n",
      "Epoch: 89, step: 400/781, loss: 3.306553363800049\n",
      "Epoch: 89, step: 450/781, loss: 3.463416814804077\n",
      "Epoch: 89, step: 500/781, loss: 3.4127559661865234\n",
      "Epoch: 89, step: 550/781, loss: 3.375058650970459\n",
      "Epoch: 89, step: 600/781, loss: 3.459320545196533\n",
      "Epoch: 89, step: 650/781, loss: 3.4718945026397705\n",
      "Epoch: 89, step: 700/781, loss: 3.4339540004730225\n",
      "Epoch: 89, step: 750/781, loss: 3.350891590118408\n",
      "Epoch: 89 completed, average loss: 3.4296476868447514, time taken: 1.5521231373151143 mins\n",
      "Epoch: 90, step: 50/781, loss: 3.482076406478882\n",
      "Epoch: 90, step: 100/781, loss: 3.400359630584717\n",
      "Epoch: 90, step: 150/781, loss: 3.4563632011413574\n",
      "Epoch: 90, step: 200/781, loss: 3.5274996757507324\n",
      "Epoch: 90, step: 250/781, loss: 3.463770866394043\n",
      "Epoch: 90, step: 300/781, loss: 3.3917150497436523\n",
      "Epoch: 90, step: 350/781, loss: 3.386495590209961\n",
      "Epoch: 90, step: 400/781, loss: 3.399568557739258\n",
      "Epoch: 90, step: 450/781, loss: 3.4587841033935547\n",
      "Epoch: 90, step: 500/781, loss: 3.4204516410827637\n",
      "Epoch: 90, step: 550/781, loss: 3.5321133136749268\n",
      "Epoch: 90, step: 600/781, loss: 3.462183713912964\n",
      "Epoch: 90, step: 650/781, loss: 3.518583059310913\n",
      "Epoch: 90, step: 700/781, loss: 3.4614062309265137\n",
      "Epoch: 90, step: 750/781, loss: 3.4769649505615234\n",
      "Epoch: 90 completed, average loss: 3.4310409338923025, time taken: 1.551800258954366 mins\n",
      "Epoch: 91, step: 50/781, loss: 3.4271297454833984\n",
      "Epoch: 91, step: 100/781, loss: 3.3898773193359375\n",
      "Epoch: 91, step: 150/781, loss: 3.3875012397766113\n",
      "Epoch: 91, step: 200/781, loss: 3.3899343013763428\n",
      "Epoch: 91, step: 250/781, loss: 3.4524834156036377\n",
      "Epoch: 91, step: 300/781, loss: 3.366316556930542\n",
      "Epoch: 91, step: 350/781, loss: 3.4444215297698975\n",
      "Epoch: 91, step: 400/781, loss: 3.36942982673645\n",
      "Epoch: 91, step: 450/781, loss: 3.3434994220733643\n",
      "Epoch: 91, step: 500/781, loss: 3.511092185974121\n",
      "Epoch: 91, step: 550/781, loss: 3.4543893337249756\n",
      "Epoch: 91, step: 600/781, loss: 3.4776203632354736\n",
      "Epoch: 91, step: 650/781, loss: 3.447781562805176\n",
      "Epoch: 91, step: 700/781, loss: 3.3681468963623047\n",
      "Epoch: 91, step: 750/781, loss: 3.3860037326812744\n",
      "Epoch: 91 completed, average loss: 3.4302008301592055, time taken: 1.5517860770225524 mins\n",
      "Epoch: 92, step: 50/781, loss: 3.463021755218506\n",
      "Epoch: 92, step: 100/781, loss: 3.456862211227417\n",
      "Epoch: 92, step: 150/781, loss: 3.341179609298706\n",
      "Epoch: 92, step: 200/781, loss: 3.500915050506592\n",
      "Epoch: 92, step: 250/781, loss: 3.385760545730591\n",
      "Epoch: 92, step: 300/781, loss: 3.357339382171631\n",
      "Epoch: 92, step: 350/781, loss: 3.4072914123535156\n",
      "Epoch: 92, step: 400/781, loss: 3.433760643005371\n",
      "Epoch: 92, step: 450/781, loss: 3.4824435710906982\n",
      "Epoch: 92, step: 500/781, loss: 3.4390382766723633\n",
      "Epoch: 92, step: 550/781, loss: 3.470468044281006\n",
      "Epoch: 92, step: 600/781, loss: 3.47640061378479\n",
      "Epoch: 92, step: 650/781, loss: 3.5057692527770996\n",
      "Epoch: 92, step: 700/781, loss: 3.5470852851867676\n",
      "Epoch: 92, step: 750/781, loss: 3.4755847454071045\n",
      "Epoch: 92 completed, average loss: 3.432573954671354, time taken: 1.5481456637382507 mins\n",
      "Epoch: 93, step: 50/781, loss: 3.375086784362793\n",
      "Epoch: 93, step: 100/781, loss: 3.354480504989624\n",
      "Epoch: 93, step: 150/781, loss: 3.5200839042663574\n",
      "Epoch: 93, step: 200/781, loss: 3.4302101135253906\n",
      "Epoch: 93, step: 250/781, loss: 3.445246696472168\n",
      "Epoch: 93, step: 300/781, loss: 3.505357027053833\n",
      "Epoch: 93, step: 350/781, loss: 3.433223009109497\n",
      "Epoch: 93, step: 400/781, loss: 3.4485154151916504\n",
      "Epoch: 93, step: 450/781, loss: 3.4323267936706543\n",
      "Epoch: 93, step: 500/781, loss: 3.4566566944122314\n",
      "Epoch: 93, step: 550/781, loss: 3.541501998901367\n",
      "Epoch: 93, step: 600/781, loss: 3.4945032596588135\n",
      "Epoch: 93, step: 650/781, loss: 3.389961004257202\n",
      "Epoch: 93, step: 700/781, loss: 3.4468047618865967\n",
      "Epoch: 93, step: 750/781, loss: 3.378507614135742\n",
      "Epoch: 93 completed, average loss: 3.4271806467815793, time taken: 1.5513976454734801 mins\n",
      "Epoch: 94, step: 50/781, loss: 3.464750289916992\n",
      "Epoch: 94, step: 100/781, loss: 3.445707321166992\n",
      "Epoch: 94, step: 150/781, loss: 3.368774890899658\n",
      "Epoch: 94, step: 200/781, loss: 3.4077165126800537\n",
      "Epoch: 94, step: 250/781, loss: 3.4594357013702393\n",
      "Epoch: 94, step: 300/781, loss: 3.410102605819702\n",
      "Epoch: 94, step: 350/781, loss: 3.439008951187134\n",
      "Epoch: 94, step: 400/781, loss: 3.4270198345184326\n",
      "Epoch: 94, step: 450/781, loss: 3.507805109024048\n",
      "Epoch: 94, step: 500/781, loss: 3.3963074684143066\n",
      "Epoch: 94, step: 550/781, loss: 3.383425235748291\n",
      "Epoch: 94, step: 600/781, loss: 3.363677978515625\n",
      "Epoch: 94, step: 650/781, loss: 3.4898409843444824\n",
      "Epoch: 94, step: 700/781, loss: 3.376384973526001\n",
      "Epoch: 94, step: 750/781, loss: 3.4617908000946045\n",
      "Epoch: 94 completed, average loss: 3.426540665376202, time taken: 1.5501841028531393 mins\n",
      "Epoch: 95, step: 50/781, loss: 3.3558976650238037\n",
      "Epoch: 95, step: 100/781, loss: 3.363577127456665\n",
      "Epoch: 95, step: 150/781, loss: 3.436150074005127\n",
      "Epoch: 95, step: 200/781, loss: 3.4099128246307373\n",
      "Epoch: 95, step: 250/781, loss: 3.374899387359619\n",
      "Epoch: 95, step: 300/781, loss: 3.5192394256591797\n",
      "Epoch: 95, step: 350/781, loss: 3.3358259201049805\n",
      "Epoch: 95, step: 400/781, loss: 3.4131646156311035\n",
      "Epoch: 95, step: 450/781, loss: 3.4193365573883057\n",
      "Epoch: 95, step: 500/781, loss: 3.419224977493286\n",
      "Epoch: 95, step: 550/781, loss: 3.3797619342803955\n",
      "Epoch: 95, step: 600/781, loss: 3.4624404907226562\n",
      "Epoch: 95, step: 650/781, loss: 3.399468421936035\n",
      "Epoch: 95, step: 700/781, loss: 3.436331033706665\n",
      "Epoch: 95, step: 750/781, loss: 3.412365198135376\n",
      "Epoch: 95 completed, average loss: 3.4235039270183645, time taken: 1.5498371720314026 mins\n",
      "Epoch: 96, step: 50/781, loss: 3.401758909225464\n",
      "Epoch: 96, step: 100/781, loss: 3.426170825958252\n",
      "Epoch: 96, step: 150/781, loss: 3.444021463394165\n",
      "Epoch: 96, step: 200/781, loss: 3.4965593814849854\n",
      "Epoch: 96, step: 250/781, loss: 3.412320852279663\n",
      "Epoch: 96, step: 300/781, loss: 3.5549066066741943\n",
      "Epoch: 96, step: 350/781, loss: 3.4391274452209473\n",
      "Epoch: 96, step: 400/781, loss: 3.500586986541748\n",
      "Epoch: 96, step: 450/781, loss: 3.445786237716675\n",
      "Epoch: 96, step: 500/781, loss: 3.3214006423950195\n",
      "Epoch: 96, step: 550/781, loss: 3.46659517288208\n",
      "Epoch: 96, step: 600/781, loss: 3.3539605140686035\n",
      "Epoch: 96, step: 650/781, loss: 3.499784231185913\n",
      "Epoch: 96, step: 700/781, loss: 3.478893995285034\n",
      "Epoch: 96, step: 750/781, loss: 3.428978443145752\n",
      "Epoch: 96 completed, average loss: 3.4229642496218906, time taken: 1.5517528096834818 mins\n",
      "Epoch: 97, step: 50/781, loss: 3.34930682182312\n",
      "Epoch: 97, step: 100/781, loss: 3.479621171951294\n",
      "Epoch: 97, step: 150/781, loss: 3.3382437229156494\n",
      "Epoch: 97, step: 200/781, loss: 3.4175167083740234\n",
      "Epoch: 97, step: 250/781, loss: 3.472080707550049\n",
      "Epoch: 97, step: 300/781, loss: 3.3060030937194824\n",
      "Epoch: 97, step: 350/781, loss: 3.4509940147399902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97, step: 400/781, loss: 3.4041903018951416\n",
      "Epoch: 97, step: 450/781, loss: 3.4481124877929688\n",
      "Epoch: 97, step: 500/781, loss: 3.3828704357147217\n",
      "Epoch: 97, step: 550/781, loss: 3.449763298034668\n",
      "Epoch: 97, step: 600/781, loss: 3.3969593048095703\n",
      "Epoch: 97, step: 650/781, loss: 3.414634943008423\n",
      "Epoch: 97, step: 700/781, loss: 3.4155917167663574\n",
      "Epoch: 97, step: 750/781, loss: 3.3794710636138916\n",
      "Epoch: 97 completed, average loss: 3.4222472834373407, time taken: 1.556633206208547 mins\n",
      "Epoch: 98, step: 50/781, loss: 3.3747715950012207\n",
      "Epoch: 98, step: 100/781, loss: 3.4468674659729004\n",
      "Epoch: 98, step: 150/781, loss: 3.4528050422668457\n",
      "Epoch: 98, step: 200/781, loss: 3.3497347831726074\n",
      "Epoch: 98, step: 250/781, loss: 3.46682071685791\n",
      "Epoch: 98, step: 300/781, loss: 3.4428844451904297\n",
      "Epoch: 98, step: 350/781, loss: 3.3941493034362793\n",
      "Epoch: 98, step: 400/781, loss: 3.5158908367156982\n",
      "Epoch: 98, step: 450/781, loss: 3.4220142364501953\n",
      "Epoch: 98, step: 500/781, loss: 3.407650947570801\n",
      "Epoch: 98, step: 550/781, loss: 3.4561519622802734\n",
      "Epoch: 98, step: 600/781, loss: 3.4163007736206055\n",
      "Epoch: 98, step: 650/781, loss: 3.467921257019043\n",
      "Epoch: 98, step: 700/781, loss: 3.490084648132324\n",
      "Epoch: 98, step: 750/781, loss: 3.5082223415374756\n",
      "Epoch: 98 completed, average loss: 3.4235994483078334, time taken: 1.555199913183848 mins\n",
      "Epoch: 99, step: 50/781, loss: 3.5150094032287598\n",
      "Epoch: 99, step: 100/781, loss: 3.52091646194458\n",
      "Epoch: 99, step: 150/781, loss: 3.419149398803711\n",
      "Epoch: 99, step: 200/781, loss: 3.4022574424743652\n",
      "Epoch: 99, step: 250/781, loss: 3.3709113597869873\n",
      "Epoch: 99, step: 300/781, loss: 3.4585556983947754\n",
      "Epoch: 99, step: 350/781, loss: 3.4262337684631348\n",
      "Epoch: 99, step: 400/781, loss: 3.4423141479492188\n",
      "Epoch: 99, step: 450/781, loss: 3.3985838890075684\n",
      "Epoch: 99, step: 500/781, loss: 3.4480528831481934\n",
      "Epoch: 99, step: 550/781, loss: 3.414379835128784\n",
      "Epoch: 99, step: 600/781, loss: 3.320502758026123\n",
      "Epoch: 99, step: 650/781, loss: 3.4180562496185303\n",
      "Epoch: 99, step: 700/781, loss: 3.4279887676239014\n",
      "Epoch: 99, step: 750/781, loss: 3.4876534938812256\n",
      "Epoch: 99 completed, average loss: 3.420167210465357, time taken: 1.550498942534129 mins\n"
     ]
    }
   ],
   "source": [
    "proj_dim = 64\n",
    "model = SimClr('resnet50',proj_dim).cuda()\n",
    "temperature = 0.5\n",
    "#criterion = nt_xent_loss\n",
    "criterion = SimCLR_Loss(64,0.5)\n",
    "optimizer = \"LARS\"\n",
    "model, train_loss = train_simclr(train_loader_simclr,model,criterion,optimizer,100,64,True,\"/home/ky2446/saved-models/CIFAR10-RES50-SIMCLR-BS64-PD64-LARS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9b2ffc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"NT-XENT Loss\")\n",
    "plt.title(\"CIFAR10 ResNet-50 SimClr BS:64, OP: LARS\")\n",
    "plt.plot(train_loss)\n",
    "plt.savefig(\"/home/ky2446/figures/CIFAR10-RES50-SIMCLR-BS64-PD64-LARS.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a1029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/ky2446/training-logs/CIFAR10-RES50-SIMCLR-BS64-PD64-LARS\", \"wb\") as fp: \n",
    "    pickle.dump(train_loss, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9574463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
