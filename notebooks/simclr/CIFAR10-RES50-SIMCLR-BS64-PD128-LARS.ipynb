{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748383e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# setting path\n",
    "sys.path.append(\"/home/ky2446/simclr\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/layers\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/models\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/loss\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/optim\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/dataloader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6634ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simclrpy import SimClr\n",
    "from ntxent import nt_xent_loss\n",
    "from ntxentgit import SimCLR_Loss\n",
    "from augment import TransformsSimCLR\n",
    "from utils import *\n",
    "from LARS import LARS\n",
    "from downstream import DownStream\n",
    "from dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d28fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d94c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader_simclr = train_loader_simclr(\"CIFAR10\",64)\n",
    "test_loader = test_loader(\"CIFAR10\",64)\n",
    "test_images, test_labels = get_testimgs_list(\"CIFAR10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d860e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ky2446/simclr/simclr/optim/LARS.py:136: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272178570/work/torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
      "  next_v.mul_(momentum).add_(scaled_lr, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, step: 50/781, loss: 4.825571537017822\n",
      "Epoch: 0, step: 100/781, loss: 4.855781078338623\n",
      "Epoch: 0, step: 150/781, loss: 4.813143730163574\n",
      "Epoch: 0, step: 200/781, loss: 4.905054569244385\n",
      "Epoch: 0, step: 250/781, loss: 4.788863182067871\n",
      "Epoch: 0, step: 300/781, loss: 4.7373151779174805\n",
      "Epoch: 0, step: 350/781, loss: 4.641064643859863\n",
      "Epoch: 0, step: 400/781, loss: 4.716306209564209\n",
      "Epoch: 0, step: 450/781, loss: 4.617149829864502\n",
      "Epoch: 0, step: 500/781, loss: 4.581619739532471\n",
      "Epoch: 0, step: 550/781, loss: 4.662359237670898\n",
      "Epoch: 0, step: 600/781, loss: 4.455698013305664\n",
      "Epoch: 0, step: 650/781, loss: 4.653207778930664\n",
      "Epoch: 0, step: 700/781, loss: 4.583845138549805\n",
      "Epoch: 0, step: 750/781, loss: 4.602413654327393\n",
      "Epoch: 0 completed, average loss: 4.705345274696888, time taken: 1.6330726544062297 mins\n",
      "Epoch: 1, step: 50/781, loss: 4.507848262786865\n",
      "Epoch: 1, step: 100/781, loss: 4.567656993865967\n",
      "Epoch: 1, step: 150/781, loss: 4.470755577087402\n",
      "Epoch: 1, step: 200/781, loss: 4.669991493225098\n",
      "Epoch: 1, step: 250/781, loss: 4.5658674240112305\n",
      "Epoch: 1, step: 300/781, loss: 4.423369407653809\n",
      "Epoch: 1, step: 350/781, loss: 4.390819072723389\n",
      "Epoch: 1, step: 400/781, loss: 4.47528076171875\n",
      "Epoch: 1, step: 450/781, loss: 4.583227634429932\n",
      "Epoch: 1, step: 500/781, loss: 4.469098091125488\n",
      "Epoch: 1, step: 550/781, loss: 4.492643356323242\n",
      "Epoch: 1, step: 600/781, loss: 4.348947525024414\n",
      "Epoch: 1, step: 650/781, loss: 4.388835906982422\n",
      "Epoch: 1, step: 700/781, loss: 4.435393333435059\n",
      "Epoch: 1, step: 750/781, loss: 4.37561559677124\n",
      "Epoch: 1 completed, average loss: 4.48517682824031, time taken: 1.6304744164148965 mins\n",
      "Epoch: 2, step: 50/781, loss: 4.404097080230713\n",
      "Epoch: 2, step: 100/781, loss: 4.257496356964111\n",
      "Epoch: 2, step: 150/781, loss: 4.488799095153809\n",
      "Epoch: 2, step: 200/781, loss: 4.473516464233398\n",
      "Epoch: 2, step: 250/781, loss: 4.338191509246826\n",
      "Epoch: 2, step: 300/781, loss: 4.379912853240967\n",
      "Epoch: 2, step: 350/781, loss: 4.131558895111084\n",
      "Epoch: 2, step: 400/781, loss: 4.215499401092529\n",
      "Epoch: 2, step: 450/781, loss: 4.180566787719727\n",
      "Epoch: 2, step: 500/781, loss: 4.357141971588135\n",
      "Epoch: 2, step: 550/781, loss: 4.294273376464844\n",
      "Epoch: 2, step: 600/781, loss: 4.14406156539917\n",
      "Epoch: 2, step: 650/781, loss: 4.242054462432861\n",
      "Epoch: 2, step: 700/781, loss: 4.377578258514404\n",
      "Epoch: 2, step: 750/781, loss: 4.438891887664795\n",
      "Epoch: 2 completed, average loss: 4.317486782537991, time taken: 1.6258049090703328 mins\n",
      "Epoch: 3, step: 50/781, loss: 4.208016395568848\n",
      "Epoch: 3, step: 100/781, loss: 4.298915863037109\n",
      "Epoch: 3, step: 150/781, loss: 4.110732078552246\n",
      "Epoch: 3, step: 200/781, loss: 4.370938301086426\n",
      "Epoch: 3, step: 250/781, loss: 4.2241106033325195\n",
      "Epoch: 3, step: 300/781, loss: 4.108969688415527\n",
      "Epoch: 3, step: 350/781, loss: 4.272333145141602\n",
      "Epoch: 3, step: 400/781, loss: 4.424257278442383\n",
      "Epoch: 3, step: 450/781, loss: 4.191966533660889\n",
      "Epoch: 3, step: 500/781, loss: 4.372725009918213\n",
      "Epoch: 3, step: 550/781, loss: 4.120934009552002\n",
      "Epoch: 3, step: 600/781, loss: 4.2068257331848145\n",
      "Epoch: 3, step: 650/781, loss: 4.122320175170898\n",
      "Epoch: 3, step: 700/781, loss: 4.2603936195373535\n",
      "Epoch: 3, step: 750/781, loss: 4.236570835113525\n",
      "Epoch: 3 completed, average loss: 4.22321067607357, time taken: 1.623949368794759 mins\n",
      "Epoch: 4, step: 50/781, loss: 4.133304595947266\n",
      "Epoch: 4, step: 100/781, loss: 4.107935905456543\n",
      "Epoch: 4, step: 150/781, loss: 4.210723876953125\n",
      "Epoch: 4, step: 200/781, loss: 4.168173313140869\n",
      "Epoch: 4, step: 250/781, loss: 4.320443153381348\n",
      "Epoch: 4, step: 300/781, loss: 3.9988808631896973\n",
      "Epoch: 4, step: 350/781, loss: 4.160543441772461\n",
      "Epoch: 4, step: 400/781, loss: 4.146988868713379\n",
      "Epoch: 4, step: 450/781, loss: 4.121484279632568\n",
      "Epoch: 4, step: 500/781, loss: 3.9859724044799805\n",
      "Epoch: 4, step: 550/781, loss: 4.187590599060059\n",
      "Epoch: 4, step: 600/781, loss: 4.061528205871582\n",
      "Epoch: 4, step: 650/781, loss: 4.214893817901611\n",
      "Epoch: 4, step: 700/781, loss: 3.914576530456543\n",
      "Epoch: 4, step: 750/781, loss: 4.044012069702148\n",
      "Epoch: 4 completed, average loss: 4.1396517567384254, time taken: 1.6274648904800415 mins\n",
      "Epoch: 5, step: 50/781, loss: 4.143075466156006\n",
      "Epoch: 5, step: 100/781, loss: 3.982473373413086\n",
      "Epoch: 5, step: 150/781, loss: 4.0270538330078125\n",
      "Epoch: 5, step: 200/781, loss: 4.015632629394531\n",
      "Epoch: 5, step: 250/781, loss: 4.2206315994262695\n",
      "Epoch: 5, step: 300/781, loss: 4.065157890319824\n",
      "Epoch: 5, step: 350/781, loss: 3.969212055206299\n",
      "Epoch: 5, step: 400/781, loss: 4.142823219299316\n",
      "Epoch: 5, step: 450/781, loss: 4.122050762176514\n",
      "Epoch: 5, step: 500/781, loss: 4.0900702476501465\n",
      "Epoch: 5, step: 550/781, loss: 4.0831379890441895\n",
      "Epoch: 5, step: 600/781, loss: 3.986257553100586\n",
      "Epoch: 5, step: 650/781, loss: 4.138515949249268\n",
      "Epoch: 5, step: 700/781, loss: 3.8946173191070557\n",
      "Epoch: 5, step: 750/781, loss: 4.019789695739746\n",
      "Epoch: 5 completed, average loss: 4.054638180934208, time taken: 1.6239805142084758 mins\n",
      "Epoch: 6, step: 50/781, loss: 3.93188214302063\n",
      "Epoch: 6, step: 100/781, loss: 4.02618408203125\n",
      "Epoch: 6, step: 150/781, loss: 3.812807083129883\n",
      "Epoch: 6, step: 200/781, loss: 4.00427770614624\n",
      "Epoch: 6, step: 250/781, loss: 3.9780263900756836\n",
      "Epoch: 6, step: 300/781, loss: 3.906371593475342\n",
      "Epoch: 6, step: 350/781, loss: 3.7954061031341553\n",
      "Epoch: 6, step: 400/781, loss: 4.046076774597168\n",
      "Epoch: 6, step: 450/781, loss: 3.8987557888031006\n",
      "Epoch: 6, step: 500/781, loss: 3.956549882888794\n",
      "Epoch: 6, step: 550/781, loss: 3.964508295059204\n",
      "Epoch: 6, step: 600/781, loss: 4.010307312011719\n",
      "Epoch: 6, step: 650/781, loss: 4.015315532684326\n",
      "Epoch: 6, step: 700/781, loss: 3.911369800567627\n",
      "Epoch: 6, step: 750/781, loss: 4.051670551300049\n",
      "Epoch: 6 completed, average loss: 3.994807874347428, time taken: 1.6296425541241963 mins\n",
      "Epoch: 7, step: 50/781, loss: 3.899305820465088\n",
      "Epoch: 7, step: 100/781, loss: 3.937809944152832\n",
      "Epoch: 7, step: 150/781, loss: 3.9076359272003174\n",
      "Epoch: 7, step: 200/781, loss: 3.9887473583221436\n",
      "Epoch: 7, step: 250/781, loss: 3.8625569343566895\n",
      "Epoch: 7, step: 300/781, loss: 4.09224271774292\n",
      "Epoch: 7, step: 350/781, loss: 4.088222503662109\n",
      "Epoch: 7, step: 400/781, loss: 4.005457401275635\n",
      "Epoch: 7, step: 450/781, loss: 4.042337894439697\n",
      "Epoch: 7, step: 500/781, loss: 4.091777801513672\n",
      "Epoch: 7, step: 550/781, loss: 3.9438111782073975\n",
      "Epoch: 7, step: 600/781, loss: 4.001434326171875\n",
      "Epoch: 7, step: 650/781, loss: 4.066546440124512\n",
      "Epoch: 7, step: 700/781, loss: 3.8831515312194824\n",
      "Epoch: 7, step: 750/781, loss: 4.087826728820801\n",
      "Epoch: 7 completed, average loss: 3.950477881254521, time taken: 1.6249630292256674 mins\n",
      "Epoch: 8, step: 50/781, loss: 3.9079482555389404\n",
      "Epoch: 8, step: 100/781, loss: 3.8419108390808105\n",
      "Epoch: 8, step: 150/781, loss: 3.86984920501709\n",
      "Epoch: 8, step: 200/781, loss: 3.964627504348755\n",
      "Epoch: 8, step: 250/781, loss: 3.8986799716949463\n",
      "Epoch: 8, step: 300/781, loss: 3.9275155067443848\n",
      "Epoch: 8, step: 350/781, loss: 3.94104266166687\n",
      "Epoch: 8, step: 400/781, loss: 3.879401922225952\n",
      "Epoch: 8, step: 450/781, loss: 3.94211483001709\n",
      "Epoch: 8, step: 500/781, loss: 3.9643006324768066\n",
      "Epoch: 8, step: 550/781, loss: 3.9759624004364014\n",
      "Epoch: 8, step: 600/781, loss: 3.8265998363494873\n",
      "Epoch: 8, step: 650/781, loss: 3.8845677375793457\n",
      "Epoch: 8, step: 700/781, loss: 3.7761456966400146\n",
      "Epoch: 8, step: 750/781, loss: 3.8651349544525146\n",
      "Epoch: 8 completed, average loss: 3.910573291106963, time taken: 1.6247627456982932 mins\n",
      "Epoch: 9, step: 50/781, loss: 3.8419699668884277\n",
      "Epoch: 9, step: 100/781, loss: 3.894169330596924\n",
      "Epoch: 9, step: 150/781, loss: 3.9194602966308594\n",
      "Epoch: 9, step: 200/781, loss: 3.856424331665039\n",
      "Epoch: 9, step: 250/781, loss: 3.8897526264190674\n",
      "Epoch: 9, step: 300/781, loss: 3.8074941635131836\n",
      "Epoch: 9, step: 350/781, loss: 3.828653335571289\n",
      "Epoch: 9, step: 400/781, loss: 3.8919575214385986\n",
      "Epoch: 9, step: 450/781, loss: 3.90136456489563\n",
      "Epoch: 9, step: 500/781, loss: 4.019501686096191\n",
      "Epoch: 9, step: 550/781, loss: 3.828967332839966\n",
      "Epoch: 9, step: 600/781, loss: 3.8880860805511475\n",
      "Epoch: 9, step: 650/781, loss: 3.8135364055633545\n",
      "Epoch: 9, step: 700/781, loss: 3.7397308349609375\n",
      "Epoch: 9, step: 750/781, loss: 3.9997336864471436\n",
      "Epoch: 9 completed, average loss: 3.8845823513255686, time taken: 1.6269094626108804 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, step: 50/781, loss: 3.8798344135284424\n",
      "Epoch: 10, step: 100/781, loss: 3.883601427078247\n",
      "Epoch: 10, step: 150/781, loss: 3.923090696334839\n",
      "Epoch: 10, step: 200/781, loss: 3.781083822250366\n",
      "Epoch: 10, step: 250/781, loss: 3.922786235809326\n",
      "Epoch: 10, step: 300/781, loss: 3.8607308864593506\n",
      "Epoch: 10, step: 350/781, loss: 3.826582431793213\n",
      "Epoch: 10, step: 400/781, loss: 3.799001455307007\n",
      "Epoch: 10, step: 450/781, loss: 3.8789753913879395\n",
      "Epoch: 10, step: 500/781, loss: 3.951040029525757\n",
      "Epoch: 10, step: 550/781, loss: 3.835566520690918\n",
      "Epoch: 10, step: 600/781, loss: 3.758279323577881\n",
      "Epoch: 10, step: 650/781, loss: 3.737610101699829\n",
      "Epoch: 10, step: 700/781, loss: 3.7826080322265625\n",
      "Epoch: 10, step: 750/781, loss: 3.8218393325805664\n",
      "Epoch: 10 completed, average loss: 3.8558261727248815, time taken: 1.6281283497810364 mins\n",
      "Epoch: 11, step: 50/781, loss: 3.938852548599243\n",
      "Epoch: 11, step: 100/781, loss: 3.8852219581604004\n",
      "Epoch: 11, step: 150/781, loss: 3.8411452770233154\n",
      "Epoch: 11, step: 200/781, loss: 3.8224384784698486\n",
      "Epoch: 11, step: 250/781, loss: 3.7310941219329834\n",
      "Epoch: 11, step: 300/781, loss: 3.7796504497528076\n",
      "Epoch: 11, step: 350/781, loss: 3.828390121459961\n",
      "Epoch: 11, step: 400/781, loss: 3.854954957962036\n",
      "Epoch: 11, step: 450/781, loss: 3.7453625202178955\n",
      "Epoch: 11, step: 500/781, loss: 3.8242602348327637\n",
      "Epoch: 11, step: 550/781, loss: 3.7817373275756836\n",
      "Epoch: 11, step: 600/781, loss: 3.817063808441162\n",
      "Epoch: 11, step: 650/781, loss: 3.821673631668091\n",
      "Epoch: 11, step: 700/781, loss: 3.7032203674316406\n",
      "Epoch: 11, step: 750/781, loss: 3.838012218475342\n",
      "Epoch: 11 completed, average loss: 3.829011071812023, time taken: 1.6215458552042643 mins\n",
      "Epoch: 12, step: 50/781, loss: 3.727116584777832\n",
      "Epoch: 12, step: 100/781, loss: 3.7873847484588623\n",
      "Epoch: 12, step: 150/781, loss: 3.7978668212890625\n",
      "Epoch: 12, step: 200/781, loss: 3.827561616897583\n",
      "Epoch: 12, step: 250/781, loss: 3.7639999389648438\n",
      "Epoch: 12, step: 300/781, loss: 3.9343984127044678\n",
      "Epoch: 12, step: 350/781, loss: 3.829120397567749\n",
      "Epoch: 12, step: 400/781, loss: 3.829528331756592\n",
      "Epoch: 12, step: 450/781, loss: 3.756098508834839\n",
      "Epoch: 12, step: 500/781, loss: 3.6293880939483643\n",
      "Epoch: 12, step: 550/781, loss: 3.734665632247925\n",
      "Epoch: 12, step: 600/781, loss: 3.9184725284576416\n",
      "Epoch: 12, step: 650/781, loss: 3.8866117000579834\n",
      "Epoch: 12, step: 700/781, loss: 3.945676803588867\n",
      "Epoch: 12, step: 750/781, loss: 3.8074889183044434\n",
      "Epoch: 12 completed, average loss: 3.807246812327113, time taken: 1.6269190748532614 mins\n",
      "Epoch: 13, step: 50/781, loss: 3.773249626159668\n",
      "Epoch: 13, step: 100/781, loss: 3.7809743881225586\n",
      "Epoch: 13, step: 150/781, loss: 3.796128511428833\n",
      "Epoch: 13, step: 200/781, loss: 3.785794496536255\n",
      "Epoch: 13, step: 250/781, loss: 3.811913013458252\n",
      "Epoch: 13, step: 300/781, loss: 3.715531349182129\n",
      "Epoch: 13, step: 350/781, loss: 3.8331613540649414\n",
      "Epoch: 13, step: 400/781, loss: 3.6924991607666016\n",
      "Epoch: 13, step: 450/781, loss: 3.7412304878234863\n",
      "Epoch: 13, step: 500/781, loss: 3.772519111633301\n",
      "Epoch: 13, step: 550/781, loss: 3.8338751792907715\n",
      "Epoch: 13, step: 600/781, loss: 3.752535343170166\n",
      "Epoch: 13, step: 650/781, loss: 3.6272153854370117\n",
      "Epoch: 13, step: 700/781, loss: 3.805626153945923\n",
      "Epoch: 13, step: 750/781, loss: 3.814420700073242\n",
      "Epoch: 13 completed, average loss: 3.7907280857828605, time taken: 1.6259597301483155 mins\n",
      "Epoch: 14, step: 50/781, loss: 3.7848055362701416\n",
      "Epoch: 14, step: 100/781, loss: 3.724722385406494\n",
      "Epoch: 14, step: 150/781, loss: 3.6831157207489014\n",
      "Epoch: 14, step: 200/781, loss: 3.803506374359131\n",
      "Epoch: 14, step: 250/781, loss: 3.8451685905456543\n",
      "Epoch: 14, step: 300/781, loss: 3.751164674758911\n",
      "Epoch: 14, step: 350/781, loss: 3.776001453399658\n",
      "Epoch: 14, step: 400/781, loss: 3.751796245574951\n",
      "Epoch: 14, step: 450/781, loss: 3.8210747241973877\n",
      "Epoch: 14, step: 500/781, loss: 3.7650368213653564\n",
      "Epoch: 14, step: 550/781, loss: 3.7375059127807617\n",
      "Epoch: 14, step: 600/781, loss: 3.8186655044555664\n",
      "Epoch: 14, step: 650/781, loss: 3.8198556900024414\n",
      "Epoch: 14, step: 700/781, loss: 3.805163860321045\n",
      "Epoch: 14, step: 750/781, loss: 3.6897189617156982\n",
      "Epoch: 14 completed, average loss: 3.7667202198551193, time taken: 1.633704626560211 mins\n",
      "Epoch: 15, step: 50/781, loss: 3.8057198524475098\n",
      "Epoch: 15, step: 100/781, loss: 3.719104766845703\n",
      "Epoch: 15, step: 150/781, loss: 3.6695871353149414\n",
      "Epoch: 15, step: 200/781, loss: 3.7239632606506348\n",
      "Epoch: 15, step: 250/781, loss: 3.8124678134918213\n",
      "Epoch: 15, step: 300/781, loss: 3.7874770164489746\n",
      "Epoch: 15, step: 350/781, loss: 3.6069087982177734\n",
      "Epoch: 15, step: 400/781, loss: 3.6377382278442383\n",
      "Epoch: 15, step: 450/781, loss: 3.717169761657715\n",
      "Epoch: 15, step: 500/781, loss: 3.7058191299438477\n",
      "Epoch: 15, step: 550/781, loss: 3.778810739517212\n",
      "Epoch: 15, step: 600/781, loss: 3.8129982948303223\n",
      "Epoch: 15, step: 650/781, loss: 3.693937301635742\n",
      "Epoch: 15, step: 700/781, loss: 3.6478402614593506\n",
      "Epoch: 15, step: 750/781, loss: 3.7051148414611816\n",
      "Epoch: 15 completed, average loss: 3.7534200400304853, time taken: 1.6258797963460287 mins\n",
      "Epoch: 16, step: 50/781, loss: 3.7826647758483887\n",
      "Epoch: 16, step: 100/781, loss: 3.7065348625183105\n",
      "Epoch: 16, step: 150/781, loss: 3.74489688873291\n",
      "Epoch: 16, step: 200/781, loss: 3.709584951400757\n",
      "Epoch: 16, step: 250/781, loss: 3.7379562854766846\n",
      "Epoch: 16, step: 300/781, loss: 3.7868282794952393\n",
      "Epoch: 16, step: 350/781, loss: 3.7535996437072754\n",
      "Epoch: 16, step: 400/781, loss: 3.7991943359375\n",
      "Epoch: 16, step: 450/781, loss: 3.7515010833740234\n",
      "Epoch: 16, step: 500/781, loss: 3.806425094604492\n",
      "Epoch: 16, step: 550/781, loss: 3.776589870452881\n",
      "Epoch: 16, step: 600/781, loss: 3.663267135620117\n",
      "Epoch: 16, step: 650/781, loss: 3.708916425704956\n",
      "Epoch: 16, step: 700/781, loss: 3.6444091796875\n",
      "Epoch: 16, step: 750/781, loss: 3.8661351203918457\n",
      "Epoch: 16 completed, average loss: 3.7315056812442675, time taken: 1.6284497857093811 mins\n",
      "Epoch: 17, step: 50/781, loss: 3.77962589263916\n",
      "Epoch: 17, step: 100/781, loss: 3.7366533279418945\n",
      "Epoch: 17, step: 150/781, loss: 3.6952929496765137\n",
      "Epoch: 17, step: 200/781, loss: 3.785024881362915\n",
      "Epoch: 17, step: 250/781, loss: 3.7005093097686768\n",
      "Epoch: 17, step: 300/781, loss: 3.694072723388672\n",
      "Epoch: 17, step: 350/781, loss: 3.726140260696411\n",
      "Epoch: 17, step: 400/781, loss: 3.7597227096557617\n",
      "Epoch: 17, step: 450/781, loss: 3.669919967651367\n",
      "Epoch: 17, step: 500/781, loss: 3.7832400798797607\n",
      "Epoch: 17, step: 550/781, loss: 3.6878693103790283\n",
      "Epoch: 17, step: 600/781, loss: 3.5939056873321533\n",
      "Epoch: 17, step: 650/781, loss: 3.669687271118164\n",
      "Epoch: 17, step: 700/781, loss: 3.6591238975524902\n",
      "Epoch: 17, step: 750/781, loss: 3.709933280944824\n",
      "Epoch: 17 completed, average loss: 3.7112918052722184, time taken: 1.6322210868199667 mins\n",
      "Epoch: 18, step: 50/781, loss: 3.80679988861084\n",
      "Epoch: 18, step: 100/781, loss: 3.8353564739227295\n",
      "Epoch: 18, step: 150/781, loss: 3.643613576889038\n",
      "Epoch: 18, step: 200/781, loss: 3.7245302200317383\n",
      "Epoch: 18, step: 250/781, loss: 3.680884599685669\n",
      "Epoch: 18, step: 300/781, loss: 3.7187747955322266\n",
      "Epoch: 18, step: 350/781, loss: 3.7610175609588623\n",
      "Epoch: 18, step: 400/781, loss: 3.6705851554870605\n",
      "Epoch: 18, step: 450/781, loss: 3.7261297702789307\n",
      "Epoch: 18, step: 500/781, loss: 3.7276437282562256\n",
      "Epoch: 18, step: 550/781, loss: 3.5971813201904297\n",
      "Epoch: 18, step: 600/781, loss: 3.6642873287200928\n",
      "Epoch: 18, step: 650/781, loss: 3.586714029312134\n",
      "Epoch: 18, step: 700/781, loss: 3.6282525062561035\n",
      "Epoch: 18, step: 750/781, loss: 3.7522659301757812\n",
      "Epoch: 18 completed, average loss: 3.698036575439492, time taken: 1.6340160846710206 mins\n",
      "Epoch: 19, step: 50/781, loss: 3.6631438732147217\n",
      "Epoch: 19, step: 100/781, loss: 3.7544689178466797\n",
      "Epoch: 19, step: 150/781, loss: 3.6998698711395264\n",
      "Epoch: 19, step: 200/781, loss: 3.7033655643463135\n",
      "Epoch: 19, step: 250/781, loss: 3.7463161945343018\n",
      "Epoch: 19, step: 300/781, loss: 3.6621453762054443\n",
      "Epoch: 19, step: 350/781, loss: 3.6815743446350098\n",
      "Epoch: 19, step: 400/781, loss: 3.5549139976501465\n",
      "Epoch: 19, step: 450/781, loss: 3.7497670650482178\n",
      "Epoch: 19, step: 500/781, loss: 3.6810669898986816\n",
      "Epoch: 19, step: 550/781, loss: 3.697517156600952\n",
      "Epoch: 19, step: 600/781, loss: 3.767380475997925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, step: 650/781, loss: 3.6245663166046143\n",
      "Epoch: 19, step: 700/781, loss: 3.715043544769287\n",
      "Epoch: 19, step: 750/781, loss: 3.6429708003997803\n",
      "Epoch: 19 completed, average loss: 3.6768379916607494, time taken: 1.6221771399180094 mins\n",
      "Epoch: 20, step: 50/781, loss: 3.5989716053009033\n",
      "Epoch: 20, step: 100/781, loss: 3.63293194770813\n",
      "Epoch: 20, step: 150/781, loss: 3.737175464630127\n",
      "Epoch: 20, step: 200/781, loss: 3.6663293838500977\n",
      "Epoch: 20, step: 250/781, loss: 3.646725654602051\n",
      "Epoch: 20, step: 300/781, loss: 3.7303922176361084\n",
      "Epoch: 20, step: 350/781, loss: 3.6245439052581787\n",
      "Epoch: 20, step: 400/781, loss: 3.5941426753997803\n",
      "Epoch: 20, step: 450/781, loss: 3.584425210952759\n",
      "Epoch: 20, step: 500/781, loss: 3.704878568649292\n",
      "Epoch: 20, step: 550/781, loss: 3.7307519912719727\n",
      "Epoch: 20, step: 600/781, loss: 3.7517125606536865\n",
      "Epoch: 20, step: 650/781, loss: 3.7140092849731445\n",
      "Epoch: 20, step: 700/781, loss: 3.6999542713165283\n",
      "Epoch: 20, step: 750/781, loss: 3.671377182006836\n",
      "Epoch: 20 completed, average loss: 3.6652483338735777, time taken: 1.6417141477266948 mins\n",
      "Epoch: 21, step: 50/781, loss: 3.6002750396728516\n",
      "Epoch: 21, step: 100/781, loss: 3.6180574893951416\n",
      "Epoch: 21, step: 150/781, loss: 3.7076470851898193\n",
      "Epoch: 21, step: 200/781, loss: 3.5443062782287598\n",
      "Epoch: 21, step: 250/781, loss: 3.587200164794922\n",
      "Epoch: 21, step: 300/781, loss: 3.817690372467041\n",
      "Epoch: 21, step: 350/781, loss: 3.6349124908447266\n",
      "Epoch: 21, step: 400/781, loss: 3.6892693042755127\n",
      "Epoch: 21, step: 450/781, loss: 3.601487636566162\n",
      "Epoch: 21, step: 500/781, loss: 3.5891730785369873\n",
      "Epoch: 21, step: 550/781, loss: 3.6767849922180176\n",
      "Epoch: 21, step: 600/781, loss: 3.66695237159729\n",
      "Epoch: 21, step: 650/781, loss: 3.6672139167785645\n",
      "Epoch: 21, step: 700/781, loss: 3.596508741378784\n",
      "Epoch: 21, step: 750/781, loss: 3.78354811668396\n",
      "Epoch: 21 completed, average loss: 3.660938763893215, time taken: 1.6314759810765584 mins\n",
      "Epoch: 22, step: 50/781, loss: 3.519756317138672\n",
      "Epoch: 22, step: 100/781, loss: 3.6839776039123535\n",
      "Epoch: 22, step: 150/781, loss: 3.705073595046997\n",
      "Epoch: 22, step: 200/781, loss: 3.725125312805176\n",
      "Epoch: 22, step: 250/781, loss: 3.737407922744751\n",
      "Epoch: 22, step: 300/781, loss: 3.6321353912353516\n",
      "Epoch: 22, step: 350/781, loss: 3.727898597717285\n",
      "Epoch: 22, step: 400/781, loss: 3.6350135803222656\n",
      "Epoch: 22, step: 450/781, loss: 3.592432975769043\n",
      "Epoch: 22, step: 500/781, loss: 3.6115849018096924\n",
      "Epoch: 22, step: 550/781, loss: 3.6485915184020996\n",
      "Epoch: 22, step: 600/781, loss: 3.5183463096618652\n",
      "Epoch: 22, step: 650/781, loss: 3.599118709564209\n",
      "Epoch: 22, step: 700/781, loss: 3.5567996501922607\n",
      "Epoch: 22, step: 750/781, loss: 3.65059232711792\n",
      "Epoch: 22 completed, average loss: 3.648127066799071, time taken: 1.6214184840520223 mins\n",
      "Epoch: 23, step: 50/781, loss: 3.6458606719970703\n",
      "Epoch: 23, step: 100/781, loss: 3.6493170261383057\n",
      "Epoch: 23, step: 150/781, loss: 3.6219401359558105\n",
      "Epoch: 23, step: 200/781, loss: 3.5715644359588623\n",
      "Epoch: 23, step: 250/781, loss: 3.5544795989990234\n",
      "Epoch: 23, step: 300/781, loss: 3.668605327606201\n",
      "Epoch: 23, step: 350/781, loss: 3.686100721359253\n",
      "Epoch: 23, step: 400/781, loss: 3.593320846557617\n",
      "Epoch: 23, step: 450/781, loss: 3.699719190597534\n",
      "Epoch: 23, step: 500/781, loss: 3.577357530593872\n",
      "Epoch: 23, step: 550/781, loss: 3.569017171859741\n",
      "Epoch: 23, step: 600/781, loss: 3.5402135848999023\n",
      "Epoch: 23, step: 650/781, loss: 3.610302209854126\n",
      "Epoch: 23, step: 700/781, loss: 3.6427576541900635\n",
      "Epoch: 23, step: 750/781, loss: 3.5955607891082764\n",
      "Epoch: 23 completed, average loss: 3.636563369467683, time taken: 1.6304706931114197 mins\n",
      "Epoch: 24, step: 50/781, loss: 3.7626821994781494\n",
      "Epoch: 24, step: 100/781, loss: 3.7862370014190674\n",
      "Epoch: 24, step: 150/781, loss: 3.6718966960906982\n",
      "Epoch: 24, step: 200/781, loss: 3.6774954795837402\n",
      "Epoch: 24, step: 250/781, loss: 3.546994924545288\n",
      "Epoch: 24, step: 300/781, loss: 3.773603677749634\n",
      "Epoch: 24, step: 350/781, loss: 3.565448045730591\n",
      "Epoch: 24, step: 400/781, loss: 3.6266226768493652\n",
      "Epoch: 24, step: 450/781, loss: 3.6954033374786377\n",
      "Epoch: 24, step: 500/781, loss: 3.685032844543457\n",
      "Epoch: 24, step: 550/781, loss: 3.6832990646362305\n",
      "Epoch: 24, step: 600/781, loss: 3.5881919860839844\n",
      "Epoch: 24, step: 650/781, loss: 3.56363582611084\n",
      "Epoch: 24, step: 700/781, loss: 3.7209701538085938\n",
      "Epoch: 24, step: 750/781, loss: 3.643995761871338\n",
      "Epoch: 24 completed, average loss: 3.630366023768231, time taken: 1.6295912543932596 mins\n",
      "Epoch: 25, step: 50/781, loss: 3.613753318786621\n",
      "Epoch: 25, step: 100/781, loss: 3.596580982208252\n",
      "Epoch: 25, step: 150/781, loss: 3.5857789516448975\n",
      "Epoch: 25, step: 200/781, loss: 3.572282075881958\n",
      "Epoch: 25, step: 250/781, loss: 3.6793830394744873\n",
      "Epoch: 25, step: 300/781, loss: 3.544240713119507\n",
      "Epoch: 25, step: 350/781, loss: 3.5421226024627686\n",
      "Epoch: 25, step: 400/781, loss: 3.5877702236175537\n",
      "Epoch: 25, step: 450/781, loss: 3.758514881134033\n",
      "Epoch: 25, step: 500/781, loss: 3.5514822006225586\n",
      "Epoch: 25, step: 550/781, loss: 3.603079080581665\n",
      "Epoch: 25, step: 600/781, loss: 3.6511001586914062\n",
      "Epoch: 25, step: 650/781, loss: 3.5800325870513916\n",
      "Epoch: 25, step: 700/781, loss: 3.639657497406006\n",
      "Epoch: 25, step: 750/781, loss: 3.5767393112182617\n",
      "Epoch: 25 completed, average loss: 3.614850351660871, time taken: 1.6244378765424092 mins\n",
      "Epoch: 26, step: 50/781, loss: 3.6314191818237305\n",
      "Epoch: 26, step: 100/781, loss: 3.6003193855285645\n",
      "Epoch: 26, step: 150/781, loss: 3.5986056327819824\n",
      "Epoch: 26, step: 200/781, loss: 3.554802894592285\n",
      "Epoch: 26, step: 250/781, loss: 3.5905916690826416\n",
      "Epoch: 26, step: 300/781, loss: 3.62101674079895\n",
      "Epoch: 26, step: 350/781, loss: 3.5616443157196045\n",
      "Epoch: 26, step: 400/781, loss: 3.583948850631714\n",
      "Epoch: 26, step: 450/781, loss: 3.5823795795440674\n",
      "Epoch: 26, step: 500/781, loss: 3.6070263385772705\n",
      "Epoch: 26, step: 550/781, loss: 3.604583740234375\n",
      "Epoch: 26, step: 600/781, loss: 3.6477251052856445\n",
      "Epoch: 26, step: 650/781, loss: 3.647671699523926\n",
      "Epoch: 26, step: 700/781, loss: 3.6091065406799316\n",
      "Epoch: 26, step: 750/781, loss: 3.588364362716675\n",
      "Epoch: 26 completed, average loss: 3.607082918877791, time taken: 1.6334412495295207 mins\n",
      "Epoch: 27, step: 50/781, loss: 3.618356943130493\n",
      "Epoch: 27, step: 100/781, loss: 3.5724689960479736\n",
      "Epoch: 27, step: 150/781, loss: 3.7370221614837646\n",
      "Epoch: 27, step: 200/781, loss: 3.5727031230926514\n",
      "Epoch: 27, step: 250/781, loss: 3.576596736907959\n",
      "Epoch: 27, step: 300/781, loss: 3.7112016677856445\n",
      "Epoch: 27, step: 350/781, loss: 3.6661036014556885\n",
      "Epoch: 27, step: 400/781, loss: 3.5726685523986816\n",
      "Epoch: 27, step: 450/781, loss: 3.5262463092803955\n",
      "Epoch: 27, step: 500/781, loss: 3.6662042140960693\n",
      "Epoch: 27, step: 550/781, loss: 3.6226511001586914\n",
      "Epoch: 27, step: 600/781, loss: 3.594194173812866\n",
      "Epoch: 27, step: 650/781, loss: 3.5255517959594727\n",
      "Epoch: 27, step: 700/781, loss: 3.595975160598755\n",
      "Epoch: 27, step: 750/781, loss: 3.5922305583953857\n",
      "Epoch: 27 completed, average loss: 3.6019149116608915, time taken: 1.6243940075238545 mins\n",
      "Epoch: 28, step: 50/781, loss: 3.6371681690216064\n",
      "Epoch: 28, step: 100/781, loss: 3.6313915252685547\n",
      "Epoch: 28, step: 150/781, loss: 3.7073068618774414\n",
      "Epoch: 28, step: 200/781, loss: 3.703207492828369\n",
      "Epoch: 28, step: 250/781, loss: 3.665750026702881\n",
      "Epoch: 28, step: 300/781, loss: 3.5449821949005127\n",
      "Epoch: 28, step: 350/781, loss: 3.6389944553375244\n",
      "Epoch: 28, step: 400/781, loss: 3.599978446960449\n",
      "Epoch: 28, step: 450/781, loss: 3.569908618927002\n",
      "Epoch: 28, step: 500/781, loss: 3.5839290618896484\n",
      "Epoch: 28, step: 550/781, loss: 3.609635829925537\n",
      "Epoch: 28, step: 600/781, loss: 3.5901827812194824\n",
      "Epoch: 28, step: 650/781, loss: 3.5280635356903076\n",
      "Epoch: 28, step: 700/781, loss: 3.6373231410980225\n",
      "Epoch: 28, step: 750/781, loss: 3.5394277572631836\n",
      "Epoch: 28 completed, average loss: 3.596258568244768, time taken: 1.626897641023 mins\n",
      "Epoch: 29, step: 50/781, loss: 3.54219126701355\n",
      "Epoch: 29, step: 100/781, loss: 3.671060562133789\n",
      "Epoch: 29, step: 150/781, loss: 3.63132905960083\n",
      "Epoch: 29, step: 200/781, loss: 3.5272014141082764\n",
      "Epoch: 29, step: 250/781, loss: 3.507326602935791\n",
      "Epoch: 29, step: 300/781, loss: 3.4470860958099365\n",
      "Epoch: 29, step: 350/781, loss: 3.60020112991333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, step: 400/781, loss: 3.571763038635254\n",
      "Epoch: 29, step: 450/781, loss: 3.5354011058807373\n",
      "Epoch: 29, step: 500/781, loss: 3.5608842372894287\n",
      "Epoch: 29, step: 550/781, loss: 3.5339560508728027\n",
      "Epoch: 29, step: 600/781, loss: 3.5084402561187744\n",
      "Epoch: 29, step: 650/781, loss: 3.611463785171509\n",
      "Epoch: 29, step: 700/781, loss: 3.5656321048736572\n",
      "Epoch: 29, step: 750/781, loss: 3.603398323059082\n",
      "Epoch: 29 completed, average loss: 3.584597220952013, time taken: 1.6287566701571146 mins\n",
      "Epoch: 30, step: 50/781, loss: 3.5723915100097656\n",
      "Epoch: 30, step: 100/781, loss: 3.6216678619384766\n",
      "Epoch: 30, step: 150/781, loss: 3.4932916164398193\n",
      "Epoch: 30, step: 200/781, loss: 3.5040788650512695\n",
      "Epoch: 30, step: 250/781, loss: 3.54750394821167\n",
      "Epoch: 30, step: 300/781, loss: 3.633607864379883\n",
      "Epoch: 30, step: 350/781, loss: 3.651761054992676\n",
      "Epoch: 30, step: 400/781, loss: 3.554814577102661\n",
      "Epoch: 30, step: 450/781, loss: 3.6741864681243896\n",
      "Epoch: 30, step: 500/781, loss: 3.506908416748047\n",
      "Epoch: 30, step: 550/781, loss: 3.6625773906707764\n",
      "Epoch: 30, step: 600/781, loss: 3.5097053050994873\n",
      "Epoch: 30, step: 650/781, loss: 3.5561435222625732\n",
      "Epoch: 30, step: 700/781, loss: 3.630107879638672\n",
      "Epoch: 30, step: 750/781, loss: 3.5509908199310303\n",
      "Epoch: 30 completed, average loss: 3.581585434426419, time taken: 1.6250909050305684 mins\n",
      "Epoch: 31, step: 50/781, loss: 3.542384386062622\n",
      "Epoch: 31, step: 100/781, loss: 3.592146396636963\n",
      "Epoch: 31, step: 150/781, loss: 3.596674680709839\n",
      "Epoch: 31, step: 200/781, loss: 3.5623891353607178\n",
      "Epoch: 31, step: 250/781, loss: 3.6493980884552\n",
      "Epoch: 31, step: 300/781, loss: 3.635058879852295\n",
      "Epoch: 31, step: 350/781, loss: 3.65403413772583\n",
      "Epoch: 31, step: 400/781, loss: 3.6810526847839355\n",
      "Epoch: 31, step: 450/781, loss: 3.481712579727173\n",
      "Epoch: 31, step: 500/781, loss: 3.474069833755493\n",
      "Epoch: 31, step: 550/781, loss: 3.5604188442230225\n",
      "Epoch: 31, step: 600/781, loss: 3.524343490600586\n",
      "Epoch: 31, step: 650/781, loss: 3.530207872390747\n",
      "Epoch: 31, step: 700/781, loss: 3.5922584533691406\n",
      "Epoch: 31, step: 750/781, loss: 3.551079750061035\n",
      "Epoch: 31 completed, average loss: 3.5728019724734765, time taken: 1.620939067999522 mins\n",
      "Epoch: 32, step: 50/781, loss: 3.575408697128296\n",
      "Epoch: 32, step: 100/781, loss: 3.5880908966064453\n",
      "Epoch: 32, step: 150/781, loss: 3.6146929264068604\n",
      "Epoch: 32, step: 200/781, loss: 3.5890183448791504\n",
      "Epoch: 32, step: 250/781, loss: 3.4968974590301514\n",
      "Epoch: 32, step: 300/781, loss: 3.6203811168670654\n",
      "Epoch: 32, step: 350/781, loss: 3.614680290222168\n",
      "Epoch: 32, step: 400/781, loss: 3.713320016860962\n",
      "Epoch: 32, step: 450/781, loss: 3.5351574420928955\n",
      "Epoch: 32, step: 500/781, loss: 3.624793291091919\n",
      "Epoch: 32, step: 550/781, loss: 3.5284583568573\n",
      "Epoch: 32, step: 600/781, loss: 3.689840793609619\n",
      "Epoch: 32, step: 650/781, loss: 3.6434683799743652\n",
      "Epoch: 32, step: 700/781, loss: 3.6243345737457275\n",
      "Epoch: 32, step: 750/781, loss: 3.5725412368774414\n",
      "Epoch: 32 completed, average loss: 3.57195358911336, time taken: 1.63109077612559 mins\n",
      "Epoch: 33, step: 50/781, loss: 3.4645514488220215\n",
      "Epoch: 33, step: 100/781, loss: 3.474777936935425\n",
      "Epoch: 33, step: 150/781, loss: 3.5543630123138428\n",
      "Epoch: 33, step: 200/781, loss: 3.633453130722046\n",
      "Epoch: 33, step: 250/781, loss: 3.618661880493164\n",
      "Epoch: 33, step: 300/781, loss: 3.4457883834838867\n",
      "Epoch: 33, step: 350/781, loss: 3.5489296913146973\n",
      "Epoch: 33, step: 400/781, loss: 3.6179590225219727\n",
      "Epoch: 33, step: 450/781, loss: 3.5163321495056152\n",
      "Epoch: 33, step: 500/781, loss: 3.572202205657959\n",
      "Epoch: 33, step: 550/781, loss: 3.5042226314544678\n",
      "Epoch: 33, step: 600/781, loss: 3.5466933250427246\n",
      "Epoch: 33, step: 650/781, loss: 3.5069146156311035\n",
      "Epoch: 33, step: 700/781, loss: 3.599163770675659\n",
      "Epoch: 33, step: 750/781, loss: 3.6043615341186523\n",
      "Epoch: 33 completed, average loss: 3.5633032395195565, time taken: 1.6370683670043946 mins\n",
      "Epoch: 34, step: 50/781, loss: 3.637686014175415\n",
      "Epoch: 34, step: 100/781, loss: 3.4948208332061768\n",
      "Epoch: 34, step: 150/781, loss: 3.5884640216827393\n",
      "Epoch: 34, step: 200/781, loss: 3.6814818382263184\n",
      "Epoch: 34, step: 250/781, loss: 3.607231855392456\n",
      "Epoch: 34, step: 300/781, loss: 3.561962366104126\n",
      "Epoch: 34, step: 350/781, loss: 3.571776866912842\n",
      "Epoch: 34, step: 400/781, loss: 3.608968734741211\n",
      "Epoch: 34, step: 450/781, loss: 3.594463586807251\n",
      "Epoch: 34, step: 500/781, loss: 3.505237102508545\n",
      "Epoch: 34, step: 550/781, loss: 3.5293779373168945\n",
      "Epoch: 34, step: 600/781, loss: 3.5861732959747314\n",
      "Epoch: 34, step: 650/781, loss: 3.65339732170105\n",
      "Epoch: 34, step: 700/781, loss: 3.6383657455444336\n",
      "Epoch: 34, step: 750/781, loss: 3.6256632804870605\n",
      "Epoch: 34 completed, average loss: 3.5598260822125187, time taken: 1.632365636030833 mins\n",
      "Epoch: 35, step: 50/781, loss: 3.5249617099761963\n",
      "Epoch: 35, step: 100/781, loss: 3.5488133430480957\n",
      "Epoch: 35, step: 150/781, loss: 3.620413303375244\n",
      "Epoch: 35, step: 200/781, loss: 3.4369115829467773\n",
      "Epoch: 35, step: 250/781, loss: 3.589710235595703\n",
      "Epoch: 35, step: 300/781, loss: 3.495260000228882\n",
      "Epoch: 35, step: 350/781, loss: 3.508011817932129\n",
      "Epoch: 35, step: 400/781, loss: 3.5561206340789795\n",
      "Epoch: 35, step: 450/781, loss: 3.5663797855377197\n",
      "Epoch: 35, step: 500/781, loss: 3.5420196056365967\n",
      "Epoch: 35, step: 550/781, loss: 3.51798415184021\n",
      "Epoch: 35, step: 600/781, loss: 3.4714670181274414\n",
      "Epoch: 35, step: 650/781, loss: 3.57059907913208\n",
      "Epoch: 35, step: 700/781, loss: 3.384608507156372\n",
      "Epoch: 35, step: 750/781, loss: 3.5819880962371826\n",
      "Epoch: 35 completed, average loss: 3.5525303836363378, time taken: 1.6233110904693604 mins\n",
      "Epoch: 36, step: 50/781, loss: 3.6381454467773438\n",
      "Epoch: 36, step: 100/781, loss: 3.610567092895508\n",
      "Epoch: 36, step: 150/781, loss: 3.6422243118286133\n",
      "Epoch: 36, step: 200/781, loss: 3.4361412525177\n",
      "Epoch: 36, step: 250/781, loss: 3.5649240016937256\n",
      "Epoch: 36, step: 300/781, loss: 3.540252685546875\n",
      "Epoch: 36, step: 350/781, loss: 3.4790713787078857\n",
      "Epoch: 36, step: 400/781, loss: 3.5971171855926514\n",
      "Epoch: 36, step: 450/781, loss: 3.596369981765747\n",
      "Epoch: 36, step: 500/781, loss: 3.6165831089019775\n",
      "Epoch: 36, step: 550/781, loss: 3.666278839111328\n",
      "Epoch: 36, step: 600/781, loss: 3.6006433963775635\n",
      "Epoch: 36, step: 650/781, loss: 3.723849296569824\n",
      "Epoch: 36, step: 700/781, loss: 3.569669246673584\n",
      "Epoch: 36, step: 750/781, loss: 3.560225009918213\n",
      "Epoch: 36 completed, average loss: 3.5470992535848778, time taken: 1.6322100599606832 mins\n",
      "Epoch: 37, step: 50/781, loss: 3.4533138275146484\n",
      "Epoch: 37, step: 100/781, loss: 3.632171392440796\n",
      "Epoch: 37, step: 150/781, loss: 3.6620099544525146\n",
      "Epoch: 37, step: 200/781, loss: 3.540849208831787\n",
      "Epoch: 37, step: 250/781, loss: 3.4937007427215576\n",
      "Epoch: 37, step: 300/781, loss: 3.509929895401001\n",
      "Epoch: 37, step: 350/781, loss: 3.5015149116516113\n",
      "Epoch: 37, step: 400/781, loss: 3.5861659049987793\n",
      "Epoch: 37, step: 450/781, loss: 3.5702548027038574\n",
      "Epoch: 37, step: 500/781, loss: 3.636920928955078\n",
      "Epoch: 37, step: 550/781, loss: 3.5753660202026367\n",
      "Epoch: 37, step: 600/781, loss: 3.504941940307617\n",
      "Epoch: 37, step: 650/781, loss: 3.500234365463257\n",
      "Epoch: 37, step: 700/781, loss: 3.59979248046875\n",
      "Epoch: 37, step: 750/781, loss: 3.506499767303467\n",
      "Epoch: 37 completed, average loss: 3.5445484052699596, time taken: 1.6328275124231975 mins\n",
      "Epoch: 38, step: 50/781, loss: 3.5180630683898926\n",
      "Epoch: 38, step: 100/781, loss: 3.5525310039520264\n",
      "Epoch: 38, step: 150/781, loss: 3.5356523990631104\n",
      "Epoch: 38, step: 200/781, loss: 3.699000597000122\n",
      "Epoch: 38, step: 250/781, loss: 3.514691114425659\n",
      "Epoch: 38, step: 300/781, loss: 3.433786630630493\n",
      "Epoch: 38, step: 350/781, loss: 3.519347667694092\n",
      "Epoch: 38, step: 400/781, loss: 3.574115514755249\n",
      "Epoch: 38, step: 450/781, loss: 3.5905895233154297\n",
      "Epoch: 38, step: 500/781, loss: 3.454777240753174\n",
      "Epoch: 38, step: 550/781, loss: 3.5617709159851074\n",
      "Epoch: 38, step: 600/781, loss: 3.5050711631774902\n",
      "Epoch: 38, step: 650/781, loss: 3.6164774894714355\n",
      "Epoch: 38, step: 700/781, loss: 3.474321126937866\n",
      "Epoch: 38, step: 750/781, loss: 3.5972328186035156\n",
      "Epoch: 38 completed, average loss: 3.5414841956579424, time taken: 1.6254415392875672 mins\n",
      "Epoch: 39, step: 50/781, loss: 3.491029739379883\n",
      "Epoch: 39, step: 100/781, loss: 3.5777688026428223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, step: 150/781, loss: 3.508216619491577\n",
      "Epoch: 39, step: 200/781, loss: 3.5048062801361084\n",
      "Epoch: 39, step: 250/781, loss: 3.4189510345458984\n",
      "Epoch: 39, step: 300/781, loss: 3.5974504947662354\n",
      "Epoch: 39, step: 350/781, loss: 3.5200397968292236\n",
      "Epoch: 39, step: 400/781, loss: 3.641164541244507\n",
      "Epoch: 39, step: 450/781, loss: 3.5425362586975098\n",
      "Epoch: 39, step: 500/781, loss: 3.606519937515259\n",
      "Epoch: 39, step: 550/781, loss: 3.498439311981201\n",
      "Epoch: 39, step: 600/781, loss: 3.6010937690734863\n",
      "Epoch: 39, step: 650/781, loss: 3.4463555812835693\n",
      "Epoch: 39, step: 700/781, loss: 3.5858640670776367\n",
      "Epoch: 39, step: 750/781, loss: 3.5559730529785156\n",
      "Epoch: 39 completed, average loss: 3.53909192500438, time taken: 1.626235270500183 mins\n",
      "Epoch: 40, step: 50/781, loss: 3.611755132675171\n",
      "Epoch: 40, step: 100/781, loss: 3.5558111667633057\n",
      "Epoch: 40, step: 150/781, loss: 3.5152924060821533\n",
      "Epoch: 40, step: 200/781, loss: 3.544358015060425\n",
      "Epoch: 40, step: 250/781, loss: 3.5935001373291016\n",
      "Epoch: 40, step: 300/781, loss: 3.6027300357818604\n",
      "Epoch: 40, step: 350/781, loss: 3.5436322689056396\n",
      "Epoch: 40, step: 400/781, loss: 3.554124593734741\n",
      "Epoch: 40, step: 450/781, loss: 3.559257745742798\n",
      "Epoch: 40, step: 500/781, loss: 3.538022041320801\n",
      "Epoch: 40, step: 550/781, loss: 3.4050164222717285\n",
      "Epoch: 40, step: 600/781, loss: 3.6301989555358887\n",
      "Epoch: 40, step: 650/781, loss: 3.497929811477661\n",
      "Epoch: 40, step: 700/781, loss: 3.5551304817199707\n",
      "Epoch: 40, step: 750/781, loss: 3.5161099433898926\n",
      "Epoch: 40 completed, average loss: 3.5322484182487224, time taken: 1.6343677560488383 mins\n",
      "Epoch: 41, step: 50/781, loss: 3.584449291229248\n",
      "Epoch: 41, step: 100/781, loss: 3.546703338623047\n",
      "Epoch: 41, step: 150/781, loss: 3.7195982933044434\n",
      "Epoch: 41, step: 200/781, loss: 3.5766193866729736\n",
      "Epoch: 41, step: 250/781, loss: 3.5820255279541016\n",
      "Epoch: 41, step: 300/781, loss: 3.5535824298858643\n",
      "Epoch: 41, step: 350/781, loss: 3.6542861461639404\n",
      "Epoch: 41, step: 400/781, loss: 3.5655035972595215\n",
      "Epoch: 41, step: 450/781, loss: 3.470564126968384\n",
      "Epoch: 41, step: 500/781, loss: 3.6435346603393555\n",
      "Epoch: 41, step: 550/781, loss: 3.5334737300872803\n",
      "Epoch: 41, step: 600/781, loss: 3.5587151050567627\n",
      "Epoch: 41, step: 650/781, loss: 3.53531813621521\n",
      "Epoch: 41, step: 700/781, loss: 3.521007776260376\n",
      "Epoch: 41, step: 750/781, loss: 3.5314977169036865\n",
      "Epoch: 41 completed, average loss: 3.529802735727972, time taken: 1.6411053856213889 mins\n",
      "Epoch: 42, step: 50/781, loss: 3.416609764099121\n",
      "Epoch: 42, step: 100/781, loss: 3.539064645767212\n",
      "Epoch: 42, step: 150/781, loss: 3.468386650085449\n",
      "Epoch: 42, step: 200/781, loss: 3.5708189010620117\n",
      "Epoch: 42, step: 250/781, loss: 3.55972957611084\n",
      "Epoch: 42, step: 300/781, loss: 3.5430071353912354\n",
      "Epoch: 42, step: 350/781, loss: 3.5596773624420166\n",
      "Epoch: 42, step: 400/781, loss: 3.50972318649292\n",
      "Epoch: 42, step: 450/781, loss: 3.518442392349243\n",
      "Epoch: 42, step: 500/781, loss: 3.460291624069214\n",
      "Epoch: 42, step: 550/781, loss: 3.467087745666504\n",
      "Epoch: 42, step: 600/781, loss: 3.441995859146118\n",
      "Epoch: 42, step: 650/781, loss: 3.5123367309570312\n",
      "Epoch: 42, step: 700/781, loss: 3.707298755645752\n",
      "Epoch: 42, step: 750/781, loss: 3.5036776065826416\n",
      "Epoch: 42 completed, average loss: 3.5248223694277483, time taken: 1.628319295247396 mins\n",
      "Epoch: 43, step: 50/781, loss: 3.486680269241333\n",
      "Epoch: 43, step: 100/781, loss: 3.5095314979553223\n",
      "Epoch: 43, step: 150/781, loss: 3.5692319869995117\n",
      "Epoch: 43, step: 200/781, loss: 3.5052003860473633\n",
      "Epoch: 43, step: 250/781, loss: 3.577369451522827\n",
      "Epoch: 43, step: 300/781, loss: 3.45805025100708\n",
      "Epoch: 43, step: 350/781, loss: 3.4901461601257324\n",
      "Epoch: 43, step: 400/781, loss: 3.6326775550842285\n",
      "Epoch: 43, step: 450/781, loss: 3.584261417388916\n",
      "Epoch: 43, step: 500/781, loss: 3.5254063606262207\n",
      "Epoch: 43, step: 550/781, loss: 3.445742130279541\n",
      "Epoch: 43, step: 600/781, loss: 3.6428494453430176\n",
      "Epoch: 43, step: 650/781, loss: 3.4869472980499268\n",
      "Epoch: 43, step: 700/781, loss: 3.48921537399292\n",
      "Epoch: 43, step: 750/781, loss: 3.4478156566619873\n",
      "Epoch: 43 completed, average loss: 3.5189097330603802, time taken: 1.621829128265381 mins\n",
      "Epoch: 44, step: 50/781, loss: 3.484018564224243\n",
      "Epoch: 44, step: 100/781, loss: 3.529465675354004\n",
      "Epoch: 44, step: 150/781, loss: 3.542149782180786\n",
      "Epoch: 44, step: 200/781, loss: 3.442152976989746\n",
      "Epoch: 44, step: 250/781, loss: 3.4718563556671143\n",
      "Epoch: 44, step: 300/781, loss: 3.465479850769043\n",
      "Epoch: 44, step: 350/781, loss: 3.4357335567474365\n",
      "Epoch: 44, step: 400/781, loss: 3.445448398590088\n",
      "Epoch: 44, step: 450/781, loss: 3.4280812740325928\n",
      "Epoch: 44, step: 500/781, loss: 3.5569875240325928\n",
      "Epoch: 44, step: 550/781, loss: 3.470710039138794\n",
      "Epoch: 44, step: 600/781, loss: 3.5516014099121094\n",
      "Epoch: 44, step: 650/781, loss: 3.5246803760528564\n",
      "Epoch: 44, step: 700/781, loss: 3.5360965728759766\n",
      "Epoch: 44, step: 750/781, loss: 3.480095386505127\n",
      "Epoch: 44 completed, average loss: 3.51577307625403, time taken: 1.6308592081069946 mins\n",
      "Epoch: 45, step: 50/781, loss: 3.396672487258911\n",
      "Epoch: 45, step: 100/781, loss: 3.441314220428467\n",
      "Epoch: 45, step: 150/781, loss: 3.5736944675445557\n",
      "Epoch: 45, step: 200/781, loss: 3.5105621814727783\n",
      "Epoch: 45, step: 250/781, loss: 3.5322084426879883\n",
      "Epoch: 45, step: 300/781, loss: 3.517767906188965\n",
      "Epoch: 45, step: 350/781, loss: 3.538681983947754\n",
      "Epoch: 45, step: 400/781, loss: 3.5713601112365723\n",
      "Epoch: 45, step: 450/781, loss: 3.4985241889953613\n",
      "Epoch: 45, step: 500/781, loss: 3.543659210205078\n",
      "Epoch: 45, step: 550/781, loss: 3.4686901569366455\n",
      "Epoch: 45, step: 600/781, loss: 3.5663225650787354\n",
      "Epoch: 45, step: 650/781, loss: 3.5166382789611816\n",
      "Epoch: 45, step: 700/781, loss: 3.4538626670837402\n",
      "Epoch: 45, step: 750/781, loss: 3.5140955448150635\n",
      "Epoch: 45 completed, average loss: 3.5148305138918867, time taken: 1.6295322020848593 mins\n",
      "Epoch: 46, step: 50/781, loss: 3.5884296894073486\n",
      "Epoch: 46, step: 100/781, loss: 3.556006669998169\n",
      "Epoch: 46, step: 150/781, loss: 3.5181078910827637\n",
      "Epoch: 46, step: 200/781, loss: 3.4671897888183594\n",
      "Epoch: 46, step: 250/781, loss: 3.5431525707244873\n",
      "Epoch: 46, step: 300/781, loss: 3.5366485118865967\n",
      "Epoch: 46, step: 350/781, loss: 3.4964189529418945\n",
      "Epoch: 46, step: 400/781, loss: 3.5192739963531494\n",
      "Epoch: 46, step: 450/781, loss: 3.4315388202667236\n",
      "Epoch: 46, step: 500/781, loss: 3.5372743606567383\n",
      "Epoch: 46, step: 550/781, loss: 3.4973104000091553\n",
      "Epoch: 46, step: 600/781, loss: 3.5536508560180664\n",
      "Epoch: 46, step: 650/781, loss: 3.5269758701324463\n",
      "Epoch: 46, step: 700/781, loss: 3.541203260421753\n",
      "Epoch: 46, step: 750/781, loss: 3.554292917251587\n",
      "Epoch: 46 completed, average loss: 3.511069091120389, time taken: 1.625900133450826 mins\n",
      "Epoch: 47, step: 50/781, loss: 3.43219256401062\n",
      "Epoch: 47, step: 100/781, loss: 3.52862811088562\n",
      "Epoch: 47, step: 150/781, loss: 3.396188497543335\n",
      "Epoch: 47, step: 200/781, loss: 3.3873801231384277\n",
      "Epoch: 47, step: 250/781, loss: 3.46144700050354\n",
      "Epoch: 47, step: 300/781, loss: 3.57902193069458\n",
      "Epoch: 47, step: 350/781, loss: 3.4876065254211426\n",
      "Epoch: 47, step: 400/781, loss: 3.491603136062622\n",
      "Epoch: 47, step: 450/781, loss: 3.5432534217834473\n",
      "Epoch: 47, step: 500/781, loss: 3.693986654281616\n",
      "Epoch: 47, step: 550/781, loss: 3.551396608352661\n",
      "Epoch: 47, step: 600/781, loss: 3.5008697509765625\n",
      "Epoch: 47, step: 650/781, loss: 3.4051098823547363\n",
      "Epoch: 47, step: 700/781, loss: 3.45589280128479\n",
      "Epoch: 47, step: 750/781, loss: 3.584000587463379\n",
      "Epoch: 47 completed, average loss: 3.5128803680556686, time taken: 1.6275392413139342 mins\n",
      "Epoch: 48, step: 50/781, loss: 3.5217795372009277\n",
      "Epoch: 48, step: 100/781, loss: 3.582578420639038\n",
      "Epoch: 48, step: 150/781, loss: 3.330681800842285\n",
      "Epoch: 48, step: 200/781, loss: 3.4729204177856445\n",
      "Epoch: 48, step: 250/781, loss: 3.4559528827667236\n",
      "Epoch: 48, step: 300/781, loss: 3.5661392211914062\n",
      "Epoch: 48, step: 350/781, loss: 3.5524415969848633\n",
      "Epoch: 48, step: 400/781, loss: 3.571408271789551\n",
      "Epoch: 48, step: 450/781, loss: 3.373812675476074\n",
      "Epoch: 48, step: 500/781, loss: 3.5769262313842773\n",
      "Epoch: 48, step: 550/781, loss: 3.589526653289795\n",
      "Epoch: 48, step: 600/781, loss: 3.562849998474121\n",
      "Epoch: 48, step: 650/781, loss: 3.4677131175994873\n",
      "Epoch: 48, step: 700/781, loss: 3.5176565647125244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, step: 750/781, loss: 3.527617931365967\n",
      "Epoch: 48 completed, average loss: 3.5039770169691606, time taken: 1.6293559153874715 mins\n",
      "Epoch: 49, step: 50/781, loss: 3.5792858600616455\n",
      "Epoch: 49, step: 100/781, loss: 3.40789532661438\n",
      "Epoch: 49, step: 150/781, loss: 3.5485033988952637\n",
      "Epoch: 49, step: 200/781, loss: 3.463099956512451\n",
      "Epoch: 49, step: 250/781, loss: 3.4878439903259277\n",
      "Epoch: 49, step: 300/781, loss: 3.5736305713653564\n",
      "Epoch: 49, step: 350/781, loss: 3.5363147258758545\n",
      "Epoch: 49, step: 400/781, loss: 3.437150001525879\n",
      "Epoch: 49, step: 450/781, loss: 3.577570915222168\n",
      "Epoch: 49, step: 500/781, loss: 3.498070001602173\n",
      "Epoch: 49, step: 550/781, loss: 3.5884389877319336\n",
      "Epoch: 49, step: 600/781, loss: 3.635612964630127\n",
      "Epoch: 49, step: 650/781, loss: 3.500009298324585\n",
      "Epoch: 49, step: 700/781, loss: 3.5379624366760254\n",
      "Epoch: 49, step: 750/781, loss: 3.435742139816284\n",
      "Epoch: 49 completed, average loss: 3.5051125304799684, time taken: 1.6310185511906943 mins\n",
      "Epoch: 50, step: 50/781, loss: 3.4855127334594727\n",
      "Epoch: 50, step: 100/781, loss: 3.5531013011932373\n",
      "Epoch: 50, step: 150/781, loss: 3.5839760303497314\n",
      "Epoch: 50, step: 200/781, loss: 3.4612205028533936\n",
      "Epoch: 50, step: 250/781, loss: 3.5128254890441895\n",
      "Epoch: 50, step: 300/781, loss: 3.5145647525787354\n",
      "Epoch: 50, step: 350/781, loss: 3.4850692749023438\n",
      "Epoch: 50, step: 400/781, loss: 3.5467329025268555\n",
      "Epoch: 50, step: 450/781, loss: 3.5263357162475586\n",
      "Epoch: 50, step: 500/781, loss: 3.489769458770752\n",
      "Epoch: 50, step: 550/781, loss: 3.5996925830841064\n",
      "Epoch: 50, step: 600/781, loss: 3.4591763019561768\n",
      "Epoch: 50, step: 650/781, loss: 3.4796571731567383\n",
      "Epoch: 50, step: 700/781, loss: 3.6003105640411377\n",
      "Epoch: 50, step: 750/781, loss: 3.5168755054473877\n",
      "Epoch: 50 completed, average loss: 3.5004046253297147, time taken: 1.6235007445017497 mins\n",
      "Epoch: 51, step: 50/781, loss: 3.5224802494049072\n",
      "Epoch: 51, step: 100/781, loss: 3.4672605991363525\n",
      "Epoch: 51, step: 150/781, loss: 3.4921209812164307\n",
      "Epoch: 51, step: 200/781, loss: 3.4984912872314453\n",
      "Epoch: 51, step: 250/781, loss: 3.5196938514709473\n",
      "Epoch: 51, step: 300/781, loss: 3.4819586277008057\n",
      "Epoch: 51, step: 350/781, loss: 3.4089250564575195\n",
      "Epoch: 51, step: 400/781, loss: 3.517333507537842\n",
      "Epoch: 51, step: 450/781, loss: 3.4394490718841553\n",
      "Epoch: 51, step: 500/781, loss: 3.520712375640869\n",
      "Epoch: 51, step: 550/781, loss: 3.530164957046509\n",
      "Epoch: 51, step: 600/781, loss: 3.42885684967041\n",
      "Epoch: 51, step: 650/781, loss: 3.507564067840576\n",
      "Epoch: 51, step: 700/781, loss: 3.4141554832458496\n",
      "Epoch: 51, step: 750/781, loss: 3.458061933517456\n",
      "Epoch: 51 completed, average loss: 3.497874969404272, time taken: 1.6246960361798604 mins\n",
      "Epoch: 52, step: 50/781, loss: 3.430617332458496\n",
      "Epoch: 52, step: 100/781, loss: 3.555619716644287\n",
      "Epoch: 52, step: 150/781, loss: 3.467845916748047\n",
      "Epoch: 52, step: 200/781, loss: 3.499737024307251\n",
      "Epoch: 52, step: 250/781, loss: 3.4229209423065186\n",
      "Epoch: 52, step: 300/781, loss: 3.4286370277404785\n",
      "Epoch: 52, step: 350/781, loss: 3.515817403793335\n",
      "Epoch: 52, step: 400/781, loss: 3.4716975688934326\n",
      "Epoch: 52, step: 450/781, loss: 3.463848829269409\n",
      "Epoch: 52, step: 500/781, loss: 3.45285964012146\n",
      "Epoch: 52, step: 550/781, loss: 3.3894238471984863\n",
      "Epoch: 52, step: 600/781, loss: 3.511441946029663\n",
      "Epoch: 52, step: 650/781, loss: 3.483873128890991\n",
      "Epoch: 52, step: 700/781, loss: 3.4495840072631836\n",
      "Epoch: 52, step: 750/781, loss: 3.4082443714141846\n",
      "Epoch: 52 completed, average loss: 3.4959805252915306, time taken: 1.6343396464983622 mins\n",
      "Epoch: 53, step: 50/781, loss: 3.5533246994018555\n",
      "Epoch: 53, step: 100/781, loss: 3.455556631088257\n",
      "Epoch: 53, step: 150/781, loss: 3.5234131813049316\n",
      "Epoch: 53, step: 200/781, loss: 3.535670042037964\n",
      "Epoch: 53, step: 250/781, loss: 3.5008625984191895\n",
      "Epoch: 53, step: 300/781, loss: 3.4864039421081543\n",
      "Epoch: 53, step: 350/781, loss: 3.4406237602233887\n",
      "Epoch: 53, step: 400/781, loss: 3.4737820625305176\n",
      "Epoch: 53, step: 450/781, loss: 3.4538516998291016\n",
      "Epoch: 53, step: 500/781, loss: 3.4782097339630127\n",
      "Epoch: 53, step: 550/781, loss: 3.5294089317321777\n",
      "Epoch: 53, step: 600/781, loss: 3.5391674041748047\n",
      "Epoch: 53, step: 650/781, loss: 3.4487955570220947\n",
      "Epoch: 53, step: 700/781, loss: 3.5118324756622314\n",
      "Epoch: 53, step: 750/781, loss: 3.446505069732666\n",
      "Epoch: 53 completed, average loss: 3.493835198283959, time taken: 1.6269184509913126 mins\n",
      "Epoch: 54, step: 50/781, loss: 3.44101619720459\n",
      "Epoch: 54, step: 100/781, loss: 3.4346797466278076\n",
      "Epoch: 54, step: 150/781, loss: 3.4402058124542236\n",
      "Epoch: 54, step: 200/781, loss: 3.6645400524139404\n",
      "Epoch: 54, step: 250/781, loss: 3.424910545349121\n",
      "Epoch: 54, step: 300/781, loss: 3.516749143600464\n",
      "Epoch: 54, step: 350/781, loss: 3.5116891860961914\n",
      "Epoch: 54, step: 400/781, loss: 3.5044403076171875\n",
      "Epoch: 54, step: 450/781, loss: 3.5066440105438232\n",
      "Epoch: 54, step: 500/781, loss: 3.4308695793151855\n",
      "Epoch: 54, step: 550/781, loss: 3.5344972610473633\n",
      "Epoch: 54, step: 600/781, loss: 3.5736372470855713\n",
      "Epoch: 54, step: 650/781, loss: 3.502169609069824\n",
      "Epoch: 54, step: 700/781, loss: 3.4982705116271973\n",
      "Epoch: 54, step: 750/781, loss: 3.520465850830078\n",
      "Epoch: 54 completed, average loss: 3.490049990435416, time taken: 1.6328426162401835 mins\n",
      "Epoch: 55, step: 50/781, loss: 3.4322659969329834\n",
      "Epoch: 55, step: 100/781, loss: 3.478289842605591\n",
      "Epoch: 55, step: 150/781, loss: 3.4431018829345703\n",
      "Epoch: 55, step: 200/781, loss: 3.4135053157806396\n",
      "Epoch: 55, step: 250/781, loss: 3.52005672454834\n",
      "Epoch: 55, step: 300/781, loss: 3.502993583679199\n",
      "Epoch: 55, step: 350/781, loss: 3.4189062118530273\n",
      "Epoch: 55, step: 400/781, loss: 3.56503963470459\n",
      "Epoch: 55, step: 450/781, loss: 3.445607900619507\n",
      "Epoch: 55, step: 500/781, loss: 3.4252700805664062\n",
      "Epoch: 55, step: 550/781, loss: 3.482283592224121\n",
      "Epoch: 55, step: 600/781, loss: 3.396895170211792\n",
      "Epoch: 55, step: 650/781, loss: 3.4640274047851562\n",
      "Epoch: 55, step: 700/781, loss: 3.487428665161133\n",
      "Epoch: 55, step: 750/781, loss: 3.5148823261260986\n",
      "Epoch: 55 completed, average loss: 3.492969563614849, time taken: 1.6292779684066772 mins\n",
      "Epoch: 56, step: 50/781, loss: 3.4349818229675293\n",
      "Epoch: 56, step: 100/781, loss: 3.542746067047119\n",
      "Epoch: 56, step: 150/781, loss: 3.4063165187835693\n",
      "Epoch: 56, step: 200/781, loss: 3.498136043548584\n",
      "Epoch: 56, step: 250/781, loss: 3.5484838485717773\n",
      "Epoch: 56, step: 300/781, loss: 3.420503616333008\n",
      "Epoch: 56, step: 350/781, loss: 3.541076183319092\n",
      "Epoch: 56, step: 400/781, loss: 3.56150221824646\n",
      "Epoch: 56, step: 450/781, loss: 3.540121078491211\n",
      "Epoch: 56, step: 500/781, loss: 3.4847919940948486\n",
      "Epoch: 56, step: 550/781, loss: 3.58921217918396\n",
      "Epoch: 56, step: 600/781, loss: 3.428966760635376\n",
      "Epoch: 56, step: 650/781, loss: 3.3727171421051025\n",
      "Epoch: 56, step: 700/781, loss: 3.482954502105713\n",
      "Epoch: 56, step: 750/781, loss: 3.592313051223755\n",
      "Epoch: 56 completed, average loss: 3.4837336598224127, time taken: 1.6335406661033631 mins\n",
      "Epoch: 57, step: 50/781, loss: 3.477144241333008\n",
      "Epoch: 57, step: 100/781, loss: 3.489983081817627\n",
      "Epoch: 57, step: 150/781, loss: 3.5777385234832764\n",
      "Epoch: 57, step: 200/781, loss: 3.3941237926483154\n",
      "Epoch: 57, step: 250/781, loss: 3.492555618286133\n",
      "Epoch: 57, step: 300/781, loss: 3.4361519813537598\n",
      "Epoch: 57, step: 350/781, loss: 3.531665086746216\n",
      "Epoch: 57, step: 400/781, loss: 3.4730210304260254\n",
      "Epoch: 57, step: 450/781, loss: 3.428532838821411\n",
      "Epoch: 57, step: 500/781, loss: 3.5819993019104004\n",
      "Epoch: 57, step: 550/781, loss: 3.4715402126312256\n",
      "Epoch: 57, step: 600/781, loss: 3.436025619506836\n",
      "Epoch: 57, step: 650/781, loss: 3.4699997901916504\n",
      "Epoch: 57, step: 700/781, loss: 3.4150824546813965\n",
      "Epoch: 57, step: 750/781, loss: 3.52315354347229\n",
      "Epoch: 57 completed, average loss: 3.487655434199393, time taken: 1.6293194572130838 mins\n",
      "Epoch: 58, step: 50/781, loss: 3.4313466548919678\n",
      "Epoch: 58, step: 100/781, loss: 3.5016870498657227\n",
      "Epoch: 58, step: 150/781, loss: 3.52986741065979\n",
      "Epoch: 58, step: 200/781, loss: 3.463834762573242\n",
      "Epoch: 58, step: 250/781, loss: 3.469827175140381\n",
      "Epoch: 58, step: 300/781, loss: 3.4873111248016357\n",
      "Epoch: 58, step: 350/781, loss: 3.4351298809051514\n",
      "Epoch: 58, step: 400/781, loss: 3.42207407951355\n",
      "Epoch: 58, step: 450/781, loss: 3.431570053100586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58, step: 500/781, loss: 3.550842523574829\n",
      "Epoch: 58, step: 550/781, loss: 3.5424160957336426\n",
      "Epoch: 58, step: 600/781, loss: 3.443429470062256\n",
      "Epoch: 58, step: 650/781, loss: 3.480482816696167\n",
      "Epoch: 58, step: 700/781, loss: 3.516592264175415\n",
      "Epoch: 58, step: 750/781, loss: 3.472177505493164\n",
      "Epoch: 58 completed, average loss: 3.4797872858987726, time taken: 1.629375688234965 mins\n",
      "Epoch: 59, step: 50/781, loss: 3.4332964420318604\n",
      "Epoch: 59, step: 100/781, loss: 3.430696964263916\n",
      "Epoch: 59, step: 150/781, loss: 3.455801486968994\n",
      "Epoch: 59, step: 200/781, loss: 3.5442001819610596\n",
      "Epoch: 59, step: 250/781, loss: 3.494394063949585\n",
      "Epoch: 59, step: 300/781, loss: 3.4143731594085693\n",
      "Epoch: 59, step: 350/781, loss: 3.4153029918670654\n",
      "Epoch: 59, step: 400/781, loss: 3.5022456645965576\n",
      "Epoch: 59, step: 450/781, loss: 3.4542932510375977\n",
      "Epoch: 59, step: 500/781, loss: 3.446009874343872\n",
      "Epoch: 59, step: 550/781, loss: 3.4842898845672607\n",
      "Epoch: 59, step: 600/781, loss: 3.4535746574401855\n",
      "Epoch: 59, step: 650/781, loss: 3.4080240726470947\n",
      "Epoch: 59, step: 700/781, loss: 3.5789175033569336\n",
      "Epoch: 59, step: 750/781, loss: 3.434321403503418\n",
      "Epoch: 59 completed, average loss: 3.479589667118771, time taken: 1.6286078373591104 mins\n",
      "Epoch: 60, step: 50/781, loss: 3.4184823036193848\n",
      "Epoch: 60, step: 100/781, loss: 3.442625045776367\n",
      "Epoch: 60, step: 150/781, loss: 3.5118675231933594\n",
      "Epoch: 60, step: 200/781, loss: 3.572847604751587\n",
      "Epoch: 60, step: 250/781, loss: 3.4086647033691406\n",
      "Epoch: 60, step: 300/781, loss: 3.359445095062256\n",
      "Epoch: 60, step: 350/781, loss: 3.575695037841797\n",
      "Epoch: 60, step: 400/781, loss: 3.5278985500335693\n",
      "Epoch: 60, step: 450/781, loss: 3.503695249557495\n",
      "Epoch: 60, step: 500/781, loss: 3.4890193939208984\n",
      "Epoch: 60, step: 550/781, loss: 3.589456558227539\n",
      "Epoch: 60, step: 600/781, loss: 3.514143466949463\n",
      "Epoch: 60, step: 650/781, loss: 3.415158748626709\n",
      "Epoch: 60, step: 700/781, loss: 3.4309005737304688\n",
      "Epoch: 60, step: 750/781, loss: 3.43445086479187\n",
      "Epoch: 60 completed, average loss: 3.4795200110397633, time taken: 1.6309456666310629 mins\n",
      "Epoch: 61, step: 50/781, loss: 3.465439558029175\n",
      "Epoch: 61, step: 100/781, loss: 3.5070419311523438\n",
      "Epoch: 61, step: 150/781, loss: 3.497037410736084\n",
      "Epoch: 61, step: 200/781, loss: 3.4716832637786865\n",
      "Epoch: 61, step: 250/781, loss: 3.4463586807250977\n",
      "Epoch: 61, step: 300/781, loss: 3.4460620880126953\n",
      "Epoch: 61, step: 350/781, loss: 3.504772186279297\n",
      "Epoch: 61, step: 400/781, loss: 3.5202019214630127\n",
      "Epoch: 61, step: 450/781, loss: 3.484194755554199\n",
      "Epoch: 61, step: 500/781, loss: 3.576758623123169\n",
      "Epoch: 61, step: 550/781, loss: 3.4994494915008545\n",
      "Epoch: 61, step: 600/781, loss: 3.5521669387817383\n",
      "Epoch: 61, step: 650/781, loss: 3.496121406555176\n",
      "Epoch: 61, step: 700/781, loss: 3.394680976867676\n",
      "Epoch: 61, step: 750/781, loss: 3.4827094078063965\n",
      "Epoch: 61 completed, average loss: 3.475275920386809, time taken: 1.6394335627555847 mins\n",
      "Epoch: 62, step: 50/781, loss: 3.4102282524108887\n",
      "Epoch: 62, step: 100/781, loss: 3.500532388687134\n",
      "Epoch: 62, step: 150/781, loss: 3.412199020385742\n",
      "Epoch: 62, step: 200/781, loss: 3.353074312210083\n",
      "Epoch: 62, step: 250/781, loss: 3.4187963008880615\n",
      "Epoch: 62, step: 300/781, loss: 3.441840648651123\n",
      "Epoch: 62, step: 350/781, loss: 3.5499770641326904\n",
      "Epoch: 62, step: 400/781, loss: 3.4116244316101074\n",
      "Epoch: 62, step: 450/781, loss: 3.463022232055664\n",
      "Epoch: 62, step: 500/781, loss: 3.4303383827209473\n",
      "Epoch: 62, step: 550/781, loss: 3.4063827991485596\n",
      "Epoch: 62, step: 600/781, loss: 3.3950917720794678\n",
      "Epoch: 62, step: 650/781, loss: 3.4170451164245605\n",
      "Epoch: 62, step: 700/781, loss: 3.507009983062744\n",
      "Epoch: 62, step: 750/781, loss: 3.477010726928711\n",
      "Epoch: 62 completed, average loss: 3.4759446939646663, time taken: 1.6335074305534363 mins\n",
      "Epoch: 63, step: 50/781, loss: 3.4850261211395264\n",
      "Epoch: 63, step: 100/781, loss: 3.411491870880127\n",
      "Epoch: 63, step: 150/781, loss: 3.5173542499542236\n",
      "Epoch: 63, step: 200/781, loss: 3.51987361907959\n",
      "Epoch: 63, step: 250/781, loss: 3.478926420211792\n",
      "Epoch: 63, step: 300/781, loss: 3.5406277179718018\n",
      "Epoch: 63, step: 350/781, loss: 3.433687686920166\n",
      "Epoch: 63, step: 400/781, loss: 3.468409538269043\n",
      "Epoch: 63, step: 450/781, loss: 3.531052350997925\n",
      "Epoch: 63, step: 500/781, loss: 3.5034778118133545\n",
      "Epoch: 63, step: 550/781, loss: 3.4925293922424316\n",
      "Epoch: 63, step: 600/781, loss: 3.528596878051758\n",
      "Epoch: 63, step: 650/781, loss: 3.4899826049804688\n",
      "Epoch: 63, step: 700/781, loss: 3.479583978652954\n",
      "Epoch: 63, step: 750/781, loss: 3.3710503578186035\n",
      "Epoch: 63 completed, average loss: 3.4754661066736667, time taken: 1.6306685129801433 mins\n",
      "Epoch: 64, step: 50/781, loss: 3.4708096981048584\n",
      "Epoch: 64, step: 100/781, loss: 3.490229368209839\n",
      "Epoch: 64, step: 150/781, loss: 3.460550308227539\n",
      "Epoch: 64, step: 200/781, loss: 3.4172866344451904\n",
      "Epoch: 64, step: 250/781, loss: 3.4867262840270996\n",
      "Epoch: 64, step: 300/781, loss: 3.430819272994995\n",
      "Epoch: 64, step: 350/781, loss: 3.4845409393310547\n",
      "Epoch: 64, step: 400/781, loss: 3.476780414581299\n",
      "Epoch: 64, step: 450/781, loss: 3.471688747406006\n",
      "Epoch: 64, step: 500/781, loss: 3.5865988731384277\n",
      "Epoch: 64, step: 550/781, loss: 3.4693992137908936\n",
      "Epoch: 64, step: 600/781, loss: 3.571723699569702\n",
      "Epoch: 64, step: 650/781, loss: 3.4688282012939453\n",
      "Epoch: 64, step: 700/781, loss: 3.3730430603027344\n",
      "Epoch: 64, step: 750/781, loss: 3.549471378326416\n",
      "Epoch: 64 completed, average loss: 3.472055345124991, time taken: 1.6285120328267415 mins\n",
      "Epoch: 65, step: 50/781, loss: 3.4206936359405518\n",
      "Epoch: 65, step: 100/781, loss: 3.4275317192077637\n",
      "Epoch: 65, step: 150/781, loss: 3.4793784618377686\n",
      "Epoch: 65, step: 200/781, loss: 3.532759189605713\n",
      "Epoch: 65, step: 250/781, loss: 3.582509756088257\n",
      "Epoch: 65, step: 300/781, loss: 3.5249879360198975\n",
      "Epoch: 65, step: 350/781, loss: 3.528662919998169\n",
      "Epoch: 65, step: 400/781, loss: 3.402897596359253\n",
      "Epoch: 65, step: 450/781, loss: 3.50549578666687\n",
      "Epoch: 65, step: 500/781, loss: 3.423656940460205\n",
      "Epoch: 65, step: 550/781, loss: 3.5275888442993164\n",
      "Epoch: 65, step: 600/781, loss: 3.5013062953948975\n",
      "Epoch: 65, step: 650/781, loss: 3.5853965282440186\n",
      "Epoch: 65, step: 700/781, loss: 3.473212957382202\n",
      "Epoch: 65, step: 750/781, loss: 3.557039260864258\n",
      "Epoch: 65 completed, average loss: 3.4688549087539067, time taken: 1.621982498963674 mins\n",
      "Epoch: 66, step: 50/781, loss: 3.488088607788086\n",
      "Epoch: 66, step: 100/781, loss: 3.4499800205230713\n",
      "Epoch: 66, step: 150/781, loss: 3.4489707946777344\n",
      "Epoch: 66, step: 200/781, loss: 3.5463216304779053\n",
      "Epoch: 66, step: 250/781, loss: 3.4562621116638184\n",
      "Epoch: 66, step: 300/781, loss: 3.4498019218444824\n",
      "Epoch: 66, step: 350/781, loss: 3.514315605163574\n",
      "Epoch: 66, step: 400/781, loss: 3.48038911819458\n",
      "Epoch: 66, step: 450/781, loss: 3.424105644226074\n",
      "Epoch: 66, step: 500/781, loss: 3.479015827178955\n",
      "Epoch: 66, step: 550/781, loss: 3.4534685611724854\n",
      "Epoch: 66, step: 600/781, loss: 3.559539794921875\n",
      "Epoch: 66, step: 650/781, loss: 3.416001319885254\n",
      "Epoch: 66, step: 700/781, loss: 3.4851722717285156\n",
      "Epoch: 66, step: 750/781, loss: 3.576625108718872\n",
      "Epoch: 66 completed, average loss: 3.466964107774742, time taken: 1.6278056462605794 mins\n",
      "Epoch: 67, step: 50/781, loss: 3.3488478660583496\n",
      "Epoch: 67, step: 100/781, loss: 3.535323143005371\n",
      "Epoch: 67, step: 150/781, loss: 3.4210755825042725\n",
      "Epoch: 67, step: 200/781, loss: 3.4966440200805664\n",
      "Epoch: 67, step: 250/781, loss: 3.4796788692474365\n",
      "Epoch: 67, step: 300/781, loss: 3.4663138389587402\n",
      "Epoch: 67, step: 350/781, loss: 3.5517334938049316\n",
      "Epoch: 67, step: 400/781, loss: 3.3766613006591797\n",
      "Epoch: 67, step: 450/781, loss: 3.4661407470703125\n",
      "Epoch: 67, step: 500/781, loss: 3.6091489791870117\n",
      "Epoch: 67, step: 550/781, loss: 3.3860464096069336\n",
      "Epoch: 67, step: 600/781, loss: 3.4088761806488037\n",
      "Epoch: 67, step: 650/781, loss: 3.3954858779907227\n",
      "Epoch: 67, step: 700/781, loss: 3.5228309631347656\n",
      "Epoch: 67, step: 750/781, loss: 3.4169013500213623\n",
      "Epoch: 67 completed, average loss: 3.463865707839497, time taken: 1.6312782486279807 mins\n",
      "Epoch: 68, step: 50/781, loss: 3.4811301231384277\n",
      "Epoch: 68, step: 100/781, loss: 3.4853880405426025\n",
      "Epoch: 68, step: 150/781, loss: 3.378303289413452\n",
      "Epoch: 68, step: 200/781, loss: 3.484076738357544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68, step: 250/781, loss: 3.4922683238983154\n",
      "Epoch: 68, step: 300/781, loss: 3.4107649326324463\n",
      "Epoch: 68, step: 350/781, loss: 3.447054624557495\n",
      "Epoch: 68, step: 400/781, loss: 3.4905757904052734\n",
      "Epoch: 68, step: 450/781, loss: 3.4607625007629395\n",
      "Epoch: 68, step: 500/781, loss: 3.472114324569702\n",
      "Epoch: 68, step: 550/781, loss: 3.526176691055298\n",
      "Epoch: 68, step: 600/781, loss: 3.4448561668395996\n",
      "Epoch: 68, step: 650/781, loss: 3.518089771270752\n",
      "Epoch: 68, step: 700/781, loss: 3.390256881713867\n",
      "Epoch: 68, step: 750/781, loss: 3.4440219402313232\n",
      "Epoch: 68 completed, average loss: 3.4617551664384165, time taken: 1.6344812750816344 mins\n",
      "Epoch: 69, step: 50/781, loss: 3.4971659183502197\n",
      "Epoch: 69, step: 100/781, loss: 3.4616260528564453\n",
      "Epoch: 69, step: 150/781, loss: 3.4430277347564697\n",
      "Epoch: 69, step: 200/781, loss: 3.553318500518799\n",
      "Epoch: 69, step: 250/781, loss: 3.4495716094970703\n",
      "Epoch: 69, step: 300/781, loss: 3.347374677658081\n",
      "Epoch: 69, step: 350/781, loss: 3.400378942489624\n",
      "Epoch: 69, step: 400/781, loss: 3.4022092819213867\n",
      "Epoch: 69, step: 450/781, loss: 3.4861903190612793\n",
      "Epoch: 69, step: 500/781, loss: 3.4503567218780518\n",
      "Epoch: 69, step: 550/781, loss: 3.5758469104766846\n",
      "Epoch: 69, step: 600/781, loss: 3.4763102531433105\n",
      "Epoch: 69, step: 650/781, loss: 3.4395244121551514\n",
      "Epoch: 69, step: 700/781, loss: 3.5259804725646973\n",
      "Epoch: 69, step: 750/781, loss: 3.47001051902771\n",
      "Epoch: 69 completed, average loss: 3.4636631274498075, time taken: 1.6256361961364747 mins\n",
      "Epoch: 70, step: 50/781, loss: 3.4007577896118164\n",
      "Epoch: 70, step: 100/781, loss: 3.363873243331909\n",
      "Epoch: 70, step: 150/781, loss: 3.552107810974121\n",
      "Epoch: 70, step: 200/781, loss: 3.424595594406128\n",
      "Epoch: 70, step: 250/781, loss: 3.4092841148376465\n",
      "Epoch: 70, step: 300/781, loss: 3.445984363555908\n",
      "Epoch: 70, step: 350/781, loss: 3.39345121383667\n",
      "Epoch: 70, step: 400/781, loss: 3.4108285903930664\n",
      "Epoch: 70, step: 450/781, loss: 3.4337897300720215\n",
      "Epoch: 70, step: 500/781, loss: 3.4574387073516846\n",
      "Epoch: 70, step: 550/781, loss: 3.4768362045288086\n",
      "Epoch: 70, step: 600/781, loss: 3.387016534805298\n",
      "Epoch: 70, step: 650/781, loss: 3.467228651046753\n",
      "Epoch: 70, step: 700/781, loss: 3.509140729904175\n",
      "Epoch: 70, step: 750/781, loss: 3.406785726547241\n",
      "Epoch: 70 completed, average loss: 3.4561527599598474, time taken: 1.6258871277173361 mins\n",
      "Epoch: 71, step: 50/781, loss: 3.402843952178955\n",
      "Epoch: 71, step: 100/781, loss: 3.492556095123291\n",
      "Epoch: 71, step: 150/781, loss: 3.320678234100342\n",
      "Epoch: 71, step: 200/781, loss: 3.5082991123199463\n",
      "Epoch: 71, step: 250/781, loss: 3.4382917881011963\n",
      "Epoch: 71, step: 300/781, loss: 3.5168066024780273\n",
      "Epoch: 71, step: 350/781, loss: 3.4660377502441406\n",
      "Epoch: 71, step: 400/781, loss: 3.4198555946350098\n",
      "Epoch: 71, step: 450/781, loss: 3.4410762786865234\n",
      "Epoch: 71, step: 500/781, loss: 3.396541118621826\n",
      "Epoch: 71, step: 550/781, loss: 3.4716038703918457\n",
      "Epoch: 71, step: 600/781, loss: 3.482163667678833\n",
      "Epoch: 71, step: 650/781, loss: 3.508551836013794\n",
      "Epoch: 71, step: 700/781, loss: 3.513915538787842\n",
      "Epoch: 71, step: 750/781, loss: 3.5797677040100098\n",
      "Epoch: 71 completed, average loss: 3.4616686217152965, time taken: 1.6319480299949647 mins\n",
      "Epoch: 72, step: 50/781, loss: 3.5181503295898438\n",
      "Epoch: 72, step: 100/781, loss: 3.514124631881714\n",
      "Epoch: 72, step: 150/781, loss: 3.502288579940796\n",
      "Epoch: 72, step: 200/781, loss: 3.4239587783813477\n",
      "Epoch: 72, step: 250/781, loss: 3.4136409759521484\n",
      "Epoch: 72, step: 300/781, loss: 3.5212910175323486\n",
      "Epoch: 72, step: 350/781, loss: 3.4921300411224365\n",
      "Epoch: 72, step: 400/781, loss: 3.4712796211242676\n",
      "Epoch: 72, step: 450/781, loss: 3.4191012382507324\n",
      "Epoch: 72, step: 500/781, loss: 3.424417495727539\n",
      "Epoch: 72, step: 550/781, loss: 3.483665704727173\n",
      "Epoch: 72, step: 600/781, loss: 3.318202495574951\n",
      "Epoch: 72, step: 650/781, loss: 3.474198579788208\n",
      "Epoch: 72, step: 700/781, loss: 3.482717990875244\n",
      "Epoch: 72, step: 750/781, loss: 3.5610764026641846\n",
      "Epoch: 72 completed, average loss: 3.459979602530427, time taken: 1.6280704379081725 mins\n",
      "Epoch: 73, step: 50/781, loss: 3.3844411373138428\n",
      "Epoch: 73, step: 100/781, loss: 3.527231454849243\n",
      "Epoch: 73, step: 150/781, loss: 3.471134901046753\n",
      "Epoch: 73, step: 200/781, loss: 3.414774179458618\n",
      "Epoch: 73, step: 250/781, loss: 3.3921849727630615\n",
      "Epoch: 73, step: 300/781, loss: 3.455737829208374\n",
      "Epoch: 73, step: 350/781, loss: 3.5127975940704346\n",
      "Epoch: 73, step: 400/781, loss: 3.413269519805908\n",
      "Epoch: 73, step: 450/781, loss: 3.4714717864990234\n",
      "Epoch: 73, step: 500/781, loss: 3.4999496936798096\n",
      "Epoch: 73, step: 550/781, loss: 3.431039571762085\n",
      "Epoch: 73, step: 600/781, loss: 3.4964749813079834\n",
      "Epoch: 73, step: 650/781, loss: 3.5526134967803955\n",
      "Epoch: 73, step: 700/781, loss: 3.417733669281006\n",
      "Epoch: 73, step: 750/781, loss: 3.4277329444885254\n",
      "Epoch: 73 completed, average loss: 3.456070025354891, time taken: 1.6302457094192504 mins\n",
      "Epoch: 74, step: 50/781, loss: 3.3707048892974854\n",
      "Epoch: 74, step: 100/781, loss: 3.476928234100342\n",
      "Epoch: 74, step: 150/781, loss: 3.438556432723999\n",
      "Epoch: 74, step: 200/781, loss: 3.4702553749084473\n",
      "Epoch: 74, step: 250/781, loss: 3.48026442527771\n",
      "Epoch: 74, step: 300/781, loss: 3.429619073867798\n",
      "Epoch: 74, step: 350/781, loss: 3.454529047012329\n",
      "Epoch: 74, step: 400/781, loss: 3.455702543258667\n",
      "Epoch: 74, step: 450/781, loss: 3.406280994415283\n",
      "Epoch: 74, step: 500/781, loss: 3.4356818199157715\n",
      "Epoch: 74, step: 550/781, loss: 3.3894758224487305\n",
      "Epoch: 74, step: 600/781, loss: 3.4344139099121094\n",
      "Epoch: 74, step: 650/781, loss: 3.348161220550537\n",
      "Epoch: 74, step: 700/781, loss: 3.5870680809020996\n",
      "Epoch: 74, step: 750/781, loss: 3.4163992404937744\n",
      "Epoch: 74 completed, average loss: 3.45366337540513, time taken: 1.6246110399564107 mins\n",
      "Epoch: 75, step: 50/781, loss: 3.4730825424194336\n",
      "Epoch: 75, step: 100/781, loss: 3.385247230529785\n",
      "Epoch: 75, step: 150/781, loss: 3.5075316429138184\n",
      "Epoch: 75, step: 200/781, loss: 3.461639881134033\n",
      "Epoch: 75, step: 250/781, loss: 3.4527759552001953\n",
      "Epoch: 75, step: 300/781, loss: 3.4493637084960938\n",
      "Epoch: 75, step: 350/781, loss: 3.4846770763397217\n",
      "Epoch: 75, step: 400/781, loss: 3.4288086891174316\n",
      "Epoch: 75, step: 450/781, loss: 3.5077407360076904\n",
      "Epoch: 75, step: 500/781, loss: 3.484248161315918\n",
      "Epoch: 75, step: 550/781, loss: 3.4760708808898926\n",
      "Epoch: 75, step: 600/781, loss: 3.3941898345947266\n",
      "Epoch: 75, step: 650/781, loss: 3.579688549041748\n",
      "Epoch: 75, step: 700/781, loss: 3.4321343898773193\n",
      "Epoch: 75, step: 750/781, loss: 3.4095277786254883\n",
      "Epoch: 75 completed, average loss: 3.455041804173234, time taken: 1.6328145265579224 mins\n",
      "Epoch: 76, step: 50/781, loss: 3.485396146774292\n",
      "Epoch: 76, step: 100/781, loss: 3.474217176437378\n",
      "Epoch: 76, step: 150/781, loss: 3.5413637161254883\n",
      "Epoch: 76, step: 200/781, loss: 3.4550440311431885\n",
      "Epoch: 76, step: 250/781, loss: 3.4265239238739014\n",
      "Epoch: 76, step: 300/781, loss: 3.4217584133148193\n",
      "Epoch: 76, step: 350/781, loss: 3.520979166030884\n",
      "Epoch: 76, step: 400/781, loss: 3.4323534965515137\n",
      "Epoch: 76, step: 450/781, loss: 3.6272714138031006\n",
      "Epoch: 76, step: 500/781, loss: 3.4322311878204346\n",
      "Epoch: 76, step: 550/781, loss: 3.4363906383514404\n",
      "Epoch: 76, step: 600/781, loss: 3.5277795791625977\n",
      "Epoch: 76, step: 650/781, loss: 3.503044605255127\n",
      "Epoch: 76, step: 700/781, loss: 3.456622362136841\n",
      "Epoch: 76, step: 750/781, loss: 3.419100284576416\n",
      "Epoch: 76 completed, average loss: 3.4506976158762406, time taken: 1.633203375339508 mins\n",
      "Epoch: 77, step: 50/781, loss: 3.434976100921631\n",
      "Epoch: 77, step: 100/781, loss: 3.523206949234009\n",
      "Epoch: 77, step: 150/781, loss: 3.4630467891693115\n",
      "Epoch: 77, step: 200/781, loss: 3.529444932937622\n",
      "Epoch: 77, step: 250/781, loss: 3.446672201156616\n",
      "Epoch: 77, step: 300/781, loss: 3.3813843727111816\n",
      "Epoch: 77, step: 350/781, loss: 3.419461965560913\n",
      "Epoch: 77, step: 400/781, loss: 3.4592201709747314\n",
      "Epoch: 77, step: 450/781, loss: 3.5491280555725098\n",
      "Epoch: 77, step: 500/781, loss: 3.4974172115325928\n",
      "Epoch: 77, step: 550/781, loss: 3.521996259689331\n",
      "Epoch: 77, step: 600/781, loss: 3.454517364501953\n",
      "Epoch: 77, step: 650/781, loss: 3.4548187255859375\n",
      "Epoch: 77, step: 700/781, loss: 3.457059144973755\n",
      "Epoch: 77, step: 750/781, loss: 3.437678575515747\n",
      "Epoch: 77 completed, average loss: 3.450845816071299, time taken: 1.6281760732332866 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78, step: 50/781, loss: 3.489264726638794\n",
      "Epoch: 78, step: 100/781, loss: 3.3709633350372314\n",
      "Epoch: 78, step: 150/781, loss: 3.5069878101348877\n",
      "Epoch: 78, step: 200/781, loss: 3.510300636291504\n",
      "Epoch: 78, step: 250/781, loss: 3.3853824138641357\n",
      "Epoch: 78, step: 300/781, loss: 3.4523253440856934\n",
      "Epoch: 78, step: 350/781, loss: 3.4581832885742188\n",
      "Epoch: 78, step: 400/781, loss: 3.435086250305176\n",
      "Epoch: 78, step: 450/781, loss: 3.457397937774658\n",
      "Epoch: 78, step: 500/781, loss: 3.3579697608947754\n",
      "Epoch: 78, step: 550/781, loss: 3.37416672706604\n",
      "Epoch: 78, step: 600/781, loss: 3.361043691635132\n",
      "Epoch: 78, step: 650/781, loss: 3.4280829429626465\n",
      "Epoch: 78, step: 700/781, loss: 3.4587020874023438\n",
      "Epoch: 78, step: 750/781, loss: 3.4949638843536377\n",
      "Epoch: 78 completed, average loss: 3.4472692678283026, time taken: 1.6246481537818909 mins\n",
      "Epoch: 79, step: 50/781, loss: 3.338651657104492\n",
      "Epoch: 79, step: 100/781, loss: 3.423865795135498\n",
      "Epoch: 79, step: 150/781, loss: 3.492636203765869\n",
      "Epoch: 79, step: 200/781, loss: 3.380645275115967\n",
      "Epoch: 79, step: 250/781, loss: 3.37446665763855\n",
      "Epoch: 79, step: 300/781, loss: 3.4820029735565186\n",
      "Epoch: 79, step: 350/781, loss: 3.5233142375946045\n",
      "Epoch: 79, step: 400/781, loss: 3.408891201019287\n",
      "Epoch: 79, step: 450/781, loss: 3.450227737426758\n",
      "Epoch: 79, step: 500/781, loss: 3.4572854042053223\n",
      "Epoch: 79, step: 550/781, loss: 3.4549317359924316\n",
      "Epoch: 79, step: 600/781, loss: 3.496041774749756\n",
      "Epoch: 79, step: 650/781, loss: 3.3997716903686523\n",
      "Epoch: 79, step: 700/781, loss: 3.4362940788269043\n",
      "Epoch: 79, step: 750/781, loss: 3.4978418350219727\n",
      "Epoch: 79 completed, average loss: 3.4471796700652217, time taken: 1.6308901270230611 mins\n",
      "Epoch: 80, step: 50/781, loss: 3.4391019344329834\n",
      "Epoch: 80, step: 100/781, loss: 3.4164342880249023\n",
      "Epoch: 80, step: 150/781, loss: 3.496091604232788\n",
      "Epoch: 80, step: 200/781, loss: 3.3878872394561768\n",
      "Epoch: 80, step: 250/781, loss: 3.377636194229126\n",
      "Epoch: 80, step: 300/781, loss: 3.397197723388672\n",
      "Epoch: 80, step: 350/781, loss: 3.5129380226135254\n",
      "Epoch: 80, step: 400/781, loss: 3.433241605758667\n",
      "Epoch: 80, step: 450/781, loss: 3.4166507720947266\n",
      "Epoch: 80, step: 500/781, loss: 3.3711462020874023\n",
      "Epoch: 80, step: 550/781, loss: 3.5185294151306152\n",
      "Epoch: 80, step: 600/781, loss: 3.448383092880249\n",
      "Epoch: 80, step: 650/781, loss: 3.3429718017578125\n",
      "Epoch: 80, step: 700/781, loss: 3.4935553073883057\n",
      "Epoch: 80, step: 750/781, loss: 3.328453779220581\n",
      "Epoch: 80 completed, average loss: 3.4461636329582497, time taken: 1.6274887681007386 mins\n",
      "Epoch: 81, step: 50/781, loss: 3.466740846633911\n",
      "Epoch: 81, step: 100/781, loss: 3.453254461288452\n",
      "Epoch: 81, step: 150/781, loss: 3.477600574493408\n",
      "Epoch: 81, step: 200/781, loss: 3.423880100250244\n",
      "Epoch: 81, step: 250/781, loss: 3.3761093616485596\n",
      "Epoch: 81, step: 300/781, loss: 3.4546406269073486\n",
      "Epoch: 81, step: 350/781, loss: 3.370654582977295\n",
      "Epoch: 81, step: 400/781, loss: 3.453265428543091\n",
      "Epoch: 81, step: 450/781, loss: 3.4242753982543945\n",
      "Epoch: 81, step: 500/781, loss: 3.3832814693450928\n",
      "Epoch: 81, step: 550/781, loss: 3.4002373218536377\n",
      "Epoch: 81, step: 600/781, loss: 3.4257547855377197\n",
      "Epoch: 81, step: 650/781, loss: 3.4541876316070557\n",
      "Epoch: 81, step: 700/781, loss: 3.451162099838257\n",
      "Epoch: 81, step: 750/781, loss: 3.4539506435394287\n",
      "Epoch: 81 completed, average loss: 3.44478542459759, time taken: 1.6283418615659078 mins\n",
      "Epoch: 82, step: 50/781, loss: 3.422421455383301\n",
      "Epoch: 82, step: 100/781, loss: 3.3373019695281982\n",
      "Epoch: 82, step: 150/781, loss: 3.4441449642181396\n",
      "Epoch: 82, step: 200/781, loss: 3.450664520263672\n",
      "Epoch: 82, step: 250/781, loss: 3.4817042350769043\n",
      "Epoch: 82, step: 300/781, loss: 3.48219633102417\n",
      "Epoch: 82, step: 350/781, loss: 3.479992628097534\n",
      "Epoch: 82, step: 400/781, loss: 3.5304453372955322\n",
      "Epoch: 82, step: 450/781, loss: 3.411303758621216\n",
      "Epoch: 82, step: 500/781, loss: 3.5001752376556396\n",
      "Epoch: 82, step: 550/781, loss: 3.3716559410095215\n",
      "Epoch: 82, step: 600/781, loss: 3.486919641494751\n",
      "Epoch: 82, step: 650/781, loss: 3.501940965652466\n",
      "Epoch: 82, step: 700/781, loss: 3.570207118988037\n",
      "Epoch: 82, step: 750/781, loss: 3.5334811210632324\n",
      "Epoch: 82 completed, average loss: 3.4462934904916644, time taken: 1.6262861371040345 mins\n",
      "Epoch: 83, step: 50/781, loss: 3.4166014194488525\n",
      "Epoch: 83, step: 100/781, loss: 3.5687448978424072\n",
      "Epoch: 83, step: 150/781, loss: 3.541907548904419\n",
      "Epoch: 83, step: 200/781, loss: 3.5040156841278076\n",
      "Epoch: 83, step: 250/781, loss: 3.3265879154205322\n",
      "Epoch: 83, step: 300/781, loss: 3.466787338256836\n",
      "Epoch: 83, step: 350/781, loss: 3.4333066940307617\n",
      "Epoch: 83, step: 400/781, loss: 3.4158244132995605\n",
      "Epoch: 83, step: 450/781, loss: 3.3613739013671875\n",
      "Epoch: 83, step: 500/781, loss: 3.3556087017059326\n",
      "Epoch: 83, step: 550/781, loss: 3.4364013671875\n",
      "Epoch: 83, step: 600/781, loss: 3.4094045162200928\n",
      "Epoch: 83, step: 650/781, loss: 3.5448451042175293\n",
      "Epoch: 83, step: 700/781, loss: 3.4584624767303467\n",
      "Epoch: 83, step: 750/781, loss: 3.3790760040283203\n",
      "Epoch: 83 completed, average loss: 3.442692584478596, time taken: 1.6361604690551759 mins\n",
      "Epoch: 84, step: 50/781, loss: 3.4502809047698975\n",
      "Epoch: 84, step: 100/781, loss: 3.5530433654785156\n",
      "Epoch: 84, step: 150/781, loss: 3.464845657348633\n",
      "Epoch: 84, step: 200/781, loss: 3.5272254943847656\n",
      "Epoch: 84, step: 250/781, loss: 3.4453561305999756\n",
      "Epoch: 84, step: 300/781, loss: 3.4330358505249023\n",
      "Epoch: 84, step: 350/781, loss: 3.4378037452697754\n",
      "Epoch: 84, step: 400/781, loss: 3.37196946144104\n",
      "Epoch: 84, step: 450/781, loss: 3.403491735458374\n",
      "Epoch: 84, step: 500/781, loss: 3.3234786987304688\n",
      "Epoch: 84, step: 550/781, loss: 3.4254698753356934\n",
      "Epoch: 84, step: 600/781, loss: 3.563452959060669\n",
      "Epoch: 84, step: 650/781, loss: 3.3789288997650146\n",
      "Epoch: 84, step: 700/781, loss: 3.474707841873169\n",
      "Epoch: 84, step: 750/781, loss: 3.407294273376465\n",
      "Epoch: 84 completed, average loss: 3.4436595152953826, time taken: 1.6238853494326273 mins\n",
      "Epoch: 85, step: 50/781, loss: 3.5732877254486084\n",
      "Epoch: 85, step: 100/781, loss: 3.382955551147461\n",
      "Epoch: 85, step: 150/781, loss: 3.3763301372528076\n",
      "Epoch: 85, step: 200/781, loss: 3.5104379653930664\n",
      "Epoch: 85, step: 250/781, loss: 3.544952154159546\n",
      "Epoch: 85, step: 300/781, loss: 3.4896414279937744\n",
      "Epoch: 85, step: 350/781, loss: 3.5658271312713623\n",
      "Epoch: 85, step: 400/781, loss: 3.3135263919830322\n",
      "Epoch: 85, step: 450/781, loss: 3.438131809234619\n",
      "Epoch: 85, step: 500/781, loss: 3.393928289413452\n",
      "Epoch: 85, step: 550/781, loss: 3.344326972961426\n",
      "Epoch: 85, step: 600/781, loss: 3.4517335891723633\n",
      "Epoch: 85, step: 650/781, loss: 3.441584348678589\n",
      "Epoch: 85, step: 700/781, loss: 3.408229112625122\n",
      "Epoch: 85, step: 750/781, loss: 3.4117777347564697\n",
      "Epoch: 85 completed, average loss: 3.4392604186806577, time taken: 1.628585191567739 mins\n",
      "Epoch: 86, step: 50/781, loss: 3.460932731628418\n",
      "Epoch: 86, step: 100/781, loss: 3.463893413543701\n",
      "Epoch: 86, step: 150/781, loss: 3.3777287006378174\n",
      "Epoch: 86, step: 200/781, loss: 3.4158802032470703\n",
      "Epoch: 86, step: 250/781, loss: 3.5264878273010254\n",
      "Epoch: 86, step: 300/781, loss: 3.445342540740967\n",
      "Epoch: 86, step: 350/781, loss: 3.503570556640625\n",
      "Epoch: 86, step: 400/781, loss: 3.445122718811035\n",
      "Epoch: 86, step: 450/781, loss: 3.3246660232543945\n",
      "Epoch: 86, step: 500/781, loss: 3.4432456493377686\n",
      "Epoch: 86, step: 550/781, loss: 3.3885157108306885\n",
      "Epoch: 86, step: 600/781, loss: 3.387314796447754\n",
      "Epoch: 86, step: 650/781, loss: 3.3913416862487793\n",
      "Epoch: 86, step: 700/781, loss: 3.5482571125030518\n",
      "Epoch: 86, step: 750/781, loss: 3.420767068862915\n",
      "Epoch: 86 completed, average loss: 3.4396696041854486, time taken: 1.6287442604700724 mins\n",
      "Epoch: 87, step: 50/781, loss: 3.4045486450195312\n",
      "Epoch: 87, step: 100/781, loss: 3.39962100982666\n",
      "Epoch: 87, step: 150/781, loss: 3.5302391052246094\n",
      "Epoch: 87, step: 200/781, loss: 3.4933807849884033\n",
      "Epoch: 87, step: 250/781, loss: 3.4875264167785645\n",
      "Epoch: 87, step: 300/781, loss: 3.4555835723876953\n",
      "Epoch: 87, step: 350/781, loss: 3.468873977661133\n",
      "Epoch: 87, step: 400/781, loss: 3.4322733879089355\n",
      "Epoch: 87, step: 450/781, loss: 3.4824228286743164\n",
      "Epoch: 87, step: 500/781, loss: 3.3828508853912354\n",
      "Epoch: 87, step: 550/781, loss: 3.468932867050171\n",
      "Epoch: 87, step: 600/781, loss: 3.3585259914398193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87, step: 650/781, loss: 3.4297711849212646\n",
      "Epoch: 87, step: 700/781, loss: 3.5861504077911377\n",
      "Epoch: 87, step: 750/781, loss: 3.366206645965576\n",
      "Epoch: 87 completed, average loss: 3.44080204481352, time taken: 1.626196297009786 mins\n",
      "Epoch: 88, step: 50/781, loss: 3.409128189086914\n",
      "Epoch: 88, step: 100/781, loss: 3.3088738918304443\n",
      "Epoch: 88, step: 150/781, loss: 3.4825267791748047\n",
      "Epoch: 88, step: 200/781, loss: 3.5366714000701904\n",
      "Epoch: 88, step: 250/781, loss: 3.3382627964019775\n",
      "Epoch: 88, step: 300/781, loss: 3.4212400913238525\n",
      "Epoch: 88, step: 350/781, loss: 3.4907710552215576\n",
      "Epoch: 88, step: 400/781, loss: 3.3116979598999023\n",
      "Epoch: 88, step: 450/781, loss: 3.5307400226593018\n",
      "Epoch: 88, step: 500/781, loss: 3.5066659450531006\n",
      "Epoch: 88, step: 550/781, loss: 3.371919870376587\n",
      "Epoch: 88, step: 600/781, loss: 3.393838882446289\n",
      "Epoch: 88, step: 650/781, loss: 3.488917827606201\n",
      "Epoch: 88, step: 700/781, loss: 3.4820823669433594\n",
      "Epoch: 88, step: 750/781, loss: 3.529982089996338\n",
      "Epoch: 88 completed, average loss: 3.4341448745410053, time taken: 1.6249103784561156 mins\n",
      "Epoch: 89, step: 50/781, loss: 3.3247780799865723\n",
      "Epoch: 89, step: 100/781, loss: 3.32273530960083\n",
      "Epoch: 89, step: 150/781, loss: 3.3972737789154053\n",
      "Epoch: 89, step: 200/781, loss: 3.3486487865448\n",
      "Epoch: 89, step: 250/781, loss: 3.4161746501922607\n",
      "Epoch: 89, step: 300/781, loss: 3.4731509685516357\n",
      "Epoch: 89, step: 350/781, loss: 3.5170650482177734\n",
      "Epoch: 89, step: 400/781, loss: 3.396681308746338\n",
      "Epoch: 89, step: 450/781, loss: 3.4960005283355713\n",
      "Epoch: 89, step: 500/781, loss: 3.460474967956543\n",
      "Epoch: 89, step: 550/781, loss: 3.369926929473877\n",
      "Epoch: 89, step: 600/781, loss: 3.4498603343963623\n",
      "Epoch: 89, step: 650/781, loss: 3.3491787910461426\n",
      "Epoch: 89, step: 700/781, loss: 3.395460844039917\n",
      "Epoch: 89, step: 750/781, loss: 3.4319698810577393\n",
      "Epoch: 89 completed, average loss: 3.436045479682893, time taken: 1.626963198184967 mins\n",
      "Epoch: 90, step: 50/781, loss: 3.3773810863494873\n",
      "Epoch: 90, step: 100/781, loss: 3.478501558303833\n",
      "Epoch: 90, step: 150/781, loss: 3.3890130519866943\n",
      "Epoch: 90, step: 200/781, loss: 3.475914716720581\n",
      "Epoch: 90, step: 250/781, loss: 3.415088415145874\n",
      "Epoch: 90, step: 300/781, loss: 3.4681074619293213\n",
      "Epoch: 90, step: 350/781, loss: 3.4824273586273193\n",
      "Epoch: 90, step: 400/781, loss: 3.468801259994507\n",
      "Epoch: 90, step: 450/781, loss: 3.415456771850586\n",
      "Epoch: 90, step: 500/781, loss: 3.4956610202789307\n",
      "Epoch: 90, step: 550/781, loss: 3.4097204208374023\n",
      "Epoch: 90, step: 600/781, loss: 3.481799364089966\n",
      "Epoch: 90, step: 650/781, loss: 3.2875308990478516\n",
      "Epoch: 90, step: 700/781, loss: 3.4506514072418213\n",
      "Epoch: 90, step: 750/781, loss: 3.459832191467285\n",
      "Epoch: 90 completed, average loss: 3.4354068530811697, time taken: 1.6252981980641683 mins\n",
      "Epoch: 91, step: 50/781, loss: 3.610834836959839\n",
      "Epoch: 91, step: 100/781, loss: 3.479496479034424\n",
      "Epoch: 91, step: 150/781, loss: 3.4580020904541016\n",
      "Epoch: 91, step: 200/781, loss: 3.3370490074157715\n",
      "Epoch: 91, step: 250/781, loss: 3.4743566513061523\n",
      "Epoch: 91, step: 300/781, loss: 3.5110042095184326\n",
      "Epoch: 91, step: 350/781, loss: 3.3157448768615723\n",
      "Epoch: 91, step: 400/781, loss: 3.416943311691284\n",
      "Epoch: 91, step: 450/781, loss: 3.4743995666503906\n",
      "Epoch: 91, step: 500/781, loss: 3.357189655303955\n",
      "Epoch: 91, step: 550/781, loss: 3.3605594635009766\n",
      "Epoch: 91, step: 600/781, loss: 3.4162676334381104\n",
      "Epoch: 91, step: 650/781, loss: 3.3785898685455322\n",
      "Epoch: 91, step: 700/781, loss: 3.4799396991729736\n",
      "Epoch: 91, step: 750/781, loss: 3.4208621978759766\n",
      "Epoch: 91 completed, average loss: 3.431979844573213, time taken: 1.6271190683046977 mins\n",
      "Epoch: 92, step: 50/781, loss: 3.351491689682007\n",
      "Epoch: 92, step: 100/781, loss: 3.458716869354248\n",
      "Epoch: 92, step: 150/781, loss: 3.4901554584503174\n",
      "Epoch: 92, step: 200/781, loss: 3.455796241760254\n",
      "Epoch: 92, step: 250/781, loss: 3.4661970138549805\n",
      "Epoch: 92, step: 300/781, loss: 3.4099929332733154\n",
      "Epoch: 92, step: 350/781, loss: 3.4489541053771973\n",
      "Epoch: 92, step: 400/781, loss: 3.418642282485962\n",
      "Epoch: 92, step: 450/781, loss: 3.467397451400757\n",
      "Epoch: 92, step: 500/781, loss: 3.4007694721221924\n",
      "Epoch: 92, step: 550/781, loss: 3.3656234741210938\n",
      "Epoch: 92, step: 600/781, loss: 3.4669222831726074\n",
      "Epoch: 92, step: 650/781, loss: 3.3583710193634033\n",
      "Epoch: 92, step: 700/781, loss: 3.335697650909424\n",
      "Epoch: 92, step: 750/781, loss: 3.3424336910247803\n",
      "Epoch: 92 completed, average loss: 3.4336732190946613, time taken: 1.6283403038978577 mins\n",
      "Epoch: 93, step: 50/781, loss: 3.6024060249328613\n",
      "Epoch: 93, step: 100/781, loss: 3.5832021236419678\n",
      "Epoch: 93, step: 150/781, loss: 3.4030048847198486\n",
      "Epoch: 93, step: 200/781, loss: 3.5132720470428467\n",
      "Epoch: 93, step: 250/781, loss: 3.3825082778930664\n",
      "Epoch: 93, step: 300/781, loss: 3.4010794162750244\n",
      "Epoch: 93, step: 350/781, loss: 3.4313888549804688\n",
      "Epoch: 93, step: 400/781, loss: 3.4876744747161865\n",
      "Epoch: 93, step: 450/781, loss: 3.3813583850860596\n",
      "Epoch: 93, step: 500/781, loss: 3.4822745323181152\n",
      "Epoch: 93, step: 550/781, loss: 3.404265880584717\n",
      "Epoch: 93, step: 600/781, loss: 3.375208854675293\n",
      "Epoch: 93, step: 650/781, loss: 3.3749639987945557\n",
      "Epoch: 93, step: 700/781, loss: 3.364284038543701\n",
      "Epoch: 93, step: 750/781, loss: 3.347095012664795\n",
      "Epoch: 93 completed, average loss: 3.4328511423704415, time taken: 1.6225893139839171 mins\n",
      "Epoch: 94, step: 50/781, loss: 3.36977219581604\n",
      "Epoch: 94, step: 100/781, loss: 3.4772145748138428\n",
      "Epoch: 94, step: 150/781, loss: 3.4273979663848877\n",
      "Epoch: 94, step: 200/781, loss: 3.407325029373169\n",
      "Epoch: 94, step: 250/781, loss: 3.4241421222686768\n",
      "Epoch: 94, step: 300/781, loss: 3.385681390762329\n",
      "Epoch: 94, step: 350/781, loss: 3.5182604789733887\n",
      "Epoch: 94, step: 400/781, loss: 3.4677765369415283\n",
      "Epoch: 94, step: 450/781, loss: 3.491434097290039\n",
      "Epoch: 94, step: 500/781, loss: 3.4234156608581543\n",
      "Epoch: 94, step: 550/781, loss: 3.5677437782287598\n",
      "Epoch: 94, step: 600/781, loss: 3.3682050704956055\n",
      "Epoch: 94, step: 650/781, loss: 3.4343132972717285\n",
      "Epoch: 94, step: 700/781, loss: 3.3661396503448486\n",
      "Epoch: 94, step: 750/781, loss: 3.463564157485962\n",
      "Epoch: 94 completed, average loss: 3.4269612458237613, time taken: 1.6195718804995218 mins\n",
      "Epoch: 95, step: 50/781, loss: 3.4564836025238037\n",
      "Epoch: 95, step: 100/781, loss: 3.48956561088562\n",
      "Epoch: 95, step: 150/781, loss: 3.3630456924438477\n",
      "Epoch: 95, step: 200/781, loss: 3.342189311981201\n",
      "Epoch: 95, step: 250/781, loss: 3.468940258026123\n",
      "Epoch: 95, step: 300/781, loss: 3.403641939163208\n",
      "Epoch: 95, step: 350/781, loss: 3.429413080215454\n",
      "Epoch: 95, step: 400/781, loss: 3.3107407093048096\n",
      "Epoch: 95, step: 450/781, loss: 3.45790958404541\n",
      "Epoch: 95, step: 500/781, loss: 3.3778293132781982\n",
      "Epoch: 95, step: 550/781, loss: 3.419437885284424\n",
      "Epoch: 95, step: 600/781, loss: 3.435511589050293\n",
      "Epoch: 95, step: 650/781, loss: 3.3461384773254395\n",
      "Epoch: 95, step: 700/781, loss: 3.4466769695281982\n",
      "Epoch: 95, step: 750/781, loss: 3.50163197517395\n",
      "Epoch: 95 completed, average loss: 3.426134062484956, time taken: 1.6214181860287984 mins\n",
      "Epoch: 96, step: 50/781, loss: 3.4289722442626953\n",
      "Epoch: 96, step: 100/781, loss: 3.3496530055999756\n",
      "Epoch: 96, step: 150/781, loss: 3.348726511001587\n",
      "Epoch: 96, step: 200/781, loss: 3.37607479095459\n",
      "Epoch: 96, step: 250/781, loss: 3.490732192993164\n",
      "Epoch: 96, step: 300/781, loss: 3.3878440856933594\n",
      "Epoch: 96, step: 350/781, loss: 3.5049245357513428\n",
      "Epoch: 96, step: 400/781, loss: 3.321655035018921\n",
      "Epoch: 96, step: 450/781, loss: 3.389345169067383\n",
      "Epoch: 96, step: 500/781, loss: 3.5161077976226807\n",
      "Epoch: 96, step: 550/781, loss: 3.432399034500122\n",
      "Epoch: 96, step: 600/781, loss: 3.519252061843872\n",
      "Epoch: 96, step: 650/781, loss: 3.482606887817383\n",
      "Epoch: 96, step: 700/781, loss: 3.4514856338500977\n",
      "Epoch: 96, step: 750/781, loss: 3.4363410472869873\n",
      "Epoch: 96 completed, average loss: 3.4305993820732597, time taken: 1.6221346497535705 mins\n",
      "Epoch: 97, step: 50/781, loss: 3.3459973335266113\n",
      "Epoch: 97, step: 100/781, loss: 3.4948675632476807\n",
      "Epoch: 97, step: 150/781, loss: 3.430506706237793\n",
      "Epoch: 97, step: 200/781, loss: 3.478165864944458\n",
      "Epoch: 97, step: 250/781, loss: 3.4543118476867676\n",
      "Epoch: 97, step: 300/781, loss: 3.4929733276367188\n",
      "Epoch: 97, step: 350/781, loss: 3.4476168155670166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97, step: 400/781, loss: 3.420642375946045\n",
      "Epoch: 97, step: 450/781, loss: 3.4596660137176514\n",
      "Epoch: 97, step: 500/781, loss: 3.371290683746338\n",
      "Epoch: 97, step: 550/781, loss: 3.457963228225708\n",
      "Epoch: 97, step: 600/781, loss: 3.433607339859009\n",
      "Epoch: 97, step: 650/781, loss: 3.420668840408325\n",
      "Epoch: 97, step: 700/781, loss: 3.4278604984283447\n",
      "Epoch: 97, step: 750/781, loss: 3.3548855781555176\n",
      "Epoch: 97 completed, average loss: 3.4299771019499676, time taken: 1.622571623325348 mins\n",
      "Epoch: 98, step: 50/781, loss: 3.4691667556762695\n",
      "Epoch: 98, step: 100/781, loss: 3.442854166030884\n",
      "Epoch: 98, step: 150/781, loss: 3.3578319549560547\n",
      "Epoch: 98, step: 200/781, loss: 3.3900351524353027\n",
      "Epoch: 98, step: 250/781, loss: 3.4152228832244873\n",
      "Epoch: 98, step: 300/781, loss: 3.3804244995117188\n",
      "Epoch: 98, step: 350/781, loss: 3.461190938949585\n",
      "Epoch: 98, step: 400/781, loss: 3.443189859390259\n",
      "Epoch: 98, step: 450/781, loss: 3.3777194023132324\n",
      "Epoch: 98, step: 500/781, loss: 3.415318250656128\n",
      "Epoch: 98, step: 550/781, loss: 3.3581063747406006\n",
      "Epoch: 98, step: 600/781, loss: 3.3302412033081055\n",
      "Epoch: 98, step: 650/781, loss: 3.566895008087158\n",
      "Epoch: 98, step: 700/781, loss: 3.3533618450164795\n",
      "Epoch: 98, step: 750/781, loss: 3.4140827655792236\n",
      "Epoch: 98 completed, average loss: 3.4226176073242853, time taken: 1.6306912024815878 mins\n",
      "Epoch: 99, step: 50/781, loss: 3.3834285736083984\n",
      "Epoch: 99, step: 100/781, loss: 3.3948686122894287\n",
      "Epoch: 99, step: 150/781, loss: 3.5302016735076904\n",
      "Epoch: 99, step: 200/781, loss: 3.460754632949829\n",
      "Epoch: 99, step: 250/781, loss: 3.506014585494995\n",
      "Epoch: 99, step: 300/781, loss: 3.3473401069641113\n",
      "Epoch: 99, step: 350/781, loss: 3.371300458908081\n",
      "Epoch: 99, step: 400/781, loss: 3.409419059753418\n",
      "Epoch: 99, step: 450/781, loss: 3.3861703872680664\n",
      "Epoch: 99, step: 500/781, loss: 3.4041357040405273\n",
      "Epoch: 99, step: 550/781, loss: 3.472231864929199\n",
      "Epoch: 99, step: 600/781, loss: 3.376052141189575\n",
      "Epoch: 99, step: 650/781, loss: 3.435412645339966\n",
      "Epoch: 99, step: 700/781, loss: 3.438936233520508\n",
      "Epoch: 99, step: 750/781, loss: 3.3595640659332275\n",
      "Epoch: 99 completed, average loss: 3.4252201823968433, time taken: 1.6244779268900553 mins\n"
     ]
    }
   ],
   "source": [
    "proj_dim = 128\n",
    "model = SimClr('resnet50',proj_dim).cuda()\n",
    "temperature = 0.5\n",
    "#criterion = nt_xent_loss\n",
    "criterion = SimCLR_Loss(64,0.5)\n",
    "optimizer = \"LARS\"\n",
    "model, train_loss = train_simclr(train_loader_simclr,model,criterion,optimizer,100,64,True,\"/home/ky2446/saved-models/CIFAR10-RES50-SIMCLR-BS64-PD128-LARS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76556691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"NT-XENT Loss\")\n",
    "plt.title(\"CIFAR10 ResNet-50 SimClr BS:64, OP: LARS\")\n",
    "plt.plot(train_loss)\n",
    "plt.savefig(\"/home/ky2446/figures/CIFAR10-RES50-SIMCLR-BS64-PD128-LARS.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe5936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/ky2446/training-logs/CIFAR10-RES50-SIMCLR-BS64-PD128-LARS\", \"wb\") as fp: \n",
    "    pickle.dump(train_loss, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8393700b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
