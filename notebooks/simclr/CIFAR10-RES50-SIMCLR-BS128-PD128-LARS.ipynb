{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Bhz0-M54pC8X"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aPi5kpQrwvN",
    "outputId": "ccfdfedf-a0c4-4461-9854-13b2f4d3ad8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May  4 16:13:06 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZuI_M7gOxSYB"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# setting path\n",
    "sys.path.append(\"/home/ky2446/simclr\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/layers\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/models\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/loss\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/optim\")\n",
    "sys.path.append(\"/home/ky2446/simclr/simclr/dataloader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sg8xnH8Xyhav"
   },
   "outputs": [],
   "source": [
    "from simclrpy import SimClr\n",
    "from ntxent import nt_xent_loss\n",
    "from ntxentgit import SimCLR_Loss\n",
    "from augment import TransformsSimCLR\n",
    "from utils import *\n",
    "from LARS import LARS\n",
    "from downstream import DownStream\n",
    "from dataloader import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3asJqZA2Ht8W"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9WdTN8WKuGsr",
    "outputId": "d529a3c1-f468-41b2-b160-f590a6dace11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader_simclr = train_loader_simclr(\"CIFAR10\",128)\n",
    "test_loader = test_loader(\"CIFAR10\",128)\n",
    "test_images, test_labels = get_testimgs_list(\"CIFAR10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izbMG21WokNZ",
    "outputId": "49af751c-db8d-45cd-95ab-4920c1afc351"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/simclr/optim/LARS.py:136: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)\n",
      "  next_v.mul_(momentum).add_(scaled_lr, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, step: 50/390, loss: 5.53007698059082\n",
      "Epoch: 0, step: 100/390, loss: 5.467336654663086\n",
      "Epoch: 0, step: 150/390, loss: 5.488121032714844\n",
      "Epoch: 0, step: 200/390, loss: 5.3604326248168945\n",
      "Epoch: 0, step: 250/390, loss: 5.325634002685547\n",
      "Epoch: 0, step: 300/390, loss: 5.233689785003662\n",
      "Epoch: 0, step: 350/390, loss: 5.174006938934326\n",
      "Epoch: 0 completed, average loss: 5.380153981233255, time taken: 3.1905666987101235 mins\n",
      "Epoch: 1, step: 50/390, loss: 5.189033031463623\n",
      "Epoch: 1, step: 100/390, loss: 5.02957010269165\n",
      "Epoch: 1, step: 150/390, loss: 5.08118200302124\n",
      "Epoch: 1, step: 200/390, loss: 5.150210380554199\n",
      "Epoch: 1, step: 250/390, loss: 5.117499351501465\n",
      "Epoch: 1, step: 300/390, loss: 4.924752712249756\n",
      "Epoch: 1, step: 350/390, loss: 5.0614333152771\n",
      "Epoch: 1 completed, average loss: 5.063137248846201, time taken: 3.163666001955668 mins\n",
      "Epoch: 2, step: 50/390, loss: 4.892119407653809\n",
      "Epoch: 2, step: 100/390, loss: 4.979701519012451\n",
      "Epoch: 2, step: 150/390, loss: 4.901201248168945\n",
      "Epoch: 2, step: 200/390, loss: 4.898133277893066\n",
      "Epoch: 2, step: 250/390, loss: 4.741593360900879\n",
      "Epoch: 2, step: 300/390, loss: 4.893747329711914\n",
      "Epoch: 2, step: 350/390, loss: 4.805213928222656\n",
      "Epoch: 2 completed, average loss: 4.899337378526345, time taken: 3.162945588429769 mins\n",
      "Epoch: 3, step: 50/390, loss: 4.851280689239502\n",
      "Epoch: 3, step: 100/390, loss: 4.861034870147705\n",
      "Epoch: 3, step: 150/390, loss: 4.853080749511719\n",
      "Epoch: 3, step: 200/390, loss: 4.846587181091309\n",
      "Epoch: 3, step: 250/390, loss: 4.654032230377197\n",
      "Epoch: 3, step: 300/390, loss: 4.786026954650879\n",
      "Epoch: 3, step: 350/390, loss: 4.798418998718262\n",
      "Epoch: 3 completed, average loss: 4.780921115630712, time taken: 3.1631863395373028 mins\n",
      "Epoch: 4, step: 50/390, loss: 4.599658012390137\n",
      "Epoch: 4, step: 100/390, loss: 4.732280731201172\n",
      "Epoch: 4, step: 150/390, loss: 4.626420497894287\n",
      "Epoch: 4, step: 200/390, loss: 4.697288513183594\n",
      "Epoch: 4, step: 250/390, loss: 4.629110336303711\n",
      "Epoch: 4, step: 300/390, loss: 4.57189416885376\n",
      "Epoch: 4, step: 350/390, loss: 4.647060871124268\n",
      "Epoch: 4 completed, average loss: 4.671596187200302, time taken: 3.1661006689071653 mins\n",
      "Epoch: 5, step: 50/390, loss: 4.658641815185547\n",
      "Epoch: 5, step: 100/390, loss: 4.6217570304870605\n",
      "Epoch: 5, step: 150/390, loss: 4.665834903717041\n",
      "Epoch: 5, step: 200/390, loss: 4.529531955718994\n",
      "Epoch: 5, step: 250/390, loss: 4.5141730308532715\n",
      "Epoch: 5, step: 300/390, loss: 4.651865482330322\n",
      "Epoch: 5, step: 350/390, loss: 4.579380989074707\n",
      "Epoch: 5 completed, average loss: 4.609088354844314, time taken: 3.166712486743927 mins\n",
      "Epoch: 6, step: 50/390, loss: 4.5553507804870605\n",
      "Epoch: 6, step: 100/390, loss: 4.572688102722168\n",
      "Epoch: 6, step: 150/390, loss: 4.565949440002441\n",
      "Epoch: 6, step: 200/390, loss: 4.569231033325195\n",
      "Epoch: 6, step: 250/390, loss: 4.590351104736328\n",
      "Epoch: 6, step: 300/390, loss: 4.589111328125\n",
      "Epoch: 6, step: 350/390, loss: 4.5756025314331055\n",
      "Epoch: 6 completed, average loss: 4.560908421491965, time taken: 3.161082843939463 mins\n",
      "Epoch: 7, step: 50/390, loss: 4.494394302368164\n",
      "Epoch: 7, step: 100/390, loss: 4.537591934204102\n",
      "Epoch: 7, step: 150/390, loss: 4.542336463928223\n",
      "Epoch: 7, step: 200/390, loss: 4.58059549331665\n",
      "Epoch: 7, step: 250/390, loss: 4.486114025115967\n",
      "Epoch: 7, step: 300/390, loss: 4.472216606140137\n",
      "Epoch: 7, step: 350/390, loss: 4.57524299621582\n",
      "Epoch: 7 completed, average loss: 4.516925411957961, time taken: 3.160805122057597 mins\n",
      "Epoch: 8, step: 50/390, loss: 4.44420051574707\n",
      "Epoch: 8, step: 100/390, loss: 4.503576755523682\n",
      "Epoch: 8, step: 150/390, loss: 4.475123882293701\n",
      "Epoch: 8, step: 200/390, loss: 4.4519877433776855\n",
      "Epoch: 8, step: 250/390, loss: 4.463931083679199\n",
      "Epoch: 8, step: 300/390, loss: 4.445281505584717\n",
      "Epoch: 8, step: 350/390, loss: 4.4685163497924805\n",
      "Epoch: 8 completed, average loss: 4.486599074877225, time taken: 3.1577207525571187 mins\n",
      "Epoch: 9, step: 50/390, loss: 4.564479827880859\n",
      "Epoch: 9, step: 100/390, loss: 4.442695617675781\n",
      "Epoch: 9, step: 150/390, loss: 4.489773750305176\n",
      "Epoch: 9, step: 200/390, loss: 4.440128326416016\n",
      "Epoch: 9, step: 250/390, loss: 4.4312615394592285\n",
      "Epoch: 9, step: 300/390, loss: 4.383583068847656\n",
      "Epoch: 9, step: 350/390, loss: 4.446274280548096\n",
      "Epoch: 9 completed, average loss: 4.457489971014169, time taken: 3.1575166900952656 mins\n",
      "Epoch: 10, step: 50/390, loss: 4.401899814605713\n",
      "Epoch: 10, step: 100/390, loss: 4.450078964233398\n",
      "Epoch: 10, step: 150/390, loss: 4.4791412353515625\n",
      "Epoch: 10, step: 200/390, loss: 4.414998531341553\n",
      "Epoch: 10, step: 250/390, loss: 4.442317485809326\n",
      "Epoch: 10, step: 300/390, loss: 4.530649185180664\n",
      "Epoch: 10, step: 350/390, loss: 4.472418308258057\n",
      "Epoch: 10 completed, average loss: 4.428330337084256, time taken: 3.1587098916371663 mins\n",
      "Epoch: 11, step: 50/390, loss: 4.432140827178955\n",
      "Epoch: 11, step: 100/390, loss: 4.369954586029053\n",
      "Epoch: 11, step: 150/390, loss: 4.364772319793701\n",
      "Epoch: 11, step: 200/390, loss: 4.367702484130859\n",
      "Epoch: 11, step: 250/390, loss: 4.367195129394531\n",
      "Epoch: 11, step: 300/390, loss: 4.351032257080078\n",
      "Epoch: 11, step: 350/390, loss: 4.4298624992370605\n",
      "Epoch: 11 completed, average loss: 4.399356690431253, time taken: 3.1579339265823365 mins\n",
      "Epoch: 12, step: 50/390, loss: 4.405575275421143\n",
      "Epoch: 12, step: 100/390, loss: 4.464799880981445\n",
      "Epoch: 12, step: 150/390, loss: 4.3945207595825195\n",
      "Epoch: 12, step: 200/390, loss: 4.3545613288879395\n",
      "Epoch: 12, step: 250/390, loss: 4.315540313720703\n",
      "Epoch: 12, step: 300/390, loss: 4.317934036254883\n",
      "Epoch: 12, step: 350/390, loss: 4.40850305557251\n",
      "Epoch: 12 completed, average loss: 4.379566115599412, time taken: 3.1592766364415485 mins\n",
      "Epoch: 13, step: 50/390, loss: 4.386135578155518\n",
      "Epoch: 13, step: 100/390, loss: 4.4186110496521\n",
      "Epoch: 13, step: 150/390, loss: 4.389798641204834\n",
      "Epoch: 13, step: 200/390, loss: 4.405178546905518\n",
      "Epoch: 13, step: 250/390, loss: 4.308724403381348\n",
      "Epoch: 13, step: 300/390, loss: 4.390781402587891\n",
      "Epoch: 13, step: 350/390, loss: 4.318091869354248\n",
      "Epoch: 13 completed, average loss: 4.361757394595024, time taken: 3.1600881695747374 mins\n",
      "Epoch: 14, step: 50/390, loss: 4.386491298675537\n",
      "Epoch: 14, step: 100/390, loss: 4.373110294342041\n",
      "Epoch: 14, step: 150/390, loss: 4.443576335906982\n",
      "Epoch: 14, step: 200/390, loss: 4.308549404144287\n",
      "Epoch: 14, step: 250/390, loss: 4.345255374908447\n",
      "Epoch: 14, step: 300/390, loss: 4.362918853759766\n",
      "Epoch: 14, step: 350/390, loss: 4.359930038452148\n",
      "Epoch: 14 completed, average loss: 4.349257386036408, time taken: 3.160140872001648 mins\n",
      "Epoch: 15, step: 50/390, loss: 4.286584854125977\n",
      "Epoch: 15, step: 100/390, loss: 4.32318115234375\n",
      "Epoch: 15, step: 150/390, loss: 4.2718505859375\n",
      "Epoch: 15, step: 200/390, loss: 4.255248546600342\n",
      "Epoch: 15, step: 250/390, loss: 4.353419780731201\n",
      "Epoch: 15, step: 300/390, loss: 4.3192925453186035\n",
      "Epoch: 15, step: 350/390, loss: 4.274087905883789\n",
      "Epoch: 15 completed, average loss: 4.3341857616718, time taken: 3.1607606212298074 mins\n",
      "Epoch: 16, step: 50/390, loss: 4.3524065017700195\n",
      "Epoch: 16, step: 100/390, loss: 4.264260292053223\n",
      "Epoch: 16, step: 150/390, loss: 4.280486106872559\n",
      "Epoch: 16, step: 200/390, loss: 4.292842388153076\n",
      "Epoch: 16, step: 250/390, loss: 4.331458568572998\n",
      "Epoch: 16, step: 300/390, loss: 4.26369047164917\n",
      "Epoch: 16, step: 350/390, loss: 4.317117691040039\n",
      "Epoch: 16 completed, average loss: 4.322703705078516, time taken: 3.157969832420349 mins\n",
      "Epoch: 17, step: 50/390, loss: 4.354234218597412\n",
      "Epoch: 17, step: 100/390, loss: 4.36191987991333\n",
      "Epoch: 17, step: 150/390, loss: 4.2861409187316895\n",
      "Epoch: 17, step: 200/390, loss: 4.2704620361328125\n",
      "Epoch: 17, step: 250/390, loss: 4.412877082824707\n",
      "Epoch: 17, step: 300/390, loss: 4.275267124176025\n",
      "Epoch: 17, step: 350/390, loss: 4.30972957611084\n",
      "Epoch: 17 completed, average loss: 4.308512097138625, time taken: 3.160807700951894 mins\n",
      "Epoch: 18, step: 50/390, loss: 4.2317304611206055\n",
      "Epoch: 18, step: 100/390, loss: 4.298992156982422\n",
      "Epoch: 18, step: 150/390, loss: 4.302943229675293\n",
      "Epoch: 18, step: 200/390, loss: 4.369341850280762\n",
      "Epoch: 18, step: 250/390, loss: 4.295039176940918\n",
      "Epoch: 18, step: 300/390, loss: 4.245755195617676\n",
      "Epoch: 18, step: 350/390, loss: 4.246061325073242\n",
      "Epoch: 18 completed, average loss: 4.298423152092176, time taken: 3.1594989776611326 mins\n",
      "Epoch: 19, step: 50/390, loss: 4.304506301879883\n",
      "Epoch: 19, step: 100/390, loss: 4.3144941329956055\n",
      "Epoch: 19, step: 150/390, loss: 4.215649604797363\n",
      "Epoch: 19, step: 200/390, loss: 4.255629062652588\n",
      "Epoch: 19, step: 250/390, loss: 4.327610015869141\n",
      "Epoch: 19, step: 300/390, loss: 4.300355911254883\n",
      "Epoch: 19, step: 350/390, loss: 4.230388164520264\n",
      "Epoch: 19 completed, average loss: 4.287721437062973, time taken: 3.1572582284609476 mins\n",
      "Epoch: 20, step: 50/390, loss: 4.314866542816162\n",
      "Epoch: 20, step: 100/390, loss: 4.2547526359558105\n",
      "Epoch: 20, step: 150/390, loss: 4.3142547607421875\n",
      "Epoch: 20, step: 200/390, loss: 4.264853477478027\n",
      "Epoch: 20, step: 250/390, loss: 4.2249555587768555\n",
      "Epoch: 20, step: 300/390, loss: 4.285253047943115\n",
      "Epoch: 20, step: 350/390, loss: 4.259303569793701\n",
      "Epoch: 20 completed, average loss: 4.2765200932820635, time taken: 3.1593217531840008 mins\n",
      "Epoch: 21, step: 50/390, loss: 4.269710540771484\n",
      "Epoch: 21, step: 100/390, loss: 4.279934883117676\n",
      "Epoch: 21, step: 150/390, loss: 4.273122787475586\n",
      "Epoch: 21, step: 200/390, loss: 4.230321884155273\n",
      "Epoch: 21, step: 250/390, loss: 4.27250337600708\n",
      "Epoch: 21, step: 300/390, loss: 4.298698425292969\n",
      "Epoch: 21, step: 350/390, loss: 4.2926154136657715\n",
      "Epoch: 21 completed, average loss: 4.2723069484417255, time taken: 3.157766095797221 mins\n",
      "Epoch: 22, step: 50/390, loss: 4.3112874031066895\n",
      "Epoch: 22, step: 100/390, loss: 4.243692398071289\n",
      "Epoch: 22, step: 150/390, loss: 4.3873677253723145\n",
      "Epoch: 22, step: 200/390, loss: 4.254428863525391\n",
      "Epoch: 22, step: 250/390, loss: 4.276598930358887\n",
      "Epoch: 22, step: 300/390, loss: 4.353996753692627\n",
      "Epoch: 22, step: 350/390, loss: 4.2267374992370605\n",
      "Epoch: 22 completed, average loss: 4.263920952723576, time taken: 3.158176557223002 mins\n",
      "Epoch: 23, step: 50/390, loss: 4.272693634033203\n",
      "Epoch: 23, step: 100/390, loss: 4.286261081695557\n",
      "Epoch: 23, step: 150/390, loss: 4.200182914733887\n",
      "Epoch: 23, step: 200/390, loss: 4.277191638946533\n",
      "Epoch: 23, step: 250/390, loss: 4.197352409362793\n",
      "Epoch: 23, step: 300/390, loss: 4.239712238311768\n",
      "Epoch: 23, step: 350/390, loss: 4.3214287757873535\n",
      "Epoch: 23 completed, average loss: 4.2551386172954855, time taken: 3.157794694105784 mins\n",
      "Epoch: 24, step: 50/390, loss: 4.214333534240723\n",
      "Epoch: 24, step: 100/390, loss: 4.260620594024658\n",
      "Epoch: 24, step: 150/390, loss: 4.228048801422119\n",
      "Epoch: 24, step: 200/390, loss: 4.211035251617432\n",
      "Epoch: 24, step: 250/390, loss: 4.280782699584961\n",
      "Epoch: 24, step: 300/390, loss: 4.231778621673584\n",
      "Epoch: 24, step: 350/390, loss: 4.272984981536865\n",
      "Epoch: 24 completed, average loss: 4.244811708499224, time taken: 3.1560059547424317 mins\n",
      "Epoch: 25, step: 50/390, loss: 4.235111236572266\n",
      "Epoch: 25, step: 100/390, loss: 4.2112627029418945\n",
      "Epoch: 25, step: 150/390, loss: 4.172839641571045\n",
      "Epoch: 25, step: 200/390, loss: 4.29286003112793\n",
      "Epoch: 25, step: 250/390, loss: 4.235711097717285\n",
      "Epoch: 25, step: 300/390, loss: 4.235072135925293\n",
      "Epoch: 25, step: 350/390, loss: 4.26552677154541\n",
      "Epoch: 25 completed, average loss: 4.241342121515519, time taken: 3.1613359769185383 mins\n",
      "Epoch: 26, step: 50/390, loss: 4.213310718536377\n",
      "Epoch: 26, step: 100/390, loss: 4.244107246398926\n",
      "Epoch: 26, step: 150/390, loss: 4.266401767730713\n",
      "Epoch: 26, step: 200/390, loss: 4.231446266174316\n",
      "Epoch: 26, step: 250/390, loss: 4.259947299957275\n",
      "Epoch: 26, step: 300/390, loss: 4.188847541809082\n",
      "Epoch: 26, step: 350/390, loss: 4.256839275360107\n",
      "Epoch: 26 completed, average loss: 4.234700066004044, time taken: 3.160472790400187 mins\n",
      "Epoch: 27, step: 50/390, loss: 4.151947498321533\n",
      "Epoch: 27, step: 100/390, loss: 4.217674255371094\n",
      "Epoch: 27, step: 150/390, loss: 4.233042240142822\n",
      "Epoch: 27, step: 200/390, loss: 4.220175266265869\n",
      "Epoch: 27, step: 250/390, loss: 4.233850955963135\n",
      "Epoch: 27, step: 300/390, loss: 4.1757731437683105\n",
      "Epoch: 27, step: 350/390, loss: 4.214069843292236\n",
      "Epoch: 27 completed, average loss: 4.230064148780627, time taken: 3.161759376525879 mins\n",
      "Epoch: 28, step: 50/390, loss: 4.168122291564941\n",
      "Epoch: 28, step: 100/390, loss: 4.154475212097168\n",
      "Epoch: 28, step: 150/390, loss: 4.300022602081299\n",
      "Epoch: 28, step: 200/390, loss: 4.166277885437012\n",
      "Epoch: 28, step: 250/390, loss: 4.261815071105957\n",
      "Epoch: 28, step: 300/390, loss: 4.200681209564209\n",
      "Epoch: 28, step: 350/390, loss: 4.248171329498291\n",
      "Epoch: 28 completed, average loss: 4.225604608731392, time taken: 3.161707146962484 mins\n",
      "Epoch: 29, step: 50/390, loss: 4.213274002075195\n",
      "Epoch: 29, step: 100/390, loss: 4.210135459899902\n",
      "Epoch: 29, step: 150/390, loss: 4.241765975952148\n",
      "Epoch: 29, step: 200/390, loss: 4.257599353790283\n",
      "Epoch: 29, step: 250/390, loss: 4.157786846160889\n",
      "Epoch: 29, step: 300/390, loss: 4.250314712524414\n",
      "Epoch: 29, step: 350/390, loss: 4.266003131866455\n",
      "Epoch: 29 completed, average loss: 4.225115040021065, time taken: 3.1606704791386924 mins\n",
      "Epoch: 30, step: 50/390, loss: 4.213273048400879\n",
      "Epoch: 30, step: 100/390, loss: 4.268324851989746\n",
      "Epoch: 30, step: 150/390, loss: 4.255497932434082\n",
      "Epoch: 30, step: 200/390, loss: 4.1487135887146\n",
      "Epoch: 30, step: 250/390, loss: 4.167252063751221\n",
      "Epoch: 30, step: 300/390, loss: 4.26808500289917\n",
      "Epoch: 30, step: 350/390, loss: 4.1949872970581055\n",
      "Epoch: 30 completed, average loss: 4.2192168223552216, time taken: 3.1587236642837526 mins\n",
      "Epoch: 31, step: 50/390, loss: 4.236516952514648\n",
      "Epoch: 31, step: 100/390, loss: 4.230286121368408\n",
      "Epoch: 31, step: 150/390, loss: 4.212131500244141\n",
      "Epoch: 31, step: 200/390, loss: 4.163743019104004\n",
      "Epoch: 31, step: 250/390, loss: 4.1936235427856445\n",
      "Epoch: 31, step: 300/390, loss: 4.193603992462158\n",
      "Epoch: 31, step: 350/390, loss: 4.265047550201416\n",
      "Epoch: 31 completed, average loss: 4.209910236260829, time taken: 3.157114799817403 mins\n",
      "Epoch: 32, step: 50/390, loss: 4.271353244781494\n",
      "Epoch: 32, step: 100/390, loss: 4.212082386016846\n",
      "Epoch: 32, step: 150/390, loss: 4.168089389801025\n",
      "Epoch: 32, step: 200/390, loss: 4.2247185707092285\n",
      "Epoch: 32, step: 250/390, loss: 4.267071723937988\n",
      "Epoch: 32, step: 300/390, loss: 4.195690155029297\n",
      "Epoch: 32, step: 350/390, loss: 4.281205654144287\n",
      "Epoch: 32 completed, average loss: 4.2130323568979895, time taken: 3.155963484446208 mins\n",
      "Epoch: 33, step: 50/390, loss: 4.1873016357421875\n",
      "Epoch: 33, step: 100/390, loss: 4.1594743728637695\n",
      "Epoch: 33, step: 150/390, loss: 4.224949359893799\n",
      "Epoch: 33, step: 200/390, loss: 4.182977199554443\n",
      "Epoch: 33, step: 250/390, loss: 4.186806678771973\n",
      "Epoch: 33, step: 300/390, loss: 4.169897079467773\n",
      "Epoch: 33, step: 350/390, loss: 4.223896026611328\n",
      "Epoch: 33 completed, average loss: 4.204293910051003, time taken: 3.1581233421961468 mins\n",
      "Epoch: 34, step: 50/390, loss: 4.190314769744873\n",
      "Epoch: 34, step: 100/390, loss: 4.218418598175049\n",
      "Epoch: 34, step: 150/390, loss: 4.180575370788574\n",
      "Epoch: 34, step: 200/390, loss: 4.187662124633789\n",
      "Epoch: 34, step: 250/390, loss: 4.1867241859436035\n",
      "Epoch: 34, step: 300/390, loss: 4.219954490661621\n",
      "Epoch: 34, step: 350/390, loss: 4.114047527313232\n",
      "Epoch: 34 completed, average loss: 4.201170038565611, time taken: 3.155791687965393 mins\n",
      "Epoch: 35, step: 50/390, loss: 4.254073143005371\n",
      "Epoch: 35, step: 100/390, loss: 4.2058491706848145\n",
      "Epoch: 35, step: 150/390, loss: 4.16813850402832\n",
      "Epoch: 35, step: 200/390, loss: 4.1772661209106445\n",
      "Epoch: 35, step: 250/390, loss: 4.209970951080322\n",
      "Epoch: 35, step: 300/390, loss: 4.220694541931152\n",
      "Epoch: 35, step: 350/390, loss: 4.183362007141113\n",
      "Epoch: 35 completed, average loss: 4.199906777112912, time taken: 3.1585811972618103 mins\n",
      "Epoch: 36, step: 50/390, loss: 4.174515247344971\n",
      "Epoch: 36, step: 100/390, loss: 4.182898044586182\n",
      "Epoch: 36, step: 150/390, loss: 4.223937034606934\n",
      "Epoch: 36, step: 200/390, loss: 4.231431007385254\n",
      "Epoch: 36, step: 250/390, loss: 4.23980188369751\n",
      "Epoch: 36, step: 300/390, loss: 4.239522933959961\n",
      "Epoch: 36, step: 350/390, loss: 4.163354873657227\n",
      "Epoch: 36 completed, average loss: 4.1942170497698665, time taken: 3.1560083468755087 mins\n",
      "Epoch: 37, step: 50/390, loss: 4.205226421356201\n",
      "Epoch: 37, step: 100/390, loss: 4.140096187591553\n",
      "Epoch: 37, step: 150/390, loss: 4.173173904418945\n",
      "Epoch: 37, step: 200/390, loss: 4.2348952293396\n",
      "Epoch: 37, step: 250/390, loss: 4.183143138885498\n",
      "Epoch: 37, step: 300/390, loss: 4.2491455078125\n",
      "Epoch: 37, step: 350/390, loss: 4.141777515411377\n",
      "Epoch: 37 completed, average loss: 4.191412968513293, time taken: 3.1577680985132854 mins\n",
      "Epoch: 38, step: 50/390, loss: 4.2047014236450195\n",
      "Epoch: 38, step: 100/390, loss: 4.266043663024902\n",
      "Epoch: 38, step: 150/390, loss: 4.2589898109436035\n",
      "Epoch: 38, step: 200/390, loss: 4.1784138679504395\n",
      "Epoch: 38, step: 250/390, loss: 4.18851900100708\n",
      "Epoch: 38, step: 300/390, loss: 4.20566463470459\n",
      "Epoch: 38, step: 350/390, loss: 4.22183084487915\n",
      "Epoch: 38 completed, average loss: 4.189399692339775, time taken: 3.1556756615638735 mins\n",
      "Epoch: 39, step: 50/390, loss: 4.2371039390563965\n",
      "Epoch: 39, step: 100/390, loss: 4.174574375152588\n",
      "Epoch: 39, step: 150/390, loss: 4.169322967529297\n",
      "Epoch: 39, step: 200/390, loss: 4.175907611846924\n",
      "Epoch: 39, step: 250/390, loss: 4.223433494567871\n",
      "Epoch: 39, step: 300/390, loss: 4.229312419891357\n",
      "Epoch: 39, step: 350/390, loss: 4.176225662231445\n",
      "Epoch: 39 completed, average loss: 4.18765462973179, time taken: 3.157310362656911 mins\n",
      "Epoch: 40, step: 50/390, loss: 4.184751987457275\n",
      "Epoch: 40, step: 100/390, loss: 4.291118144989014\n",
      "Epoch: 40, step: 150/390, loss: 4.109787940979004\n",
      "Epoch: 40, step: 200/390, loss: 4.1944499015808105\n",
      "Epoch: 40, step: 250/390, loss: 4.146187782287598\n",
      "Epoch: 40, step: 300/390, loss: 4.183718681335449\n",
      "Epoch: 40, step: 350/390, loss: 4.175552845001221\n",
      "Epoch: 40 completed, average loss: 4.185889414029243, time taken: 3.155311592419942 mins\n",
      "Epoch: 41, step: 50/390, loss: 4.202911853790283\n",
      "Epoch: 41, step: 100/390, loss: 4.14576530456543\n",
      "Epoch: 41, step: 150/390, loss: 4.162530899047852\n",
      "Epoch: 41, step: 200/390, loss: 4.164373397827148\n",
      "Epoch: 41, step: 250/390, loss: 4.148919582366943\n",
      "Epoch: 41, step: 300/390, loss: 4.143784523010254\n",
      "Epoch: 41, step: 350/390, loss: 4.136951923370361\n",
      "Epoch: 41 completed, average loss: 4.175973997360621, time taken: 3.156159476439158 mins\n",
      "Epoch: 42, step: 50/390, loss: 4.240813255310059\n",
      "Epoch: 42, step: 100/390, loss: 4.154813766479492\n",
      "Epoch: 42, step: 150/390, loss: 4.179730415344238\n",
      "Epoch: 42, step: 200/390, loss: 4.186270713806152\n",
      "Epoch: 42, step: 250/390, loss: 4.20762300491333\n",
      "Epoch: 42, step: 300/390, loss: 4.180426597595215\n",
      "Epoch: 42, step: 350/390, loss: 4.181738376617432\n",
      "Epoch: 42 completed, average loss: 4.178690294119028, time taken: 3.1578342358271283 mins\n",
      "Epoch: 43, step: 50/390, loss: 4.183190822601318\n",
      "Epoch: 43, step: 100/390, loss: 4.179971694946289\n",
      "Epoch: 43, step: 150/390, loss: 4.157641410827637\n",
      "Epoch: 43, step: 200/390, loss: 4.261793613433838\n",
      "Epoch: 43, step: 250/390, loss: 4.182928085327148\n",
      "Epoch: 43, step: 300/390, loss: 4.157538414001465\n",
      "Epoch: 43, step: 350/390, loss: 4.214247226715088\n",
      "Epoch: 43 completed, average loss: 4.1746381539564865, time taken: 3.1564012368520102 mins\n",
      "Epoch: 44, step: 50/390, loss: 4.200782775878906\n",
      "Epoch: 44, step: 100/390, loss: 4.126475811004639\n",
      "Epoch: 44, step: 150/390, loss: 4.260284900665283\n",
      "Epoch: 44, step: 200/390, loss: 4.147566318511963\n",
      "Epoch: 44, step: 250/390, loss: 4.203951358795166\n",
      "Epoch: 44, step: 300/390, loss: 4.20526123046875\n",
      "Epoch: 44, step: 350/390, loss: 4.2024149894714355\n",
      "Epoch: 44 completed, average loss: 4.166503565128033, time taken: 3.1558271209398905 mins\n",
      "Epoch: 45, step: 50/390, loss: 4.228734016418457\n",
      "Epoch: 45, step: 100/390, loss: 4.2107038497924805\n",
      "Epoch: 45, step: 150/390, loss: 4.2037153244018555\n",
      "Epoch: 45, step: 200/390, loss: 4.130594253540039\n",
      "Epoch: 45, step: 250/390, loss: 4.173763751983643\n",
      "Epoch: 45, step: 300/390, loss: 4.236416816711426\n",
      "Epoch: 45, step: 350/390, loss: 4.132901191711426\n",
      "Epoch: 45 completed, average loss: 4.169686469053611, time taken: 3.1636688470840455 mins\n",
      "Epoch: 46, step: 50/390, loss: 4.216868877410889\n",
      "Epoch: 46, step: 100/390, loss: 4.153868198394775\n",
      "Epoch: 46, step: 150/390, loss: 4.161613941192627\n",
      "Epoch: 46, step: 200/390, loss: 4.160364627838135\n",
      "Epoch: 46, step: 250/390, loss: 4.284977912902832\n",
      "Epoch: 46, step: 300/390, loss: 4.17848539352417\n",
      "Epoch: 46, step: 350/390, loss: 4.182091236114502\n",
      "Epoch: 46 completed, average loss: 4.164990855485965, time taken: 3.153687047958374 mins\n",
      "Epoch: 47, step: 50/390, loss: 4.148377418518066\n",
      "Epoch: 47, step: 100/390, loss: 4.159258842468262\n",
      "Epoch: 47, step: 150/390, loss: 4.172218322753906\n",
      "Epoch: 47, step: 200/390, loss: 4.171767234802246\n",
      "Epoch: 47, step: 250/390, loss: 4.196835517883301\n",
      "Epoch: 47, step: 300/390, loss: 4.183783531188965\n",
      "Epoch: 47, step: 350/390, loss: 4.154024600982666\n",
      "Epoch: 47 completed, average loss: 4.165698599204039, time taken: 3.1553157726923624 mins\n",
      "Epoch: 48, step: 50/390, loss: 4.14661169052124\n",
      "Epoch: 48, step: 100/390, loss: 4.2097907066345215\n",
      "Epoch: 48, step: 150/390, loss: 4.154823303222656\n",
      "Epoch: 48, step: 200/390, loss: 4.13502836227417\n",
      "Epoch: 48, step: 250/390, loss: 4.188810348510742\n",
      "Epoch: 48, step: 300/390, loss: 4.1627421379089355\n",
      "Epoch: 48, step: 350/390, loss: 4.163229465484619\n",
      "Epoch: 48 completed, average loss: 4.161414004594851, time taken: 3.155746948719025 mins\n",
      "Epoch: 49, step: 50/390, loss: 4.175486087799072\n",
      "Epoch: 49, step: 100/390, loss: 4.115162372589111\n",
      "Epoch: 49, step: 150/390, loss: 4.255830764770508\n",
      "Epoch: 49, step: 200/390, loss: 4.137061595916748\n",
      "Epoch: 49, step: 250/390, loss: 4.206502914428711\n",
      "Epoch: 49, step: 300/390, loss: 4.202775955200195\n",
      "Epoch: 49, step: 350/390, loss: 4.171156406402588\n",
      "Epoch: 49 completed, average loss: 4.158637054149921, time taken: 3.1515482783317568 mins\n",
      "Epoch: 50, step: 50/390, loss: 4.220044136047363\n",
      "Epoch: 50, step: 100/390, loss: 4.153510570526123\n",
      "Epoch: 50, step: 150/390, loss: 4.140141010284424\n",
      "Epoch: 50, step: 200/390, loss: 4.11883020401001\n",
      "Epoch: 50, step: 250/390, loss: 4.081685543060303\n",
      "Epoch: 50, step: 300/390, loss: 4.156337261199951\n",
      "Epoch: 50, step: 350/390, loss: 4.130518436431885\n",
      "Epoch: 50 completed, average loss: 4.15759934034103, time taken: 3.154961335659027 mins\n",
      "Epoch: 51, step: 50/390, loss: 4.202741622924805\n",
      "Epoch: 51, step: 100/390, loss: 4.200826644897461\n",
      "Epoch: 51, step: 150/390, loss: 4.165125846862793\n",
      "Epoch: 51, step: 200/390, loss: 4.166428089141846\n",
      "Epoch: 51, step: 250/390, loss: 4.152899265289307\n",
      "Epoch: 51, step: 300/390, loss: 4.204998970031738\n",
      "Epoch: 51, step: 350/390, loss: 4.199593544006348\n",
      "Epoch: 51 completed, average loss: 4.152167717615764, time taken: 3.154874328772227 mins\n",
      "Epoch: 52, step: 50/390, loss: 4.171108722686768\n",
      "Epoch: 52, step: 100/390, loss: 4.099472522735596\n",
      "Epoch: 52, step: 150/390, loss: 4.193370342254639\n",
      "Epoch: 52, step: 200/390, loss: 4.157251358032227\n",
      "Epoch: 52, step: 250/390, loss: 4.154195308685303\n",
      "Epoch: 52, step: 300/390, loss: 4.1639509201049805\n",
      "Epoch: 52, step: 350/390, loss: 4.193413734436035\n",
      "Epoch: 52 completed, average loss: 4.155086160317445, time taken: 3.1569504022598265 mins\n",
      "Epoch: 53, step: 50/390, loss: 4.104694843292236\n",
      "Epoch: 53, step: 100/390, loss: 4.112458229064941\n",
      "Epoch: 53, step: 150/390, loss: 4.099188804626465\n",
      "Epoch: 53, step: 200/390, loss: 4.073303699493408\n",
      "Epoch: 53, step: 250/390, loss: 4.129391670227051\n",
      "Epoch: 53, step: 300/390, loss: 4.150030612945557\n",
      "Epoch: 53, step: 350/390, loss: 4.107699394226074\n",
      "Epoch: 53 completed, average loss: 4.151753293550931, time taken: 3.158772869904836 mins\n",
      "Epoch: 54, step: 50/390, loss: 4.179209232330322\n",
      "Epoch: 54, step: 100/390, loss: 4.1003217697143555\n",
      "Epoch: 54, step: 150/390, loss: 4.248321533203125\n",
      "Epoch: 54, step: 200/390, loss: 4.170784950256348\n",
      "Epoch: 54, step: 250/390, loss: 4.155826091766357\n",
      "Epoch: 54, step: 300/390, loss: 4.149271011352539\n",
      "Epoch: 54, step: 350/390, loss: 4.052896976470947\n",
      "Epoch: 54 completed, average loss: 4.148043178900695, time taken: 3.1570409774780273 mins\n",
      "Epoch: 55, step: 50/390, loss: 4.150042533874512\n",
      "Epoch: 55, step: 100/390, loss: 4.057962894439697\n",
      "Epoch: 55, step: 150/390, loss: 4.146236419677734\n",
      "Epoch: 55, step: 200/390, loss: 4.223152160644531\n",
      "Epoch: 55, step: 250/390, loss: 4.073178291320801\n",
      "Epoch: 55, step: 300/390, loss: 4.064498424530029\n",
      "Epoch: 55, step: 350/390, loss: 4.1381144523620605\n",
      "Epoch: 55 completed, average loss: 4.146258344405736, time taken: 3.1553249319394427 mins\n",
      "Epoch: 56, step: 50/390, loss: 4.0982489585876465\n",
      "Epoch: 56, step: 100/390, loss: 4.096388339996338\n",
      "Epoch: 56, step: 150/390, loss: 4.164543628692627\n",
      "Epoch: 56, step: 200/390, loss: 4.171178340911865\n",
      "Epoch: 56, step: 250/390, loss: 4.134499549865723\n",
      "Epoch: 56, step: 300/390, loss: 4.200963020324707\n",
      "Epoch: 56, step: 350/390, loss: 4.238560199737549\n",
      "Epoch: 56 completed, average loss: 4.148042192214574, time taken: 3.15559884707133 mins\n",
      "Epoch: 57, step: 50/390, loss: 4.13982629776001\n",
      "Epoch: 57, step: 100/390, loss: 4.1523942947387695\n",
      "Epoch: 57, step: 150/390, loss: 4.161185264587402\n",
      "Epoch: 57, step: 200/390, loss: 4.118728160858154\n",
      "Epoch: 57, step: 250/390, loss: 4.0952348709106445\n",
      "Epoch: 57, step: 300/390, loss: 4.084896087646484\n",
      "Epoch: 57, step: 350/390, loss: 4.127964496612549\n",
      "Epoch: 57 completed, average loss: 4.141767703569853, time taken: 3.15544775724411 mins\n",
      "Epoch: 58, step: 50/390, loss: 4.143993377685547\n",
      "Epoch: 58, step: 100/390, loss: 4.094820976257324\n",
      "Epoch: 58, step: 150/390, loss: 4.11807107925415\n",
      "Epoch: 58, step: 200/390, loss: 4.224548816680908\n",
      "Epoch: 58, step: 250/390, loss: 4.095991611480713\n",
      "Epoch: 58, step: 300/390, loss: 4.129890441894531\n",
      "Epoch: 58, step: 350/390, loss: 4.146183013916016\n",
      "Epoch: 58 completed, average loss: 4.1434466080787855, time taken: 3.1567777474721272 mins\n",
      "Epoch: 59, step: 50/390, loss: 4.1623992919921875\n",
      "Epoch: 59, step: 100/390, loss: 4.09896183013916\n",
      "Epoch: 59, step: 150/390, loss: 4.152053356170654\n",
      "Epoch: 59, step: 200/390, loss: 4.148380279541016\n",
      "Epoch: 59, step: 250/390, loss: 4.151175022125244\n",
      "Epoch: 59, step: 300/390, loss: 4.0861992835998535\n",
      "Epoch: 59, step: 350/390, loss: 4.101228713989258\n",
      "Epoch: 59 completed, average loss: 4.143908166885376, time taken: 3.153910473982493 mins\n",
      "Epoch: 60, step: 50/390, loss: 4.288776397705078\n",
      "Epoch: 60, step: 100/390, loss: 4.176026821136475\n",
      "Epoch: 60, step: 150/390, loss: 4.13266134262085\n",
      "Epoch: 60, step: 200/390, loss: 4.154366970062256\n",
      "Epoch: 60, step: 250/390, loss: 4.142209053039551\n",
      "Epoch: 60, step: 300/390, loss: 4.177958011627197\n",
      "Epoch: 60, step: 350/390, loss: 4.094467639923096\n",
      "Epoch: 60 completed, average loss: 4.1422579899812355, time taken: 3.1560014327367147 mins\n",
      "Epoch: 61, step: 50/390, loss: 4.060855865478516\n",
      "Epoch: 61, step: 100/390, loss: 4.175540447235107\n",
      "Epoch: 61, step: 150/390, loss: 4.097875118255615\n",
      "Epoch: 61, step: 200/390, loss: 4.174319267272949\n",
      "Epoch: 61, step: 250/390, loss: 4.123364448547363\n",
      "Epoch: 61, step: 300/390, loss: 4.131977081298828\n",
      "Epoch: 61, step: 350/390, loss: 4.120900630950928\n",
      "Epoch: 61 completed, average loss: 4.139963165918986, time taken: 3.1554305076599123 mins\n",
      "Epoch: 62, step: 50/390, loss: 4.144993305206299\n",
      "Epoch: 62, step: 100/390, loss: 4.162516117095947\n",
      "Epoch: 62, step: 150/390, loss: 4.10845947265625\n",
      "Epoch: 62, step: 200/390, loss: 4.143802642822266\n",
      "Epoch: 62, step: 250/390, loss: 4.168170928955078\n",
      "Epoch: 62, step: 300/390, loss: 4.1872735023498535\n",
      "Epoch: 62, step: 350/390, loss: 4.099424362182617\n",
      "Epoch: 62 completed, average loss: 4.134371895667834, time taken: 3.1582919557889304 mins\n",
      "Epoch: 63, step: 50/390, loss: 4.152320384979248\n",
      "Epoch: 63, step: 100/390, loss: 4.09660005569458\n",
      "Epoch: 63, step: 150/390, loss: 4.10320520401001\n",
      "Epoch: 63, step: 200/390, loss: 4.1364426612854\n",
      "Epoch: 63, step: 250/390, loss: 4.122516632080078\n",
      "Epoch: 63, step: 300/390, loss: 4.193732261657715\n",
      "Epoch: 63, step: 350/390, loss: 4.177123546600342\n",
      "Epoch: 63 completed, average loss: 4.1348545575753235, time taken: 3.1578943490982057 mins\n",
      "Epoch: 64, step: 50/390, loss: 4.101114749908447\n",
      "Epoch: 64, step: 100/390, loss: 4.12522554397583\n",
      "Epoch: 64, step: 150/390, loss: 4.161247730255127\n",
      "Epoch: 64, step: 200/390, loss: 4.224858283996582\n",
      "Epoch: 64, step: 250/390, loss: 4.203921318054199\n",
      "Epoch: 64, step: 300/390, loss: 4.145282745361328\n",
      "Epoch: 64, step: 350/390, loss: 4.215951442718506\n",
      "Epoch: 64 completed, average loss: 4.130029568305383, time taken: 3.1648733297983807 mins\n",
      "Epoch: 65, step: 50/390, loss: 4.132594108581543\n",
      "Epoch: 65, step: 100/390, loss: 4.1474928855896\n",
      "Epoch: 65, step: 150/390, loss: 4.174137115478516\n",
      "Epoch: 65, step: 200/390, loss: 4.121565341949463\n",
      "Epoch: 65, step: 250/390, loss: 4.144961357116699\n",
      "Epoch: 65, step: 300/390, loss: 4.022458553314209\n",
      "Epoch: 65, step: 350/390, loss: 4.182540416717529\n",
      "Epoch: 65 completed, average loss: 4.128115668663612, time taken: 3.156752626101176 mins\n",
      "Epoch: 66, step: 50/390, loss: 4.115315914154053\n",
      "Epoch: 66, step: 100/390, loss: 4.096588611602783\n",
      "Epoch: 66, step: 150/390, loss: 4.149442195892334\n",
      "Epoch: 66, step: 200/390, loss: 4.123623371124268\n",
      "Epoch: 66, step: 250/390, loss: 4.12689208984375\n",
      "Epoch: 66, step: 300/390, loss: 4.093404293060303\n",
      "Epoch: 66, step: 350/390, loss: 4.109887599945068\n",
      "Epoch: 66 completed, average loss: 4.127654815331484, time taken: 3.1596267342567446 mins\n",
      "Epoch: 67, step: 50/390, loss: 4.096851348876953\n",
      "Epoch: 67, step: 100/390, loss: 4.214348793029785\n",
      "Epoch: 67, step: 150/390, loss: 4.159093379974365\n",
      "Epoch: 67, step: 200/390, loss: 4.127481460571289\n",
      "Epoch: 67, step: 250/390, loss: 4.144928932189941\n",
      "Epoch: 67, step: 300/390, loss: 4.119861125946045\n",
      "Epoch: 67, step: 350/390, loss: 4.12481164932251\n",
      "Epoch: 67 completed, average loss: 4.1261095377115105, time taken: 3.1571961800257364 mins\n",
      "Epoch: 68, step: 50/390, loss: 4.038358211517334\n",
      "Epoch: 68, step: 100/390, loss: 4.099556922912598\n",
      "Epoch: 68, step: 150/390, loss: 4.112283229827881\n",
      "Epoch: 68, step: 200/390, loss: 4.2141523361206055\n",
      "Epoch: 68, step: 250/390, loss: 4.155466556549072\n",
      "Epoch: 68, step: 300/390, loss: 4.1582818031311035\n",
      "Epoch: 68, step: 350/390, loss: 4.086184978485107\n",
      "Epoch: 68 completed, average loss: 4.127214989295372, time taken: 3.1601788361867267 mins\n",
      "Epoch: 69, step: 50/390, loss: 4.127086639404297\n",
      "Epoch: 69, step: 100/390, loss: 4.133826732635498\n",
      "Epoch: 69, step: 150/390, loss: 4.1246256828308105\n",
      "Epoch: 69, step: 200/390, loss: 4.140990257263184\n",
      "Epoch: 69, step: 250/390, loss: 4.123638153076172\n",
      "Epoch: 69, step: 300/390, loss: 4.142515182495117\n",
      "Epoch: 69, step: 350/390, loss: 4.078133583068848\n",
      "Epoch: 69 completed, average loss: 4.123978246786655, time taken: 3.1584030906359355 mins\n",
      "Epoch: 70, step: 50/390, loss: 4.101283550262451\n",
      "Epoch: 70, step: 100/390, loss: 4.190611839294434\n",
      "Epoch: 70, step: 150/390, loss: 4.0964035987854\n",
      "Epoch: 70, step: 200/390, loss: 4.038085460662842\n",
      "Epoch: 70, step: 250/390, loss: 4.198757648468018\n",
      "Epoch: 70, step: 300/390, loss: 4.0925612449646\n",
      "Epoch: 70, step: 350/390, loss: 4.167783260345459\n",
      "Epoch: 70 completed, average loss: 4.126591329085521, time taken: 3.1571919759114584 mins\n",
      "Epoch: 71, step: 50/390, loss: 4.090600490570068\n",
      "Epoch: 71, step: 100/390, loss: 4.15418004989624\n",
      "Epoch: 71, step: 150/390, loss: 4.0896782875061035\n",
      "Epoch: 71, step: 200/390, loss: 4.120395660400391\n",
      "Epoch: 71, step: 250/390, loss: 4.11973762512207\n",
      "Epoch: 71, step: 300/390, loss: 4.163022994995117\n",
      "Epoch: 71, step: 350/390, loss: 4.161399841308594\n",
      "Epoch: 71 completed, average loss: 4.123826261667105, time taken: 3.1577999273935955 mins\n",
      "Epoch: 72, step: 50/390, loss: 4.142242431640625\n",
      "Epoch: 72, step: 100/390, loss: 4.101604461669922\n",
      "Epoch: 72, step: 150/390, loss: 4.0575127601623535\n",
      "Epoch: 72, step: 200/390, loss: 4.032352924346924\n",
      "Epoch: 72, step: 250/390, loss: 4.078360557556152\n",
      "Epoch: 72, step: 300/390, loss: 4.096775531768799\n",
      "Epoch: 72, step: 350/390, loss: 4.092940330505371\n",
      "Epoch: 72 completed, average loss: 4.121393753932073, time taken: 3.1555423855781557 mins\n",
      "Epoch: 73, step: 50/390, loss: 4.14736795425415\n",
      "Epoch: 73, step: 100/390, loss: 4.099047660827637\n",
      "Epoch: 73, step: 150/390, loss: 4.164649486541748\n",
      "Epoch: 73, step: 200/390, loss: 4.093179225921631\n",
      "Epoch: 73, step: 250/390, loss: 4.12009859085083\n",
      "Epoch: 73, step: 300/390, loss: 4.087601661682129\n",
      "Epoch: 73, step: 350/390, loss: 4.21681022644043\n",
      "Epoch: 73 completed, average loss: 4.119565173907158, time taken: 3.156112861633301 mins\n",
      "Epoch: 74, step: 50/390, loss: 4.155322074890137\n",
      "Epoch: 74, step: 100/390, loss: 4.097294807434082\n",
      "Epoch: 74, step: 150/390, loss: 4.124166965484619\n",
      "Epoch: 74, step: 200/390, loss: 4.094486713409424\n",
      "Epoch: 74, step: 250/390, loss: 4.068829536437988\n",
      "Epoch: 74, step: 300/390, loss: 4.12872838973999\n",
      "Epoch: 74, step: 350/390, loss: 4.105129718780518\n",
      "Epoch: 74 completed, average loss: 4.12078046920972, time taken: 3.156834145387014 mins\n",
      "Epoch: 75, step: 50/390, loss: 4.122328281402588\n",
      "Epoch: 75, step: 100/390, loss: 4.107665538787842\n",
      "Epoch: 75, step: 150/390, loss: 4.077845096588135\n",
      "Epoch: 75, step: 200/390, loss: 4.09708309173584\n",
      "Epoch: 75, step: 250/390, loss: 4.105405330657959\n",
      "Epoch: 75, step: 300/390, loss: 4.1929144859313965\n",
      "Epoch: 75, step: 350/390, loss: 4.225052833557129\n",
      "Epoch: 75 completed, average loss: 4.1190607346021215, time taken: 3.1549090425173443 mins\n",
      "Epoch: 76, step: 50/390, loss: 4.085021018981934\n",
      "Epoch: 76, step: 100/390, loss: 4.166342258453369\n",
      "Epoch: 76, step: 150/390, loss: 4.050900936126709\n",
      "Epoch: 76, step: 200/390, loss: 4.079931735992432\n",
      "Epoch: 76, step: 250/390, loss: 4.120999336242676\n",
      "Epoch: 76, step: 300/390, loss: 4.063467979431152\n",
      "Epoch: 76, step: 350/390, loss: 4.142101764678955\n",
      "Epoch: 76 completed, average loss: 4.115062482540424, time taken: 3.1559919397036236 mins\n",
      "Epoch: 77, step: 50/390, loss: 4.111169815063477\n",
      "Epoch: 77, step: 100/390, loss: 4.083804130554199\n",
      "Epoch: 77, step: 150/390, loss: 4.105332374572754\n",
      "Epoch: 77, step: 200/390, loss: 4.090245246887207\n",
      "Epoch: 77, step: 250/390, loss: 4.10673713684082\n",
      "Epoch: 77, step: 300/390, loss: 4.153033256530762\n",
      "Epoch: 77, step: 350/390, loss: 4.1542463302612305\n",
      "Epoch: 77 completed, average loss: 4.114865158765744, time taken: 3.1573311765988668 mins\n",
      "Epoch: 78, step: 50/390, loss: 4.052314758300781\n",
      "Epoch: 78, step: 100/390, loss: 4.159976959228516\n",
      "Epoch: 78, step: 150/390, loss: 4.111438751220703\n",
      "Epoch: 78, step: 200/390, loss: 4.087305545806885\n",
      "Epoch: 78, step: 250/390, loss: 4.212492942810059\n",
      "Epoch: 78, step: 300/390, loss: 4.068368911743164\n",
      "Epoch: 78, step: 350/390, loss: 4.0799031257629395\n",
      "Epoch: 78 completed, average loss: 4.115305582682292, time taken: 3.1548718452453612 mins\n",
      "Epoch: 79, step: 50/390, loss: 4.093034744262695\n",
      "Epoch: 79, step: 100/390, loss: 4.122229099273682\n",
      "Epoch: 79, step: 150/390, loss: 4.136826992034912\n",
      "Epoch: 79, step: 200/390, loss: 4.091721534729004\n",
      "Epoch: 79, step: 250/390, loss: 4.152477264404297\n",
      "Epoch: 79, step: 300/390, loss: 4.160377025604248\n",
      "Epoch: 79, step: 350/390, loss: 4.142563343048096\n",
      "Epoch: 79 completed, average loss: 4.115814655255049, time taken: 3.157334089279175 mins\n",
      "Epoch: 80, step: 50/390, loss: 4.174898624420166\n",
      "Epoch: 80, step: 100/390, loss: 4.088845252990723\n",
      "Epoch: 80, step: 150/390, loss: 4.131350040435791\n",
      "Epoch: 80, step: 200/390, loss: 4.101364612579346\n",
      "Epoch: 80, step: 250/390, loss: 4.111301898956299\n",
      "Epoch: 80, step: 300/390, loss: 4.0325164794921875\n",
      "Epoch: 80, step: 350/390, loss: 4.095910549163818\n",
      "Epoch: 80 completed, average loss: 4.114786965419085, time taken: 3.1551212747891744 mins\n",
      "Epoch: 81, step: 50/390, loss: 4.036707878112793\n",
      "Epoch: 81, step: 100/390, loss: 4.138324737548828\n",
      "Epoch: 81, step: 150/390, loss: 4.13217830657959\n",
      "Epoch: 81, step: 200/390, loss: 4.037335395812988\n",
      "Epoch: 81, step: 250/390, loss: 4.064539909362793\n",
      "Epoch: 81, step: 300/390, loss: 4.171953201293945\n",
      "Epoch: 81, step: 350/390, loss: 4.118105411529541\n",
      "Epoch: 81 completed, average loss: 4.110092564118214, time taken: 3.1546112815539042 mins\n",
      "Epoch: 82, step: 50/390, loss: 4.130931377410889\n",
      "Epoch: 82, step: 100/390, loss: 4.133594036102295\n",
      "Epoch: 82, step: 150/390, loss: 4.101202011108398\n",
      "Epoch: 82, step: 200/390, loss: 4.135692119598389\n",
      "Epoch: 82, step: 250/390, loss: 4.089784622192383\n",
      "Epoch: 82, step: 300/390, loss: 4.037376880645752\n",
      "Epoch: 82, step: 350/390, loss: 4.171390533447266\n",
      "Epoch: 82 completed, average loss: 4.110190304731711, time taken: 3.1554352680842084 mins\n",
      "Epoch: 83, step: 50/390, loss: 4.119147777557373\n",
      "Epoch: 83, step: 100/390, loss: 4.122289180755615\n",
      "Epoch: 83, step: 150/390, loss: 4.097257614135742\n",
      "Epoch: 83, step: 200/390, loss: 4.052304267883301\n",
      "Epoch: 83, step: 250/390, loss: 4.096421241760254\n",
      "Epoch: 83, step: 300/390, loss: 4.122032642364502\n",
      "Epoch: 83, step: 350/390, loss: 4.072541236877441\n",
      "Epoch: 83 completed, average loss: 4.104347686278515, time taken: 3.1563916126887004 mins\n",
      "Epoch: 84, step: 50/390, loss: 4.151664733886719\n",
      "Epoch: 84, step: 100/390, loss: 4.136804103851318\n",
      "Epoch: 84, step: 150/390, loss: 4.101261138916016\n",
      "Epoch: 84, step: 200/390, loss: 4.175201416015625\n",
      "Epoch: 84, step: 250/390, loss: 4.098543167114258\n",
      "Epoch: 84, step: 300/390, loss: 4.0794677734375\n",
      "Epoch: 84, step: 350/390, loss: 4.167586326599121\n",
      "Epoch: 84 completed, average loss: 4.108277149689504, time taken: 3.155094627539317 mins\n",
      "Epoch: 85, step: 50/390, loss: 4.097621917724609\n",
      "Epoch: 85, step: 100/390, loss: 4.149646282196045\n",
      "Epoch: 85, step: 150/390, loss: 4.033323287963867\n",
      "Epoch: 85, step: 200/390, loss: 4.133804798126221\n",
      "Epoch: 85, step: 250/390, loss: 4.098363399505615\n",
      "Epoch: 85, step: 300/390, loss: 4.050567626953125\n",
      "Epoch: 85, step: 350/390, loss: 4.038508415222168\n",
      "Epoch: 85 completed, average loss: 4.107004615588066, time taken: 3.1613364974657694 mins\n",
      "Epoch: 86, step: 50/390, loss: 4.117863178253174\n",
      "Epoch: 86, step: 100/390, loss: 4.085287094116211\n",
      "Epoch: 86, step: 150/390, loss: 4.098256587982178\n",
      "Epoch: 86, step: 200/390, loss: 4.101933002471924\n",
      "Epoch: 86, step: 250/390, loss: 4.137073993682861\n",
      "Epoch: 86, step: 300/390, loss: 4.230980396270752\n",
      "Epoch: 86, step: 350/390, loss: 4.0980329513549805\n",
      "Epoch: 86 completed, average loss: 4.105781337542411, time taken: 3.156100543340047 mins\n",
      "Epoch: 87, step: 50/390, loss: 4.028264045715332\n",
      "Epoch: 87, step: 100/390, loss: 4.103847026824951\n",
      "Epoch: 87, step: 150/390, loss: 4.015130043029785\n",
      "Epoch: 87, step: 200/390, loss: 4.049556732177734\n",
      "Epoch: 87, step: 250/390, loss: 4.056840896606445\n",
      "Epoch: 87, step: 300/390, loss: 4.132007598876953\n",
      "Epoch: 87, step: 350/390, loss: 4.113704681396484\n",
      "Epoch: 87 completed, average loss: 4.1038489506794855, time taken: 3.155667809645335 mins\n",
      "Epoch: 88, step: 50/390, loss: 4.1196160316467285\n",
      "Epoch: 88, step: 100/390, loss: 4.117473125457764\n",
      "Epoch: 88, step: 150/390, loss: 4.087320804595947\n",
      "Epoch: 88, step: 200/390, loss: 4.080173492431641\n",
      "Epoch: 88, step: 250/390, loss: 4.100612640380859\n",
      "Epoch: 88, step: 300/390, loss: 4.175567626953125\n",
      "Epoch: 88, step: 350/390, loss: 4.081749439239502\n",
      "Epoch: 88 completed, average loss: 4.102392809818952, time taken: 3.157725433508555 mins\n",
      "Epoch: 89, step: 50/390, loss: 4.053720474243164\n",
      "Epoch: 89, step: 100/390, loss: 4.127116680145264\n",
      "Epoch: 89, step: 150/390, loss: 4.177253246307373\n",
      "Epoch: 89, step: 200/390, loss: 4.1348958015441895\n",
      "Epoch: 89, step: 250/390, loss: 4.026993751525879\n",
      "Epoch: 89, step: 300/390, loss: 4.1689453125\n",
      "Epoch: 89, step: 350/390, loss: 4.119463920593262\n",
      "Epoch: 89 completed, average loss: 4.10341615432348, time taken: 3.1634411613146463 mins\n",
      "Epoch: 90, step: 50/390, loss: 4.109319686889648\n",
      "Epoch: 90, step: 100/390, loss: 4.082357883453369\n",
      "Epoch: 90, step: 150/390, loss: 4.1467180252075195\n",
      "Epoch: 90, step: 200/390, loss: 4.090361595153809\n",
      "Epoch: 90, step: 250/390, loss: 4.089113235473633\n",
      "Epoch: 90, step: 300/390, loss: 4.169454574584961\n",
      "Epoch: 90, step: 350/390, loss: 4.050057888031006\n",
      "Epoch: 90 completed, average loss: 4.101281340916952, time taken: 3.1631706436475118 mins\n",
      "Epoch: 91, step: 50/390, loss: 4.077548980712891\n",
      "Epoch: 91, step: 100/390, loss: 4.095580577850342\n",
      "Epoch: 91, step: 150/390, loss: 4.06223201751709\n",
      "Epoch: 91, step: 200/390, loss: 4.08681058883667\n",
      "Epoch: 91, step: 250/390, loss: 4.072521209716797\n",
      "Epoch: 91, step: 300/390, loss: 4.091006755828857\n",
      "Epoch: 91, step: 350/390, loss: 4.20856237411499\n",
      "Epoch: 91 completed, average loss: 4.10161087451837, time taken: 3.16429089307785 mins\n",
      "Epoch: 92, step: 50/390, loss: 4.065089225769043\n",
      "Epoch: 92, step: 100/390, loss: 4.133406162261963\n",
      "Epoch: 92, step: 150/390, loss: 4.156112194061279\n",
      "Epoch: 92, step: 200/390, loss: 4.140922546386719\n",
      "Epoch: 92, step: 250/390, loss: 4.07399320602417\n",
      "Epoch: 92, step: 300/390, loss: 4.080438137054443\n",
      "Epoch: 92, step: 350/390, loss: 4.072967529296875\n",
      "Epoch: 92 completed, average loss: 4.0975014668244585, time taken: 3.165399765968323 mins\n",
      "Epoch: 93, step: 50/390, loss: 4.161809921264648\n",
      "Epoch: 93, step: 100/390, loss: 4.123655319213867\n",
      "Epoch: 93, step: 150/390, loss: 4.128498077392578\n",
      "Epoch: 93, step: 200/390, loss: 4.120236873626709\n",
      "Epoch: 93, step: 250/390, loss: 4.060428619384766\n",
      "Epoch: 93, step: 300/390, loss: 4.08961820602417\n",
      "Epoch: 93, step: 350/390, loss: 4.079681873321533\n",
      "Epoch: 93 completed, average loss: 4.097739742352412, time taken: 3.1637551546096803 mins\n",
      "Epoch: 94, step: 50/390, loss: 4.051758289337158\n",
      "Epoch: 94, step: 100/390, loss: 4.129237651824951\n",
      "Epoch: 94, step: 150/390, loss: 4.0638747215271\n",
      "Epoch: 94, step: 200/390, loss: 4.152766227722168\n",
      "Epoch: 94, step: 250/390, loss: 4.063529968261719\n",
      "Epoch: 94, step: 300/390, loss: 4.116702556610107\n",
      "Epoch: 94, step: 350/390, loss: 4.107594966888428\n",
      "Epoch: 94 completed, average loss: 4.098234751285651, time taken: 3.1565285166104635 mins\n",
      "Epoch: 95, step: 50/390, loss: 4.069364070892334\n",
      "Epoch: 95, step: 100/390, loss: 4.094925403594971\n",
      "Epoch: 95, step: 150/390, loss: 4.071480751037598\n",
      "Epoch: 95, step: 200/390, loss: 4.081061363220215\n",
      "Epoch: 95, step: 250/390, loss: 4.139721393585205\n",
      "Epoch: 95, step: 300/390, loss: 4.152434349060059\n",
      "Epoch: 95, step: 350/390, loss: 4.13426399230957\n",
      "Epoch: 95 completed, average loss: 4.097405021618574, time taken: 3.156123677889506 mins\n",
      "Epoch: 96, step: 50/390, loss: 4.150372505187988\n",
      "Epoch: 96, step: 100/390, loss: 4.063197135925293\n",
      "Epoch: 96, step: 150/390, loss: 4.0117716789245605\n",
      "Epoch: 96, step: 200/390, loss: 4.105835437774658\n",
      "Epoch: 96, step: 250/390, loss: 4.127383708953857\n",
      "Epoch: 96, step: 300/390, loss: 4.081169605255127\n",
      "Epoch: 96, step: 350/390, loss: 4.130817413330078\n",
      "Epoch: 96 completed, average loss: 4.092477090542133, time taken: 3.1549522558848064 mins\n",
      "Epoch: 97, step: 50/390, loss: 4.119262218475342\n",
      "Epoch: 97, step: 100/390, loss: 4.197988510131836\n",
      "Epoch: 97, step: 150/390, loss: 4.122829914093018\n",
      "Epoch: 97, step: 200/390, loss: 4.122519016265869\n",
      "Epoch: 97, step: 250/390, loss: 4.0333099365234375\n",
      "Epoch: 97, step: 300/390, loss: 4.157226085662842\n",
      "Epoch: 97, step: 350/390, loss: 4.102700233459473\n",
      "Epoch: 97 completed, average loss: 4.097619558603336, time taken: 3.1588993469874063 mins\n",
      "Epoch: 98, step: 50/390, loss: 4.0841965675354\n",
      "Epoch: 98, step: 100/390, loss: 4.026727676391602\n",
      "Epoch: 98, step: 150/390, loss: 4.070158958435059\n",
      "Epoch: 98, step: 200/390, loss: 4.055212020874023\n",
      "Epoch: 98, step: 250/390, loss: 4.066537857055664\n",
      "Epoch: 98, step: 300/390, loss: 4.1530656814575195\n",
      "Epoch: 98, step: 350/390, loss: 4.170485496520996\n",
      "Epoch: 98 completed, average loss: 4.09792131399497, time taken: 3.154731114705404 mins\n",
      "Epoch: 99, step: 50/390, loss: 4.041239261627197\n",
      "Epoch: 99, step: 100/390, loss: 4.058810710906982\n",
      "Epoch: 99, step: 150/390, loss: 4.082787990570068\n",
      "Epoch: 99, step: 200/390, loss: 4.031524658203125\n",
      "Epoch: 99, step: 250/390, loss: 4.220788478851318\n",
      "Epoch: 99, step: 300/390, loss: 4.1093621253967285\n",
      "Epoch: 99, step: 350/390, loss: 4.052757263183594\n",
      "Epoch: 99 completed, average loss: 4.090115930483892, time taken: 3.1544739564259845 mins\n"
     ]
    }
   ],
   "source": [
    "proj_dim = 128\n",
    "model = SimClr('resnet50',proj_dim).cuda()\n",
    "temperature = 0.5\n",
    "#criterion = nt_xent_loss\n",
    "criterion = SimCLR_Loss(128,0.5)\n",
    "optimizer = \"LARS\"\n",
    "model, train_loss = train_simclr(train_loader_simclr,model,criterion,optimizer,100,128,True,\"/content/model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "IK3CS0fa-uY0",
    "outputId": "2fe99a40-3749-4394-9b1a-c54ae0d6d576"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"NT-XENT\")\n",
    "plt.title(\"CIFAR10-RES50-BS128-LARS\")\n",
    "plt.plot(train_loss)\n",
    "plt.savefig(\"/content/CIFAR10-RES50-BS128-LARS.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TjDohcTsAtuE"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/CIFAR10-RES50-BS128-LARS\", \"wb\") as fp:   #Pickling\n",
    "  pickle.dump(train_loss, fp)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "simclr_kaan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
